{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from data_loader.data_loader import DataLoader\n",
    "import tensorflow as tf\n",
    "# from nets.depth_net import D_Net\n",
    "from nets.flow_net import feature_pyramid_flow, construct_model_pwc_full\n",
    "from nets.pose_net import P_Net3\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select one or several free gpu\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1, 2'\n",
    "# use CPU only\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_graph(graph):\n",
    "    flops = tf.profiler.profile(graph,\n",
    "    options=tf.profiler.ProfileOptionBuilder.float_operation())\n",
    "    params = tf.profiler.profile(graph,    options=tf.profiler.ProfileOptionBuilder.trainable_variables_parameter())\n",
    "    print(\"FLOPs: {}; Trainable params: {}\".format(flops.total_float_ops, params.total_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleNetV2_mobile():\n",
    "\n",
    "    first_conv_channel = 24\n",
    "    \n",
    "    def __init__(self, input_holder, var_scope, model_scale=1.0, shuffle_group=2, is_training=True):\n",
    "        self.input = input_holder\n",
    "        self.output = None\n",
    "        self.shuffle_group = shuffle_group\n",
    "        self.channel_sizes = self._select_channel_size(model_scale)\n",
    "        self.var_scope = var_scope\n",
    "        self.is_training = is_training\n",
    "        self.output_channel_sizes = [512, 256, 128, 64, 32]\n",
    "        \n",
    "    def _select_channel_size(self, model_scale):\n",
    "        # [(out_channel, repeat_times), (out_channel, repeat_times), ...]\n",
    "        if model_scale == 0.5:\n",
    "            return [(48, 4), (96, 8), (192, 4), (1024, 1)]\n",
    "        elif model_scale == 1.0:\n",
    "            return [(116, 4), (232, 8), (464, 4), (1024, 1)]\n",
    "        elif model_scale == 1.5:\n",
    "            return [(176, 4), (352, 8), (704, 4), (1024, 1)]\n",
    "        elif model_scale == 2.0:\n",
    "            return [(244, 4), (488, 8), (976, 4), (2048, 1)]\n",
    "        else:\n",
    "            raise ValueError('Unsupported model size.')\n",
    "    \n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        with tf.variable_scope(self.var_scope) as sc:\n",
    "            with slim.arg_scope([slim.batch_norm], is_training=self.is_training):\n",
    "                skip = []\n",
    "                with tf.variable_scope('encoder'):\n",
    "                    with tf.variable_scope('init_block'):\n",
    "                        out = conv_bn_relu(self.input, self.first_conv_channel, 3, 2)\n",
    "                        skip.append(out)\n",
    "                        out = slim.max_pool2d(skip[0], 3, 2, padding='SAME')\n",
    "                        skip.append(out)\n",
    "                        \n",
    "                    for idx, block in enumerate(self.channel_sizes[:-1]):\n",
    "                        with tf.variable_scope('shuffle_block_{}'.format(idx)):\n",
    "                            out_channel, repeat = block\n",
    "\n",
    "                            # First block is downsampling\n",
    "                            print(\"[Downsample] out, out_channel:\", out.shape[-1], out_channel)\n",
    "                            out = shufflenet_v2_block(out, out_channel, 3, 2, shuffle_group=self.shuffle_group)\n",
    "\n",
    "                            # Rest blocks\n",
    "                            for i in range(repeat-1):\n",
    "                                print(\"[Rest] out, out_channel:\", out.shape[-1], out_channel)\n",
    "                                out = shufflenet_v2_block(out, out_channel, 3, shuffle_group=self.shuffle_group)\n",
    "\n",
    "                            skip.append(out)\n",
    "\n",
    "\n",
    "                    with tf.variable_scope('end_block'):\n",
    "                        out = conv_bn_relu(out, self.channel_sizes[-1][0], 1)\n",
    "\n",
    "                for idx, sk in enumerate(skip):\n",
    "                    print(\"skip[%d]:\" % idx, sk.shape)\n",
    "                    \n",
    "                with tf.variable_scope('decoder'):\n",
    "                    # DECODER\n",
    "                    pred = []\n",
    "                    x = out\n",
    "                    for idx, channel in enumerate(self.output_channel_sizes):\n",
    "                        x = upsample_nn(x, 2)\n",
    "                        x = dec_block(x, channel, scope='up_block_%d' % idx, depthType='sep')\n",
    "                        \n",
    "                        if idx != 4:\n",
    "                            x = tf.concat([x, skip[3-idx]], 3)\n",
    "                        if idx > 1:\n",
    "                            x = tf.concat([x, upsample_nn(pred[idx-2], 2)], 3)\n",
    "                            \n",
    "                        x = dec_block(x, channel, scope='block_%d' % idx, depthType='sep')\n",
    "                        \n",
    "                        if idx != 0:\n",
    "                            pred.append(get_pred(x))\n",
    "                        \n",
    "       \n",
    "        return pred[::-1], out\n",
    "\n",
    "\n",
    "    \n",
    "def dec_block(input_tensor, output_channel, scope = None, depthType='sep'):\n",
    "    with tf.variable_scope(scope, default_name='separable_conv'):\n",
    "        input_tensor = tf.identity(input_tensor, name='input')\n",
    "        net = input_tensor\n",
    "        \n",
    "        #define depthwise function\n",
    "        if depthType == 'sep':\n",
    "            depthwise_func = functools.partial(slim.separable_conv2d,\n",
    "                                                num_outputs=None,\n",
    "                                                kernel_size=3,\n",
    "                                                depth_multiplier=1,\n",
    "                                                stride=1,\n",
    "                                                rate=1,\n",
    "                                                normalizer_fn=None,\n",
    "                                                padding='SAME',\n",
    "                                                scope='depthwise')\n",
    "        elif depthType == 'dep':\n",
    "            depthwise_func = functools.partial(dwise_conv, k_h=3, k_w=3, channel_multiplier= 1, strides=[1,1,1,1],\n",
    "                                                   padding='SAME', stddev=0.02, name='dwise_conv')\n",
    "        elif depthType == 'combine':\n",
    "            depthwise_func = functools.partial(dwise_combine, name='dwise_combine')\n",
    "        \n",
    "        \n",
    "        # main block\n",
    "#         net = slim.conv2d(net, 6*output_channel, 1)\n",
    "        net = depthwise_func(net)\n",
    "        net = slim.conv2d(net, output_channel, 1, activation_fn=None)\n",
    "        \n",
    "\n",
    "    \n",
    "        return tf.identity(net, name='output')\n",
    "    \n",
    "def dwise_conv(input, k_h=3, k_w=3, channel_multiplier= 1, strides=[1,1,1,1],\n",
    "               padding='SAME', stddev=0.02, name='dwise_conv'):\n",
    "    with tf.variable_scope(name):\n",
    "        in_channel=input.get_shape().as_list()[-1]\n",
    "        w = tf.get_variable('w', [k_h, k_w, in_channel, channel_multiplier], dtype=tf.float32, \n",
    "                        initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        conv = tf.nn.depthwise_conv2d(input, w, strides, padding, rate=None,name=None,data_format=None)\n",
    "\n",
    "    return conv\n",
    "\n",
    "def dwise_combine(input, name='dwise_combine'):\n",
    "    with tf.variable_scope(name):\n",
    "        n, h, w, c = input.get_shape().as_list()\n",
    "        if (c >= 512) or (c < 512 and h < 128):\n",
    "            return dwise_conv(input)\n",
    "        else:\n",
    "            return slim.separable_conv2d(input, \n",
    "                                        num_outputs=None,\n",
    "                                        kernel_size=3,\n",
    "                                        depth_multiplier=1,\n",
    "                                        stride=1,\n",
    "                                        rate=1,\n",
    "                                        normalizer_fn=None,\n",
    "                                        padding='SAME',\n",
    "                                        scope='depthwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleNetV2():\n",
    "\n",
    "    first_conv_channel = 24\n",
    "    \n",
    "    def __init__(self, input_holder, var_scope, model_scale=1.0, shuffle_group=2, is_training=True):\n",
    "        self.input = input_holder\n",
    "        self.output = None\n",
    "        self.shuffle_group = shuffle_group\n",
    "        self.channel_sizes = self._select_channel_size(model_scale)\n",
    "        self.var_scope = var_scope\n",
    "        self.is_training = is_training\n",
    "\n",
    "    def _select_channel_size(self, model_scale):\n",
    "        # [(out_channel, repeat_times), (out_channel, repeat_times), ...]\n",
    "        if model_scale == 0.5:\n",
    "            return [(48, 4), (96, 8), (192, 4), (1024, 1)]\n",
    "        elif model_scale == 1.0:\n",
    "            return [(116, 4), (232, 8), (464, 4), (1024, 1)]\n",
    "        elif model_scale == 1.5:\n",
    "            return [(176, 4), (352, 8), (704, 4), (1024, 1)]\n",
    "        elif model_scale == 2.0:\n",
    "            return [(244, 4), (488, 8), (976, 4), (2048, 1)]\n",
    "        else:\n",
    "            raise ValueError('Unsupported model size.')\n",
    "\n",
    "    def build_model(self):\n",
    "        with tf.variable_scope(self.var_scope) as sc:\n",
    "            with slim.arg_scope([slim.batch_norm], is_training=self.is_training):\n",
    "                skip = []\n",
    "                with tf.variable_scope('encoder'):\n",
    "                    with tf.variable_scope('init_block'):\n",
    "                        out = conv_bn_relu(self.input, self.first_conv_channel, 3, 2)\n",
    "                        skip.append(out)\n",
    "                        out = slim.max_pool2d(skip[0], 3, 2, padding='SAME')\n",
    "                        skip.append(out)\n",
    "                        \n",
    "                    for idx, block in enumerate(self.channel_sizes[:-1]):\n",
    "                        with tf.variable_scope('shuffle_block_{}'.format(idx)):\n",
    "                            out_channel, repeat = block\n",
    "\n",
    "                            # First block is downsampling\n",
    "                            print(\"[Downsample] out, out_channel:\", out.shape[-1], out_channel)\n",
    "                            out = shufflenet_v2_block(out, out_channel, 3, 2, shuffle_group=self.shuffle_group)\n",
    "\n",
    "                            # Rest blocks\n",
    "                            for i in range(repeat-1):\n",
    "                                print(\"[Rest] out, out_channel:\", out.shape[-1], out_channel)\n",
    "                                out = shufflenet_v2_block(out, out_channel, 3, shuffle_group=self.shuffle_group)\n",
    "\n",
    "                            skip.append(out)\n",
    "\n",
    "\n",
    "                    with tf.variable_scope('end_block'):\n",
    "                        out = conv_bn_relu(out, self.channel_sizes[-1][0], 1)\n",
    "                        skip.append(out)\n",
    "                for idx, sk in enumerate(skip):\n",
    "                    print(\"skip[%d]:\" % idx, sk.shape)\n",
    "                with tf.variable_scope('decoder'):\n",
    "                    # DECODING\n",
    "                    upconv6 = upconv(skip[5],   512, 3, 2)\n",
    "#                     upconv6 = upconv_sep(skip[5],   512, 3, 2) #H/32\n",
    "                    upconv6 = resize_like(upconv6, skip[4])\n",
    "                    concat6 = tf.concat([upconv6, skip[4]], 3)\n",
    "                    iconv6  = conv(concat6,   512, 3, 1)\n",
    "#                     iconv6  = shufflenet_v2_block(concat6, 512, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "                    \n",
    "                    upconv5 = upconv(iconv6, 256, 3, 2)\n",
    "#                     upconv5 = upconv_sep(iconv6, 256, 3, 2) #H/16\n",
    "                    upconv5 = resize_like(upconv5, skip[3])\n",
    "                    concat5 = tf.concat([upconv5, skip[3]], 3)\n",
    "                    iconv5  = conv(concat5,   256, 3, 1)\n",
    "#                     iconv5  = shufflenet_v2_block(concat5, 256, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "\n",
    "                    upconv4 = upconv(iconv5,  128, 3, 2)\n",
    "#                     upconv4 = upconv_sep(iconv5,  128, 3, 2) #H/8\n",
    "                    upconv4 = resize_like(upconv4, skip[2])\n",
    "                    concat4 = tf.concat([upconv4, skip[2]], 3)\n",
    "                    iconv4  = conv(concat4,   128, 3, 1)\n",
    "#                     iconv4  = shufflenet_v2_block(concat4, 128, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "                    pred4 = get_pred(iconv4)\n",
    "                    upred4  = upsample_nn(pred4, 2)\n",
    "                    \n",
    "                    upconv3 = upconv(iconv4,   64, 3, 2)\n",
    "#                     upconv3 = upconv_sep(iconv4,   64, 3, 2) #H/4\n",
    "                    concat3 = tf.concat([upconv3, skip[1], upred4], 3)\n",
    "                    iconv3  = conv(concat3,    64, 3, 1)\n",
    "#                     iconv3  = shufflenet_v2_block(concat3, 64, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "                    pred3 = get_pred(iconv3)\n",
    "                    upred3  = upsample_nn(pred3, 2)\n",
    "                    \n",
    "                    upconv2 = upconv(iconv3,   32, 3, 2)\n",
    "#                     upconv2 = upconv_sep(iconv3,   32, 3, 2) #H/2\n",
    "                    concat2 = tf.concat([upconv2, skip[0], upred3], 3)\n",
    "                    iconv2  = conv(concat2,    32, 3, 1)\n",
    "#                     iconv2  = shufflenet_v2_block(concat2, 32, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "                    pred2 = get_pred(iconv2)\n",
    "                    upred2  = upsample_nn(pred2, 2)\n",
    "                    \n",
    "                    upconv1 = upconv(iconv2,  16, 3, 2)\n",
    "#                     upconv1 = upconv_sep(iconv2,  16, 3, 2) #H\n",
    "                    concat1 = tf.concat([upconv1, upred2], 3)\n",
    "                    iconv1  = conv(concat1,   16, 3, 1)\n",
    "#                     iconv1  = shufflenet_v2_block(concat1, 16, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "                    pred1 = get_pred(iconv1)\n",
    "\n",
    "                    return [pred1, pred2, pred3, pred4], skip[5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_unit(x, groups):\n",
    "    with tf.variable_scope('shuffle_unit'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "        if c % groups == 0:\n",
    "            x = tf.reshape(x, shape=tf.convert_to_tensor([tf.shape(x)[0], h, w, groups, c // groups]))\n",
    "            x = tf.transpose(x, tf.convert_to_tensor([0, 1, 2, 4, 3]))\n",
    "            x = tf.reshape(x, shape=tf.convert_to_tensor([tf.shape(x)[0], h, w, c]))\n",
    "    return x\n",
    "\n",
    "def conv_bn_relu(x, out_channel, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'conv_bn_relu'):\n",
    "        x = slim.conv2d(x, out_channel, kernel_size, stride, rate=dilation,\n",
    "                        biases_initializer=None, activation_fn=None)\n",
    "        x = slim.batch_norm(x, activation_fn=tf.nn.relu, fused=False)\n",
    "    return x\n",
    "\n",
    "def conv_bn(x, out_channel, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'conv_bn'):\n",
    "        x = slim.conv2d(x, out_channel, kernel_size, stride, rate=dilation,\n",
    "                        biases_initializer=None, activation_fn=None)\n",
    "        x = slim.batch_norm(x, activation_fn=None, fused=False)\n",
    "    return x\n",
    "\n",
    "def depthwise_conv_bn(x, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'depthwise_conv_bn'):\n",
    "        x = slim.separable_conv2d(x, None, kernel_size, depth_multiplier=1, stride=stride,\n",
    "                                  rate=dilation, activation_fn=None, biases_initializer=None)\n",
    "        x = slim.batch_norm(x, activation_fn=None, fused=False)\n",
    "    return x\n",
    "\n",
    "def resolve_shape(x):\n",
    "    with tf.variable_scope(None, 'resolve_shape'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "        if h is None or w is None:\n",
    "            kernel_size = tf.convert_to_tensor([tf.shape(x)[1], tf.shape(x)[2]])\n",
    "        else:\n",
    "            kernel_size = [h, w]\n",
    "    return kernel_size\n",
    "\n",
    "def global_avg_pool2D(x):\n",
    "    with tf.variable_scope(None, 'global_pool2D'):\n",
    "        kernel_size = resolve_shape(x)\n",
    "        x = slim.avg_pool2d(x, kernel_size, stride=1)\n",
    "        x.set_shape([None, 1, 1, None])\n",
    "    return x\n",
    "\n",
    "def se_unit(x, bottleneck=2):\n",
    "    with tf.variable_scope(None, 'SE_module'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "\n",
    "        kernel_size = resolve_shape(x)\n",
    "        x_pool = slim.avg_pool2d(x, kernel_size, stride=1)\n",
    "        x_pool = tf.reshape(x_pool, shape=[-1, c])\n",
    "        fc = slim.fully_connected(x_pool, bottleneck, activation_fn=tf.nn.relu,\n",
    "                                  biases_initializer=None)\n",
    "        fc = slim.fully_connected(fc, c, activation_fn=tf.nn.sigmoid,\n",
    "                                  biases_initializer=None)\n",
    "        if n is None:\n",
    "            channel_w = tf.reshape(fc, shape=tf.convert_to_tensor([tf.shape(x)[0], 1, 1, c]))\n",
    "        else:\n",
    "            channel_w = tf.reshape(fc, shape=[n, 1, 1, c])\n",
    "\n",
    "        x = tf.multiply(x, channel_w)\n",
    "    return x\n",
    "\n",
    "def shufflenet_v2_block(x, out_channel, kernel_size, stride=1, dilation=1, shuffle_group=2):\n",
    "    with tf.variable_scope(None, 'shuffle_v2_block'):\n",
    "        if stride == 1 and x.shape[-1] == out_channel:\n",
    "#             if x.shape[-1] != out_channel:\n",
    "#                 x = conv_bn_relu(x, out_channel, 1)\n",
    "                \n",
    "            top, bottom = tf.split(x, num_or_size_splits=2, axis=3)\n",
    "\n",
    "            half_channel = out_channel // 2\n",
    "\n",
    "            top = conv_bn_relu(top, half_channel, 1)\n",
    "            top = depthwise_conv_bn(top, kernel_size, stride, dilation)\n",
    "            top = conv_bn_relu(top, half_channel, 1)\n",
    "\n",
    "            out = tf.concat([top, bottom], axis=3)\n",
    "\n",
    "            out = shuffle_unit(out, shuffle_group)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            half_channel = out_channel // 2\n",
    "            b0 = conv_bn_relu(x, half_channel, 1)\n",
    "            b0 = depthwise_conv_bn(b0, kernel_size, stride, dilation)\n",
    "            b0 = conv_bn_relu(b0, half_channel, 1)\n",
    "\n",
    "            b1 = depthwise_conv_bn(x, kernel_size, stride, dilation)\n",
    "            b1 = conv_bn_relu(b1, half_channel, 1)\n",
    "\n",
    "            out = tf.concat([b0, b1], axis=3)\n",
    "            out = shuffle_unit(out, shuffle_group)\n",
    "       \n",
    "        return out\n",
    "    \n",
    "\n",
    "def resize_like(inputs, ref):\n",
    "    iH, iW = inputs.get_shape()[1], inputs.get_shape()[2]\n",
    "    rH, rW = ref.get_shape()[1], ref.get_shape()[2]\n",
    "    if iH == rH and iW == rW:\n",
    "        return inputs\n",
    "    return tf.image.resize_nearest_neighbor(inputs, [rH.value, rW.value])\n",
    "\n",
    "def upconv(x, num_out_layers, kernel_size, scale):\n",
    "    upsample = upsample_nn(x, scale)\n",
    "    cnv = conv(upsample, num_out_layers, kernel_size, 1)\n",
    "    return cnv\n",
    "\n",
    "def upsample_nn(x, ratio):\n",
    "    h = x.get_shape()[1].value\n",
    "    w = x.get_shape()[2].value\n",
    "    return tf.image.resize_nearest_neighbor(x, [h * ratio, w * ratio])\n",
    "\n",
    "def upconv_sep(x, num_out_layers, kernel_size, scale):\n",
    "    upsample = upsample_nn(x, scale)\n",
    "#     cnv = conv(upsample, num_out_layers, kernel_size, 1)\n",
    "    cnv  = shufflenet_v2_block(upsample, num_out_layers, kernel_size, stride=1, dilation=1, shuffle_group=2)\n",
    "    return cnv\n",
    "\n",
    "def conv(x, num_out_layers, kernel_size, stride, activation_fn=tf.nn.elu, normalizer_fn=slim.batch_norm):\n",
    "    p = np.floor((kernel_size - 1) / 2).astype(np.int32)\n",
    "    p_x = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], mode='REFLECT')\n",
    "    return slim.conv2d(p_x, num_out_layers, kernel_size, stride, 'VALID', activation_fn=activation_fn, normalizer_fn=normalizer_fn)\n",
    "\n",
    "def maxpool(x, kernel_size):\n",
    "    p = np.floor((kernel_size - 1) / 2).astype(np.int32)\n",
    "    p_x = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], mode='REFLECT')\n",
    "    return slim.max_pool2d(p_x, kernel_size)\n",
    "\n",
    "def get_pred(x):\n",
    "    disp = 5 * conv(x, 1, 3, 1, activation_fn=tf.nn.sigmoid, normalizer_fn=None) + 0.01\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_Net3(image_stack, disp_bottleneck_stack, joint_encoder, weight_reg=0.0004):\n",
    "    with tf.variable_scope('pose_net') as sc:\n",
    "        end_points_collection = sc.original_name_scope + '_end_points'\n",
    "        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                          normalizer_fn=None,\n",
    "                          weights_regularizer=slim.l2_regularizer(weight_reg),\n",
    "                          normalizer_params=None,\n",
    "                          activation_fn=tf.nn.relu,\n",
    "                          outputs_collections=end_points_collection):\n",
    "            if not joint_encoder:\n",
    "                cnv1 = slim.conv2d(image_stack, 16, [7, 7], stride=2, scope='cnv1')\n",
    "                cnv1b = slim.conv2d(cnv1, 16, [7, 7], stride=1, scope='cnv1b')\n",
    "                cnv2 = slim.conv2d(cnv1b, 32, [5, 5], stride=2, scope='cnv2')\n",
    "                cnv2b = slim.conv2d(cnv2, 32, [5, 5], stride=1, scope='cnv2b')\n",
    "                cnv3 = slim.conv2d(cnv2b, 64, [3, 3], stride=2, scope='cnv3')\n",
    "                cnv3b = slim.conv2d(cnv3, 64, [3, 3], stride=1, scope='cnv3b')\n",
    "                cnv4 = slim.conv2d(cnv3b, 128, [3, 3], stride=2, scope='cnv4')\n",
    "                cnv4b = slim.conv2d(cnv4, 128, [3, 3], stride=1, scope='cnv4b')\n",
    "                cnv5 = slim.conv2d(cnv4b, 256, [3, 3], stride=2, scope='cnv5')\n",
    "                cnv5b = slim.conv2d(cnv5, 256, [3, 3], stride=1, scope='cnv5b')\n",
    "\n",
    "            inputs = disp_bottleneck_stack if joint_encoder else cnv5b\n",
    "\n",
    "            # Pose specific layers\n",
    "            cnv6 = slim.conv2d(inputs, 256, [3, 3], stride=2, scope='cnv6')\n",
    "            cnv6b = slim.conv2d(cnv6, 256, [3, 3], stride=1, scope='cnv6b')\n",
    "            cnv7 = slim.conv2d(cnv6b, 256, [3, 3], stride=2, scope='cnv7')\n",
    "            cnv7b = slim.conv2d(cnv7, 256, [3, 3], stride=1, scope='cnv7b')\n",
    "\n",
    "            pose_pred = slim.conv2d(\n",
    "                cnv7b,\n",
    "                6*6, [1, 1],\n",
    "                scope='pred',\n",
    "                stride=1,\n",
    "                normalizer_fn=None,\n",
    "                activation_fn=None)\n",
    "            pose_avg = tf.reduce_mean(pose_pred, [1, 2])\n",
    "            pose_final = tf.reshape(pose_avg, [-1, 1, 6*6])\n",
    "\n",
    "            tran_mag = 0.001 if joint_encoder else 1.0\n",
    "            rot_mag= 0.01\n",
    "\n",
    "            pose_final = tf.concat(\n",
    "                [tran_mag * pose_final[:, :, 0:3],   rot_mag * pose_final[:, :, 3:6],    # 0: src0 -> tgt\n",
    "                 tran_mag * pose_final[:, :, 6:9],   rot_mag * pose_final[:, :, 9:12],   # 1: tgt -> src1\n",
    "                 tran_mag * pose_final[:, :, 12:15], rot_mag * pose_final[:, :, 15:18],  # 2: src0 -> src1\n",
    "                 tran_mag * pose_final[:, :, 18:21], rot_mag * pose_final[:, :, 21:24],  # 3: tgt -> src0\n",
    "                 tran_mag * pose_final[:, :, 24:27], rot_mag * pose_final[:, :, 27:30],  # 4: src1 -> tgt\n",
    "                 tran_mag * pose_final[:, :, 30:33], rot_mag * pose_final[:, :, 33:36]], # 5: src1 -> src0\n",
    "                axis=2)\n",
    "\n",
    "            return pose_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "(8, 256, 832, 3)\n",
      "[Downsample] out, out_channel: 24 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Downsample] out, out_channel: 116 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Downsample] out, out_channel: 232 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "skip[0]: (8, 128, 416, 24)\n",
      "skip[1]: (8, 64, 208, 24)\n",
      "skip[2]: (8, 32, 104, 116)\n",
      "skip[3]: (8, 16, 52, 232)\n",
      "skip[4]: (8, 8, 26, 464)\n",
      "skip[5]: (8, 8, 26, 1024)\n"
     ]
    }
   ],
   "source": [
    "Gd=tf.Graph()\n",
    "Gp=tf.Graph()\n",
    "Gf=tf.Graph()\n",
    "\n",
    "batch_size = 8\n",
    "img_height = 256\n",
    "img_width = 832\n",
    "\n",
    "with Gd.as_default():\n",
    "    t = tf.random_uniform((batch_size, img_height, img_width, 3))\n",
    "    \n",
    "    print(t.dtype)\n",
    "    print(t.shape)\n",
    "#     tgt_pred_disp, tgt_disp_bottlenecks = D_Net(depth_inputs, weight_reg=0.05, is_training=True, reuse=False)\n",
    "    D_Model = ShuffleNetV2(input_holder=t, \n",
    "                           var_scope='depth_net', \n",
    "                           model_scale=1.0, \n",
    "                           shuffle_group=2, \n",
    "                           is_training=True)\n",
    "    tgt_pred_disp, tgt_disp_bottlenecks = D_Model.build_model()\n",
    "    \n",
    "    #Get layers\n",
    "    var_depth = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*(depth_net|feature_net_disp).*\")))\n",
    "    var_enc = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*encoder.*\")))\n",
    "    var_dec = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*decoder.*\")))\n",
    "    #Get param\n",
    "    pc_depth = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_depth])\n",
    "    pc_enc = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_enc])\n",
    "    pc_dec = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_dec])\n",
    "    \n",
    "with Gp.as_default():    \n",
    "    pose_inputs = tf.random_uniform((batch_size, img_height, img_width, 9))\n",
    "    pred_poses = P_Net3(pose_inputs, None, False, 0.05)\n",
    "    \n",
    "    var_pose = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*pose_net.*\")))\n",
    "    pc_pose = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_pose])\n",
    "\n",
    "    \n",
    "with Gf.as_default():  \n",
    "    \n",
    "    flow_inputs1 = tf.random_uniform((batch_size, img_height, img_width, 3))\n",
    "    flow_inputs2 = tf.random_uniform((batch_size, img_height, img_width, 3))\n",
    "    \n",
    "    #Flow\n",
    "    feature_tgt_flow = feature_pyramid_flow(flow_inputs1, reuse=False)\n",
    "    feature_src0_flow = feature_pyramid_flow(flow_inputs2, reuse=True)\n",
    "    flow_fw0 = construct_model_pwc_full(flow_inputs2, flow_inputs1, feature_src0_flow, feature_tgt_flow)\n",
    "    \n",
    "    var_flow = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\".*(flow_net|feature_net_flow).*\")))\n",
    "    pc_flow = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_flow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]  depth size: 13.51259M\n",
      "[Info] encode size: 1.24551M\n",
      "[Info] decode size: 12.26708M\n",
      "[Info] pose size: 3.58978M\n",
      "[Info] flow size: 5.11574M\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=Gd) as sess_d:\n",
    "    print(\"[Info]  depth size: {:.5f}M\".format(sess_d.run(pc_depth)/1000000.0))\n",
    "    print(\"[Info] encode size: {:.5f}M\".format(sess_d.run(pc_enc)/1000000.0))\n",
    "    print(\"[Info] decode size: {:.5f}M\".format(sess_d.run(pc_dec)/1000000.0))\n",
    "    \n",
    "    \n",
    "with tf.Session(graph=Gp) as sess_p:\n",
    "    print(\"[Info] pose size: {:.5f}M\".format(sess_p.run(pc_pose)/1000000.0))\n",
    "    \n",
    "with tf.Session(graph=Gf) as sess_f:\n",
    "    print(\"[Info] flow size: {:.5f}M\".format(sess_f.run(pc_flow)/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPs: 230637565052; Trainable params: 13512590\n",
      "FLOPs: 35033741725; Trainable params: 3589780\n",
      "FLOPs: 330874534472; Trainable params: 5115740\n"
     ]
    }
   ],
   "source": [
    "stats_graph(Gd)\n",
    "stats_graph(Gp)\n",
    "stats_graph(Gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
