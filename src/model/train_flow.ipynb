{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('../kitti_eval/flow_tool/')\n",
    "sys.path.append('..')\n",
    "import flowlib as fl\n",
    "\n",
    "from nets.flow_net import Flow_net\n",
    "\n",
    "from utils.optical_flow_warp_fwd import transformerFwd\n",
    "from utils.optical_flow_warp_old import transformer_old\n",
    "from utils.loss_utils import SSIM, cal_grad2_error\n",
    "from data_loader.data_loader import DataLoader\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import imageio\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus, device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mode\n",
    "mode = \"train_flow\"\n",
    "# mode = \"train_dp\"\n",
    "\n",
    "#是否要載入 pretrain weights\n",
    "LOAD_FLOW_WEIGHT = False\n",
    "LOAD_DEPTH_WEIGHT = False\n",
    "LOAD_POSE_WEIGHT = False\n",
    "\n",
    "if mode == 'train_dp':\n",
    "    LOAD_FLOW_WEIGHT = True\n",
    "\n",
    "# Dataset路徑\n",
    "kitti_depth_folder = '../../../../datasets/kitti_3frames_256_832'\n",
    "\n",
    "\n",
    "\n",
    "# Model Input 解析度設定\n",
    "num_GPU = 4\n",
    "EPOCH = 20\n",
    "PER_BATCH = 8\n",
    "BATCH_SIZE = PER_BATCH * num_GPU\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 832\n",
    "NUM_SCALE = 4\n",
    "NUM_SOURCE = 2\n",
    "\n",
    "# Loss Hyperparameters\n",
    "SSIM_WEIGHT = 0.85\n",
    "FLOW_RECONSTRUCTION_WEIGHT = 0.15\n",
    "FLOW_SMOOTH_WEIGHT = 10.0\n",
    "FLOW_CROSS_GEOMETRY_WEIGHT = 0.3\n",
    "flow_diff_threshold = 4.0\n",
    "flow_consist_weight = 0.01\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "print('[info] Using %d GPUS to speedup' % mirrored_strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(mode=mode, \n",
    "                        dataset_dir=kitti_depth_folder, \n",
    "                        img_height=IMG_HEIGHT, \n",
    "                        img_width=IMG_WIDTH,\n",
    "                        split='train')\n",
    "dataset = dataloader.build_dataloader().shuffle(5000).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    model = Flow_net(input_shape=[IMG_HEIGHT, IMG_WIDTH, 9])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset產生2個內容:三張連續彩色影像(n, h, w, 9), 相機內參(n, 3, 3), n:Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Optimizers and Checkpoint-saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 1e-4\n",
    "with mirrored_strategy.scope():\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_attr = str(BATCH_SIZE) + '_' + str(IMG_HEIGHT) + '_' + str(IMG_WIDTH)\n",
    "checkpoint_dir = os.path.join('../training_checkpoints', mode, checkpoint_attr)\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(flowModel=model, flowOptimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=checkpoint_dir, checkpoint_name='ckpt', max_to_keep=10)\n",
    "\n",
    "# 若LOAD_FLOW_WEIGHT為True，載入Model weight\n",
    "if LOAD_FLOW_WEIGHT:\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show input image, optical flow result and soft occlusion result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, flow, occlusion, epoch, isSave=False, count=0):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    \n",
    "    display_list = [image[:, :, :3], image[:, :, 3:6], \n",
    "                    flow[0].numpy(), flow[1].numpy(), \n",
    "                    occlusion[0].numpy().squeeze(), occlusion[1].numpy().squeeze()]\n",
    "    title = ['Input Image(L)', 'Input Image(M)', \n",
    "             'Optical Flow(FW)', 'Optical Flow(BW)', \n",
    "             'Soft Occlusion(FW)', 'Soft Occlusion(BW)']\n",
    "\n",
    "    for i in range(6):\n",
    "        plt.subplot(3, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        if i < 4:\n",
    "            plt.imshow(display_list[i])\n",
    "        else:\n",
    "            plt.imshow(display_list[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    if isSave:\n",
    "        if not os.path.isdir('./result'):\n",
    "            os.makedirs('./result')\n",
    "        imageio.imwrite('./result/{}_{}_imageL.jpg'.format(epoch, count), image[:, :, :3])\n",
    "        imageio.imwrite('./result/{}_{}_imageM.jpg'.format(epoch, count), image[:, :, 3:6])\n",
    "        imageio.imwrite('./result/{}_{}_flowbw.jpg'.format(epoch, count), flow[1].numpy())\n",
    "        imageio.imwrite('./result/{}_{}_occlusionbw.jpg'.format(epoch, count), occlusion[1].numpy())\n",
    "        imageio.imwrite('./result/{}_{}_flowfw.jpg'.format(epoch, count), flow[0].numpy())\n",
    "        imageio.imwrite('./result/{}_{}_occlusionfw.jpg'.format(epoch, count), occlusion[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit(dataset, epochs):\n",
    "    his_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        #with mirrored_strategy.scope():\n",
    "        optimizer.learning_rate = initial_learning_rate * (0.5**(epoch//5))\n",
    "        total_loss = 0\n",
    "        count = 1\n",
    "        start = time.time()\n",
    "        for image_batch, cam in dataset:\n",
    "\n",
    "            loss = train_step(image_batch)\n",
    "            total_loss += loss.numpy()\n",
    "            if count % 20 == 0:\n",
    "                print('[info] Epoch:{} Count:{} Loss:{} Time:{:.2f} sec'.format(epoch, count, total_loss/count, time.time()-start))\n",
    "#                 show_image(image_batch[0], [flow[0][0], flow[1][0]], [occlusion[0][0], occlusion[1][0]], epoch)\n",
    "                if count % 200 == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    print('[info] Epoch:{} Count:{} Loss:{} Time:{:.2f} sec'.format(epoch, count, total_loss/count, time.time()-start))\n",
    "#                     show_image(image_batch[0], [flow[0][0], flow[1][0]], [occlusion[0][0], occlusion[1][0]], epoch, isSave=True, count=count)\n",
    "                start = time.time()\n",
    "            his_loss.append(total_loss/count)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "        path = ckpt_manager.save(checkpoint_number=epoch)         \n",
    "        print(\"[info] model saved to %s\" % path)\n",
    "\n",
    "\n",
    "\n",
    "    return his_loss\n",
    "    \n",
    "with mirrored_strategy.scope():\n",
    "    # with mirrored_strategy.scope():\n",
    "    def step_fn(inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predict = model(inputs) #training=True\n",
    "            #loss = build_flow_loss(inputs, predict)\n",
    "            loss = model.total_losses\n",
    "\n",
    "        gradients_of_model = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients_of_model, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(images):\n",
    "        per_example_losses = mirrored_strategy.experimental_run_v2(step_fn, args=(images,))\n",
    "        mean_loss = mirrored_strategy.reduce(tf.distribute.ReduceOp.MEAN, per_example_losses, axis=None)\n",
    "    #     mean_loss, flow, occlusion = step_fn(images)\n",
    "        return mean_loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_learning_phase(True)\n",
    "#checkpoint.restore(checkpoint_prefix+'-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = fit(dist_dataset, EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss(his):\n",
    "    ep = len(his)\n",
    "    ep = np.arange(ep)\n",
    "    plt.plot(ep, his)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_loss(his_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_loss(small_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def build_flow_loss(input_images, predict):\n",
    "    tgt_image = input_images[:, :, :, 3:6]\n",
    "    src_image_stack = tf.concat([input_images[:, :, :, :3], input_images[:, :, :, 6:]], axis=3)\n",
    "\n",
    "    pred_fw_flows = predict[:3]\n",
    "    pred_bw_flows = predict[3:]\n",
    "\n",
    "    reconstructed_loss = 0\n",
    "    cross_reconstructed_loss = 0\n",
    "    flow_smooth_loss = 0\n",
    "    cross_flow_smooth_loss = 0\n",
    "    ssim_loss = 0\n",
    "    cross_ssim_loss = 0\n",
    "\n",
    "\n",
    "\n",
    "    curr_tgt_image_all = []\n",
    "    curr_src_image_stack_all = []\n",
    "    occlusion_map_0_all = []\n",
    "    occlusion_map_1_all = []\n",
    "    occlusion_map_2_all = []\n",
    "    occlusion_map_3_all = []\n",
    "    occlusion_map_4_all = []\n",
    "    occlusion_map_5_all = []\n",
    "\n",
    "    # Calculate different scale occulsion maps described in 'Occlusion Aware Unsupervised\n",
    "    # Learning of Optical Flow by Yang Wang et al'\n",
    "    occu_masks_bw = []\n",
    "    occu_masks_bw_avg = []\n",
    "    occu_masks_fw = []\n",
    "    occu_masks_fw_avg = []\n",
    "\n",
    "    for i in range(len(pred_bw_flows)):\n",
    "        temp_occu_masks_bw = []\n",
    "        temp_occu_masks_bw_avg = []\n",
    "        temp_occu_masks_fw = []\n",
    "        temp_occu_masks_fw_avg = []\n",
    "\n",
    "        for s in range(NUM_SCALE):\n",
    "            H = int(IMG_HEIGHT / (2**s))\n",
    "            W = int(IMG_WIDTH  / (2**s))\n",
    "\n",
    "            mask, mask_avg = occulsion(pred_bw_flows[i][s])\n",
    "            temp_occu_masks_bw.append(mask)\n",
    "            temp_occu_masks_bw_avg.append(mask_avg)\n",
    "            # [src0, tgt, src0_1]\n",
    "\n",
    "            mask, mask_avg = occulsion(pred_fw_flows[i][s])\n",
    "            temp_occu_masks_fw.append(mask)\n",
    "            temp_occu_masks_fw_avg.append(mask_avg)\n",
    "            # [tgt, src1, src1_1]\n",
    "\n",
    "        occu_masks_bw.append(temp_occu_masks_bw)\n",
    "        occu_masks_bw_avg.append(temp_occu_masks_bw_avg)\n",
    "        occu_masks_fw.append(temp_occu_masks_fw)\n",
    "        occu_masks_fw_avg.append(temp_occu_masks_fw_avg)\n",
    "\n",
    "    for s in range(NUM_SCALE):\n",
    "        H = int(IMG_HEIGHT / (2**s))\n",
    "        W = int(IMG_WIDTH  / (2**s))\n",
    "        curr_tgt_image = tf.image.resize(\n",
    "            tgt_image, [H, W], method=tf.image.ResizeMethod.BILINEAR)\n",
    "        curr_src_image_stack = tf.image.resize(\n",
    "            src_image_stack, [H, W], method=tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "        curr_tgt_image_all.append(curr_tgt_image)\n",
    "        curr_src_image_stack_all.append(curr_src_image_stack)\n",
    "\n",
    "        # src0\n",
    "        curr_proj_image_optical_src0 = transformer_old(curr_tgt_image, pred_fw_flows[0][s], [H, W])\n",
    "        curr_proj_error_optical_src0 = tf.abs(curr_proj_image_optical_src0 - curr_src_image_stack[:,:,:,0:3])\n",
    "        reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_src0 * occu_masks_bw[0][s]) / occu_masks_bw_avg[0][s]\n",
    "\n",
    "        curr_proj_image_optical_src0_1 = transformer_old(curr_src_image_stack[:,:,:,3:6], pred_fw_flows[2][s], [H, W])\n",
    "        curr_proj_error_optical_src0_1 = tf.abs(curr_proj_image_optical_src0_1 - curr_src_image_stack[:,:,:,0:3])\n",
    "        cross_reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_src0_1 * occu_masks_bw[2][s]) / occu_masks_bw_avg[2][s]\n",
    "\n",
    "        # tgt\n",
    "        curr_proj_image_optical_tgt = transformer_old(curr_src_image_stack[:,:,:,3:6], pred_fw_flows[1][s], [H, W])\n",
    "        curr_proj_error_optical_tgt = tf.abs(curr_proj_image_optical_tgt - curr_tgt_image)\n",
    "        reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_tgt * occu_masks_bw[1][s]) / occu_masks_bw_avg[1][s]\n",
    "\n",
    "        curr_proj_image_optical_tgt_1 = transformer_old(curr_src_image_stack[:,:,:,0:3], pred_bw_flows[0][s], [H, W])\n",
    "        curr_proj_error_optical_tgt_1 = tf.abs(curr_proj_image_optical_tgt_1 - curr_tgt_image)\n",
    "        reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_tgt_1 * occu_masks_fw[0][s]) / occu_masks_fw_avg[0][s]\n",
    "\n",
    "        # src1\n",
    "        curr_proj_image_optical_src1 = transformer_old(curr_tgt_image, pred_bw_flows[1][s], [H, W])\n",
    "        curr_proj_error_optical_src1 = tf.abs(curr_proj_image_optical_src1 - curr_src_image_stack[:,:,:,3:6])\n",
    "        reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_src1 * occu_masks_fw[1][s]) / occu_masks_fw_avg[1][s]\n",
    "\n",
    "        curr_proj_image_optical_src1_1 = transformer_old(curr_src_image_stack[:,:,:,0:3], pred_bw_flows[2][s], [H, W])\n",
    "        curr_proj_error_optical_src1_1 = tf.abs(curr_proj_image_optical_src1_1 - curr_src_image_stack[:,:,:,3:6])\n",
    "        cross_reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_src1_1 * occu_masks_fw[2][s]) / occu_masks_fw_avg[2][s]\n",
    "\n",
    "        if SSIM_WEIGHT > 0:\n",
    "            # src0\n",
    "            ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_src0 * occu_masks_bw[0][s],\n",
    "                     curr_src_image_stack[:,:,:,0:3] * occu_masks_bw[0][s])) / occu_masks_bw_avg[0][s]\n",
    "\n",
    "            cross_ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_src0_1 * occu_masks_bw[2][s],\n",
    "                     curr_src_image_stack[:,:,:,0:3] * occu_masks_bw[2][s])) / occu_masks_bw_avg[2][s]\n",
    "\n",
    "            # tgt\n",
    "            ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_tgt * occu_masks_bw[1][s],\n",
    "                     curr_tgt_image * occu_masks_bw[1][s])) / occu_masks_bw_avg[1][s]\n",
    "\n",
    "            ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_tgt_1 * occu_masks_fw[0][s],\n",
    "                     curr_tgt_image * occu_masks_fw[0][s])) / occu_masks_fw_avg[0][s]\n",
    "\n",
    "            # src1\n",
    "            ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_src1 * occu_masks_fw[1][s],\n",
    "                     curr_src_image_stack[:,:,:,3:6] * occu_masks_fw[1][s])) / occu_masks_fw_avg[1][s]\n",
    "\n",
    "            cross_ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_src1_1 * occu_masks_fw[2][s],\n",
    "                     curr_src_image_stack[:,:,:,3:6] * occu_masks_fw[2][s])) / occu_masks_fw_avg[2][s]\n",
    "\n",
    "        # Compute second-order derivatives for flow smoothness loss\n",
    "        flow_smooth_loss += cal_grad2_error(\n",
    "            pred_fw_flows[0][s] / 20.0, curr_src_image_stack[:,:,:,0:3], 1.0)\n",
    "\n",
    "        flow_smooth_loss += cal_grad2_error(\n",
    "            pred_fw_flows[1][s] / 20.0, curr_tgt_image, 1.0)\n",
    "\n",
    "        cross_flow_smooth_loss += cal_grad2_error(\n",
    "            pred_fw_flows[2][s] / 20.0, curr_src_image_stack[:,:,:,0:3], 1.0)\n",
    "\n",
    "        flow_smooth_loss += cal_grad2_error(\n",
    "            pred_bw_flows[0][s] / 20.0, curr_tgt_image, 1.0)\n",
    "\n",
    "        flow_smooth_loss += cal_grad2_error(\n",
    "            pred_bw_flows[1][s] / 20.0, curr_src_image_stack[:,:,:,3:6], 1.0)\n",
    "\n",
    "        cross_flow_smooth_loss += cal_grad2_error(\n",
    "            pred_bw_flows[2][s] / 20.0, curr_src_image_stack[:,:,:,3:6], 1.0)\n",
    "\n",
    "        # [TODO] Add first-order derivatives for flow smoothness loss\n",
    "        # [TODO] use robust Charbonnier penalty?\n",
    "\n",
    "        if s == 0:\n",
    "            occlusion_map_0_all = occu_masks_bw[0][s]\n",
    "            occlusion_map_1_all = occu_masks_bw[1][s]\n",
    "            occlusion_map_2_all = occu_masks_bw[2][s]\n",
    "            occlusion_map_3_all = occu_masks_fw[0][s]\n",
    "            occlusion_map_4_all = occu_masks_fw[1][s]\n",
    "            occlusion_map_5_all = occu_masks_fw[2][s]\n",
    "\n",
    "    recon_losses = reconstructed_loss + FLOW_CROSS_GEOMETRY_WEIGHT * cross_reconstructed_loss\n",
    "    ssim_losses = ssim_loss + FLOW_CROSS_GEOMETRY_WEIGHT * cross_ssim_loss\n",
    "    smooth_losses = flow_smooth_loss + FLOW_CROSS_GEOMETRY_WEIGHT*cross_flow_smooth_loss\n",
    "\n",
    "    losses = FLOW_RECONSTRUCTION_WEIGHT * recon_losses + \\\n",
    "             SSIM_WEIGHT * ssim_losses + \\\n",
    "             FLOW_SMOOTH_WEIGHT * smooth_losses\n",
    "\n",
    "\n",
    "\n",
    "#     summaries = []\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"total_loss\", losses))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"reconstructed_loss\", reconstructed_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"cross_reconstructed_loss\", cross_reconstructed_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"ssim_loss\", ssim_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"cross_ssim_loss\", cross_ssim_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"flow_smooth_loss\", flow_smooth_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"cross_flow_smooth_loss\", cross_flow_smooth_loss))\n",
    "\n",
    "#     s = 0\n",
    "#     tf.compat.v1.summary.image('scale%d_target_image' % s, tf.image.convert_image_dtype(curr_tgt_image_all[0], dtype=tf.uint8))\n",
    "\n",
    "#     for i in range(NUM_SOURCE):\n",
    "#         tf.compat.v1.summary.image('scale%d_src_image_%d' % (s, i), \\\n",
    "#                         tf.image.convert_image_dtype(curr_src_image_stack_all[0][:, :, :, i*3:(i+1)*3], dtype=tf.uint8))\n",
    "\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_src02tgt' % s, fl.flow_to_color(self.pred_fw_flows[0][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_tgt2src1' % s, fl.flow_to_color(self.pred_fw_flows[1][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_src02src1' % s, fl.flow_to_color(self.pred_fw_flows[2][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_tgt2src0' % s, fl.flow_to_color(self.pred_bw_flows[0][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_src12tgt' % s, fl.flow_to_color(self.pred_bw_flows[1][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_src12src0' % s, fl.flow_to_color(self.pred_bw_flows[2][s], max_flow=256))\n",
    "\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_src0', occlusion_map_0_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_tgt', occlusion_map_1_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_src0_1', occlusion_map_2_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_tgt1', occlusion_map_3_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_src1', occlusion_map_4_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_src1_1', occlusion_map_5_all)\n",
    "\n",
    "#     self.summ_op = tf.compat.v1.summary.merge(summaries)\n",
    "    s = 0\n",
    "    flow = [fl.flow_to_color(pred_fw_flows[0][s], max_flow=256), fl.flow_to_color(pred_bw_flows[0][s], max_flow=256)]\n",
    "    occlusion = [occlusion_map_3_all, occlusion_map_0_all]\n",
    "    return losses\n",
    "\n",
    "\n",
    "def occulsion(pred_flow):\n",
    "    \"\"\"\n",
    "    Here, we compute the soft occlusion maps proposed in https://arxiv.org/pdf/1711.05890.pdf\n",
    "\n",
    "    pred_flow: the estimated forward optical flow\n",
    "    \"\"\"\n",
    "\n",
    "    n, h, w, c = pred_flow.get_shape().as_list()\n",
    "#     transformerFwd = TransformerFwd()\n",
    "    occu_mask = [\n",
    "        tf.clip_by_value(\n",
    "            transformerFwd(\n",
    "                tf.ones(shape=[PER_BATCH, h, w, 1], dtype='float32'),\n",
    "                pred_flow, [h , w], backprop=True),\n",
    "            clip_value_min=0.0,\n",
    "            clip_value_max=1.0)\n",
    "        ]\n",
    "    occu_mask = tf.reshape(occu_mask, [PER_BATCH, h, w, 1])\n",
    "    occu_mask_avg = tf.reduce_mean(input_tensor=occu_mask)\n",
    "\n",
    "    return occu_mask, occu_mask_avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
