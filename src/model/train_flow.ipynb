{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('../kitti_eval/flow_tool/')\n",
    "sys.path.append('..')\n",
    "import flowlib as fl\n",
    "\n",
    "\n",
    "from nets.flow_net import Flow_net\n",
    "\n",
    "from utils.optical_flow_warp_fwd import TransformerFwd\n",
    "from utils.optical_flow_warp_old import transformer_old\n",
    "from utils.loss_utils import SSIM, cal_grad2_error_mask, charbonnier_loss, cal_grad2_error, compute_edge_aware_smooth_loss, ternary_loss, depth_smoothness\n",
    "from utils.utils import average_gradients, normalize_depth_for_display, preprocess_image, deprocess_image, inverse_warp, inverse_warp_new\n",
    "from data_loader.data_loader import DataLoader\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0:2], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#是否要載入 pretrain weights\n",
    "LOAD_DEPTH_WEIGHT = False\n",
    "\n",
    "\n",
    "# 欲載入 pretrain weight 的路徑\n",
    "load_depthWeight_path = '../../models/mnv2_segment_depth_multiloss/origin/PSMNet_DataAug_KITTI_depthCorrection_epoch-49_loss-3.4839.h5'\n",
    "#load_depthWeight_path = '../../models/mnv2_segment_depth_multiloss/log_depth/log_depth4~80_epoch-21_loss-3.8513.h5' # log depth\n",
    "#load_depthWeight_path = '../../models/mnv2_segment_depth_multiloss/224x224/224x224_epoch-39_loss-4.3492.h5'\n",
    "\n",
    "# 儲存 training weight 的路徑\n",
    "save_depthWeight_path = '../../models/mnv2_segment_depth_multiloss/log_depth/'\n",
    "\n",
    "# Dataset路徑\n",
    "kitti_depth_folder = '../../../../datasets/kitti_3frames_256_832'\n",
    "\n",
    "# train mode\n",
    "mode = \"train_flow\"\n",
    "# mode = \"train_dp\"\n",
    "\n",
    "# Model Input 解析度設定\n",
    "EPOCH = 100\n",
    "BATCH_SIZE = 8\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 832\n",
    "NUM_SCALE = 4\n",
    "NUM_SOURCE = 2\n",
    "\n",
    "# Loss Hyperparameters\n",
    "SSIM_WEIGHT = 0.85\n",
    "FLOW_RECONSTRUCTION_WEIGHT = 1.0\n",
    "FLOW_SMOOTH_WEIGHT = 10.0\n",
    "FLOW_CROSS_GEOMETRY_WEIGHT = 0.3\n",
    "flow_diff_threshold = 4.0\n",
    "flow_consist_weight = 0.01\n",
    "\n",
    "\n",
    "initial_learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Flow_net(input_shape=[IMG_HEIGHT, IMG_WIDTH, 9])\n",
    "\n",
    "# 若LOAD_DEPTH_WEIGHT為True，載入Model weight\n",
    "if LOAD_DEPTH_WEIGHT:\n",
    "    model.load_weights(load_depthWeight_path)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(mode=mode, \n",
    "                        dataset_dir=kitti_depth_folder, \n",
    "                        img_height=IMG_HEIGHT, \n",
    "                        img_width=IMG_WIDTH)\n",
    "dataset = dataloader.build_dataloader().batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 設定訓練參數的儲存路徑與方式\n",
    "# model_checkpoint = ModelCheckpoint(filepath=save_depthWeight_path+'log_depth4~80_epoch-{epoch:02d}_loss-{loss:.4f}.h5',\n",
    "#                                    monitor='loss',\n",
    "#                                    verbose=1,\n",
    "#                                    save_best_only=False,\n",
    "#                                    save_weights_only=True,\n",
    "#                 mode='auto',\n",
    "#                                    period=1)\n",
    "\n",
    "# 設定log檔的儲存方式\n",
    "# csv_logger = CSVLogger(filename=save_depthWeight_path+'training_log.csv',\n",
    "#                        separator=',',\n",
    "#                        append=True)\n",
    "\n",
    "# Define the checkpoint directory to store the checkpoints\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "\n",
    "# 設定每個epoch的 learning rate\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00005\n",
    "\n",
    "\n",
    "# 設定當Loss為NaN時停止訓練\n",
    "# terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "# # 設定loss function的callback functions\n",
    "# callbacks = [model_checkpoint,\n",
    "#              csv_logger,\n",
    "#              learning_rate_scheduler,\n",
    "#              terminate_on_nan]\n",
    "\n",
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "                                                      model.optimizer.lr.numpy()))\n",
    "    \n",
    "callbacks = [\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                       save_weights_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "    PrintLR()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 訓練起始 epoch [TODO]\n",
    "initial_epoch=0\n",
    "\n",
    "# 訓練結束 epoch [TODO]\n",
    "final_epoch = 10\n",
    "\n",
    "# 每個 epoch 的 training iteration\n",
    "steps_per_epoch = 1000\n",
    "\n",
    "# 設定每個 loss output 的權重: [depth_pred_2x, depth_pred_4x, depth_pred_8x, depth_pred_16x,seg_pred_2x,seg_pred_4x,seg_pred_8x,seg_pred_16x]\n",
    "loss_weights=[0.25,0.25,0.25,0.25,0.75,0.75,0.75,0.75]\n",
    "\n",
    "# 建立 loss function\n",
    "# depth_loss = custom_depth_loss(depth_weight=1.0, disparity_weight=0.0)\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "model.fit(dataset.take(100), epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    his_loss = []\n",
    "    for epoch in range(2000, 2000+epochs):\n",
    "        total_loss = 0\n",
    "        count = 0\n",
    "        for image_batch, cam in dataset.take(1):\n",
    "            loss, flow, occlusion = train_step(image_batch)\n",
    "            total_loss += loss.numpy()\n",
    "            count += 1\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(image_batch[0][:, :, :3])\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(image_batch[0][:, :, 3:6])\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(flow[0].numpy())\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(occlusion.numpy()[0].squeeze(), cmap='gray')\n",
    "            plt.show()\n",
    "            imageio.imwrite('flow{}.jpg'.format(epoch), flow[0].numpy())\n",
    "            imageio.imwrite('occlusion{}.jpg'.format(epoch), occlusion[0].numpy())\n",
    "        \n",
    "        print('[info] Epoch:{} Loss:{}'.format(epoch, total_loss/count))\n",
    "        his_loss.append(total_loss/count)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    return his_loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        output_model = model(images) #training=True\n",
    "        loss, flow, occlusion = build_flow_loss(images, output_model)\n",
    "\n",
    "    gradients_of_model = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients_of_model, model.trainable_variables))\n",
    "\n",
    "    return loss, flow, occlusion\n",
    "\n",
    "@tf.function\n",
    "def build_flow_loss(input_images, output_model):\n",
    "    tgt_image = input_images[:, :, :, 3:6]\n",
    "    src_image_stack = tf.concat([input_images[:, :, :, :3], input_images[:, :, :, 6:]], axis=3)\n",
    "    \n",
    "    pred_fw_flows = output_model[:3]\n",
    "    pred_bw_flows = output_model[3:]\n",
    "    \n",
    "    reconstructed_loss = 0\n",
    "    cross_reconstructed_loss = 0\n",
    "    flow_smooth_loss = 0\n",
    "    cross_flow_smooth_loss = 0\n",
    "    ssim_loss = 0\n",
    "    cross_ssim_loss = 0\n",
    "\n",
    "    curr_tgt_image_all = []\n",
    "    curr_src_image_stack_all = []\n",
    "    occlusion_map_0_all = []\n",
    "    occlusion_map_1_all = []\n",
    "    occlusion_map_2_all = []\n",
    "    occlusion_map_3_all = []\n",
    "    occlusion_map_4_all = []\n",
    "    occlusion_map_5_all = []\n",
    "\n",
    "    # Calculate different scale occulsion maps described in 'Occlusion Aware Unsupervised\n",
    "    # Learning of Optical Flow by Yang Wang et al'\n",
    "    occu_masks_bw = []\n",
    "    occu_masks_bw_avg = []\n",
    "    occu_masks_fw = []\n",
    "    occu_masks_fw_avg = []\n",
    "\n",
    "    for i in range(len(pred_bw_flows)):\n",
    "        temp_occu_masks_bw = []\n",
    "        temp_occu_masks_bw_avg = []\n",
    "        temp_occu_masks_fw = []\n",
    "        temp_occu_masks_fw_avg = []\n",
    "\n",
    "        for s in range(NUM_SCALE):\n",
    "            H = int(IMG_HEIGHT / (2**s))\n",
    "            W = int(IMG_WIDTH  / (2**s))\n",
    "\n",
    "            mask, mask_avg = occulsion(pred_bw_flows[i][s], H, W)\n",
    "            temp_occu_masks_bw.append(mask)\n",
    "            temp_occu_masks_bw_avg.append(mask_avg)\n",
    "            # [src0, tgt, src0_1]\n",
    "\n",
    "            mask, mask_avg = occulsion(pred_fw_flows[i][s], H, W)\n",
    "            temp_occu_masks_fw.append(mask)\n",
    "            temp_occu_masks_fw_avg.append(mask_avg)\n",
    "            # [tgt, src1, src1_1]\n",
    "\n",
    "        occu_masks_bw.append(temp_occu_masks_bw)\n",
    "        occu_masks_bw_avg.append(temp_occu_masks_bw_avg)\n",
    "        occu_masks_fw.append(temp_occu_masks_fw)\n",
    "        occu_masks_fw_avg.append(temp_occu_masks_fw_avg)\n",
    "\n",
    "    for s in range(NUM_SCALE):\n",
    "        H = int(IMG_HEIGHT / (2**s))\n",
    "        W = int(IMG_WIDTH  / (2**s))\n",
    "        curr_tgt_image = tf.image.resize(\n",
    "            tgt_image, [H, W], method=tf.image.ResizeMethod.BILINEAR)\n",
    "        curr_src_image_stack = tf.image.resize(\n",
    "            src_image_stack, [H, W], method=tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "        curr_tgt_image_all.append(curr_tgt_image)\n",
    "        curr_src_image_stack_all.append(curr_src_image_stack)\n",
    "\n",
    "        # src0\n",
    "        curr_proj_image_optical_src0 = transformer_old(curr_tgt_image, pred_fw_flows[0][s], [H, W])\n",
    "        curr_proj_error_optical_src0 = tf.abs(curr_proj_image_optical_src0 - curr_src_image_stack[:,:,:,0:3])\n",
    "        reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_src0 * occu_masks_bw[0][s]) / occu_masks_bw_avg[0][s]\n",
    "\n",
    "        curr_proj_image_optical_src0_1 = transformer_old(curr_src_image_stack[:,:,:,3:6], pred_fw_flows[2][s], [H, W])\n",
    "        curr_proj_error_optical_src0_1 = tf.abs(curr_proj_image_optical_src0_1 - curr_src_image_stack[:,:,:,0:3])\n",
    "        cross_reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_src0_1 * occu_masks_bw[2][s]) / occu_masks_bw_avg[2][s]\n",
    "\n",
    "        # tgt\n",
    "        curr_proj_image_optical_tgt = transformer_old(curr_src_image_stack[:,:,:,3:6], pred_fw_flows[1][s], [H, W])\n",
    "        curr_proj_error_optical_tgt = tf.abs(curr_proj_image_optical_tgt - curr_tgt_image)\n",
    "        reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_tgt * occu_masks_bw[1][s]) / occu_masks_bw_avg[1][s]\n",
    "\n",
    "        curr_proj_image_optical_tgt_1 = transformer_old(curr_src_image_stack[:,:,:,0:3], pred_bw_flows[0][s], [H, W])\n",
    "        curr_proj_error_optical_tgt_1 = tf.abs(curr_proj_image_optical_tgt_1 - curr_tgt_image)\n",
    "        reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_tgt_1 * occu_masks_fw[0][s]) / occu_masks_fw_avg[0][s]\n",
    "\n",
    "        # src1\n",
    "        curr_proj_image_optical_src1 = transformer_old(curr_tgt_image, pred_bw_flows[1][s], [H, W])\n",
    "        curr_proj_error_optical_src1 = tf.abs(curr_proj_image_optical_src1 - curr_src_image_stack[:,:,:,3:6])\n",
    "        reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_src1 * occu_masks_fw[1][s]) / occu_masks_fw_avg[1][s]\n",
    "\n",
    "        curr_proj_image_optical_src1_1 = transformer_old(curr_src_image_stack[:,:,:,0:3], pred_bw_flows[2][s], [H, W])\n",
    "        curr_proj_error_optical_src1_1 = tf.abs(curr_proj_image_optical_src1_1 - curr_src_image_stack[:,:,:,3:6])\n",
    "        cross_reconstructed_loss += tf.reduce_mean(\n",
    "            input_tensor=curr_proj_error_optical_src1_1 * occu_masks_fw[2][s]) / occu_masks_fw_avg[2][s]\n",
    "\n",
    "        if SSIM_WEIGHT > 0:\n",
    "            # src0\n",
    "            ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_src0 * occu_masks_bw[0][s],\n",
    "                     curr_src_image_stack[:,:,:,0:3] * occu_masks_bw[0][s])) / occu_masks_bw_avg[0][s]\n",
    "\n",
    "            cross_ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_src0_1 * occu_masks_bw[2][s],\n",
    "                     curr_src_image_stack[:,:,:,0:3] * occu_masks_bw[2][s])) / occu_masks_bw_avg[2][s]\n",
    "\n",
    "            # tgt\n",
    "            ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_tgt * occu_masks_bw[1][s],\n",
    "                     curr_tgt_image * occu_masks_bw[1][s])) / occu_masks_bw_avg[1][s]\n",
    "\n",
    "            ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_tgt_1 * occu_masks_fw[0][s],\n",
    "                     curr_tgt_image * occu_masks_fw[0][s])) / occu_masks_fw_avg[0][s]\n",
    "\n",
    "            # src1\n",
    "            ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_src1 * occu_masks_fw[1][s],\n",
    "                     curr_src_image_stack[:,:,:,3:6] * occu_masks_fw[1][s])) / occu_masks_fw_avg[1][s]\n",
    "\n",
    "            cross_ssim_loss += tf.reduce_mean(\n",
    "                input_tensor=SSIM(curr_proj_image_optical_src1_1 * occu_masks_fw[2][s],\n",
    "                     curr_src_image_stack[:,:,:,3:6] * occu_masks_fw[2][s])) / occu_masks_fw_avg[2][s]\n",
    "\n",
    "        # Compute second-order derivatives for flow smoothness loss\n",
    "        flow_smooth_loss += cal_grad2_error(\n",
    "            pred_fw_flows[0][s] / 20.0, curr_src_image_stack[:,:,:,0:3], 1.0)\n",
    "\n",
    "        flow_smooth_loss += cal_grad2_error(\n",
    "            pred_fw_flows[1][s] / 20.0, curr_tgt_image, 1.0)\n",
    "\n",
    "        cross_flow_smooth_loss += cal_grad2_error(\n",
    "            pred_fw_flows[2][s] / 20.0, curr_src_image_stack[:,:,:,0:3], 1.0)\n",
    "\n",
    "        flow_smooth_loss += cal_grad2_error(\n",
    "            pred_bw_flows[0][s] / 20.0, curr_tgt_image, 1.0)\n",
    "\n",
    "        flow_smooth_loss += cal_grad2_error(\n",
    "            pred_bw_flows[1][s] / 20.0, curr_src_image_stack[:,:,:,3:6], 1.0)\n",
    "\n",
    "        cross_flow_smooth_loss += cal_grad2_error(\n",
    "            pred_bw_flows[2][s] / 20.0, curr_src_image_stack[:,:,:,3:6], 1.0)\n",
    "\n",
    "        # [TODO] Add first-order derivatives for flow smoothness loss\n",
    "        # [TODO] use robust Charbonnier penalty?\n",
    "\n",
    "        if s == 0:\n",
    "            occlusion_map_0_all = occu_masks_bw[0][s]\n",
    "            occlusion_map_1_all = occu_masks_bw[1][s]\n",
    "            occlusion_map_2_all = occu_masks_bw[2][s]\n",
    "            occlusion_map_3_all = occu_masks_fw[0][s]\n",
    "            occlusion_map_4_all = occu_masks_fw[1][s]\n",
    "            occlusion_map_5_all = occu_masks_fw[2][s]\n",
    "\n",
    "    losses = FLOW_RECONSTRUCTION_WEIGHT * ((1.0 - SSIM_WEIGHT) * \\\n",
    "                  (reconstructed_loss + FLOW_CROSS_GEOMETRY_WEIGHT*cross_reconstructed_loss) + \\\n",
    "                    SSIM_WEIGHT*(ssim_loss+FLOW_CROSS_GEOMETRY_WEIGHT*cross_ssim_loss)) + \\\n",
    "                  FLOW_SMOOTH_WEIGHT * (flow_smooth_loss + FLOW_CROSS_GEOMETRY_WEIGHT*cross_flow_smooth_loss)\n",
    "\n",
    "\n",
    "    \n",
    "#     summaries = []\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"total_loss\", losses))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"reconstructed_loss\", reconstructed_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"cross_reconstructed_loss\", cross_reconstructed_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"ssim_loss\", ssim_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"cross_ssim_loss\", cross_ssim_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"flow_smooth_loss\", flow_smooth_loss))\n",
    "#     summaries.append(tf.compat.v1.summary.scalar(\"cross_flow_smooth_loss\", cross_flow_smooth_loss))\n",
    "\n",
    "#     s = 0\n",
    "#     tf.compat.v1.summary.image('scale%d_target_image' % s, tf.image.convert_image_dtype(curr_tgt_image_all[0], dtype=tf.uint8))\n",
    "\n",
    "#     for i in range(NUM_SOURCE):\n",
    "#         tf.compat.v1.summary.image('scale%d_src_image_%d' % (s, i), \\\n",
    "#                         tf.image.convert_image_dtype(curr_src_image_stack_all[0][:, :, :, i*3:(i+1)*3], dtype=tf.uint8))\n",
    "\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_src02tgt' % s, fl.flow_to_color(self.pred_fw_flows[0][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_tgt2src1' % s, fl.flow_to_color(self.pred_fw_flows[1][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_src02src1' % s, fl.flow_to_color(self.pred_fw_flows[2][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_tgt2src0' % s, fl.flow_to_color(self.pred_bw_flows[0][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_src12tgt' % s, fl.flow_to_color(self.pred_bw_flows[1][s], max_flow=256))\n",
    "#     tf.compat.v1.summary.image('scale%d_flow_src12src0' % s, fl.flow_to_color(self.pred_bw_flows[2][s], max_flow=256))\n",
    "\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_src0', occlusion_map_0_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_tgt', occlusion_map_1_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_src0_1', occlusion_map_2_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_tgt1', occlusion_map_3_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_src1', occlusion_map_4_all)\n",
    "#     tf.compat.v1.summary.image('scale_flyout_mask_src1_1', occlusion_map_5_all)\n",
    "\n",
    "#     self.summ_op = tf.compat.v1.summary.merge(summaries)\n",
    "    s = 0\n",
    "    flow = fl.flow_to_color(pred_fw_flows[0][s], max_flow=256)\n",
    "    occlusion = occlusion_map_0_all\n",
    "    return losses, flow, occlusion\n",
    "\n",
    "def occulsion(pred_flow, H, W):\n",
    "    \"\"\"\n",
    "    Here, we compute the soft occlusion maps proposed in https://arxiv.org/pdf/1711.05890.pdf\n",
    "\n",
    "    pred_flow: the estimated forward optical flow\n",
    "    \"\"\"\n",
    "    transformerFwd = TransformerFwd()\n",
    "    occu_mask = [\n",
    "        tf.clip_by_value(\n",
    "            transformerFwd(\n",
    "                tf.ones(shape=[BATCH_SIZE, H, W, 1], dtype='float32'),\n",
    "                pred_flow, [H , W], backprop=True),\n",
    "            clip_value_min=0.0,\n",
    "            clip_value_max=1.0)\n",
    "        ]\n",
    "    occu_mask = tf.reshape(occu_mask, [BATCH_SIZE, H, W, 1])\n",
    "    occu_mask_avg = tf.reduce_mean(input_tensor=occu_mask)\n",
    "\n",
    "    return occu_mask, occu_mask_avg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_learning_phase(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = train(dataset, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show flow and occlusion mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(his)\n",
    "x = np.arange(x)\n",
    "plt.plot(x, his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in his:\n",
    "    temp.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(temp)\n",
    "x = np.arange(x)\n",
    "plt.plot(x, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "flow = tf.random.uniform((1,256,832,3), 0, 1)\n",
    "occlusion = tf.random.uniform((1,256,832,1), 0, 1)\n",
    "\n",
    "print('[info] flow:', flow.shape)\n",
    "print('[info] occlusion:', occlusion.shape)\n",
    "plt.figure(figsize=(20, 50))\n",
    "plt.subplot(121)\n",
    "plt.imshow(flow[0].numpy())\n",
    "plt.subplot(122)\n",
    "plt.imshow(occlusion.numpy()[0].squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
