{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from data_loader.data_loader import DataLoader\n",
    "import tensorflow as tf\n",
    "from nets.depth_net import D_Net\n",
    "from nets.flow_net import feature_pyramid_flow, construct_model_pwc_full\n",
    "from nets.pose_net import P_Net3\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select one or several free gpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "# use CPU only\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_graph(graph):\n",
    "    flops = tf.profiler.profile(graph,\n",
    "    options=tf.profiler.ProfileOptionBuilder.float_operation())\n",
    "    params = tf.profiler.profile(graph,    options=tf.profiler.ProfileOptionBuilder.trainable_variables_parameter())\n",
    "    print(\"FLOPs: {}; Trainable params: {}\".format(flops.total_float_ops, params.total_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleNetV2():\n",
    "\n",
    "    first_conv_channel = 24\n",
    "    \n",
    "    def __init__(self, input_holder, var_scope, model_scale=1.0, shuffle_group=2, is_training=True):\n",
    "        self.input = input_holder\n",
    "        self.output = None\n",
    "        self.shuffle_group = shuffle_group\n",
    "        self.channel_sizes = self._select_channel_size(model_scale)\n",
    "        self.var_scope = var_scope\n",
    "        self.is_training = is_training\n",
    "\n",
    "    def _select_channel_size(self, model_scale):\n",
    "        # [(out_channel, repeat_times), (out_channel, repeat_times), ...]\n",
    "        if model_scale == 0.5:\n",
    "            return [(48, 4), (96, 8), (192, 4), (1024, 1)]\n",
    "        elif model_scale == 1.0:\n",
    "            return [(116, 4), (232, 8), (464, 4), (1024, 1)]\n",
    "        elif model_scale == 1.5:\n",
    "            return [(176, 4), (352, 8), (704, 4), (1024, 1)]\n",
    "        elif model_scale == 2.0:\n",
    "            return [(244, 4), (488, 8), (976, 4), (2048, 1)]\n",
    "        else:\n",
    "            raise ValueError('Unsupported model size.')\n",
    "\n",
    "    def build_model(self):\n",
    "        with tf.variable_scope(self.var_scope) as sc:\n",
    "            with slim.arg_scope([slim.batch_norm], is_training=self.is_training):\n",
    "                skip = []\n",
    "                with tf.variable_scope('encoding'):\n",
    "                    with tf.variable_scope('init_block'):\n",
    "                        out = conv_bn_relu(self.input, self.first_conv_channel, 3, 2)\n",
    "                        skip.append(out)\n",
    "                        out = slim.max_pool2d(skip[0], 3, 2, padding='SAME')\n",
    "                        skip.append(out)\n",
    "                    for idx, block in enumerate(self.channel_sizes[:-1]):\n",
    "                        with tf.variable_scope('shuffle_block_{}'.format(idx)):\n",
    "                            out_channel, repeat = block\n",
    "\n",
    "                            # First block is downsampling\n",
    "                            out = shufflenet_v2_block(out, out_channel, 3, 2, shuffle_group=self.shuffle_group)\n",
    "\n",
    "                            # Rest blocks\n",
    "                            for i in range(repeat-1):\n",
    "                                out = shufflenet_v2_block(out, out_channel, 3, shuffle_group=self.shuffle_group)\n",
    "\n",
    "                            skip.append(out)\n",
    "\n",
    "\n",
    "                    with tf.variable_scope('end_block'):\n",
    "                        out = conv_bn_relu(out, self.channel_sizes[-1][0], 1)\n",
    "                        skip.append(out)\n",
    "\n",
    "                with tf.variable_scope('decoding'):\n",
    "                    # DECODING\n",
    "                    upconv6 = upconv(skip[5],   512, 3, 2) #H/32\n",
    "                    upconv6 = resize_like(upconv6, skip[4])\n",
    "                    concat6 = tf.concat([upconv6, skip[4]], 3)\n",
    "                    iconv6  = conv(concat6,   512, 3, 1)\n",
    "\n",
    "                    upconv5 = upconv(iconv6, 256, 3, 2) #H/16\n",
    "                    upconv5 = resize_like(upconv5, skip[3])\n",
    "                    concat5 = tf.concat([upconv5, skip[3]], 3)\n",
    "                    iconv5  = conv(concat5,   256, 3, 1)\n",
    "\n",
    "                    upconv4 = upconv(iconv5,  128, 3, 2) #H/8\n",
    "                    upconv4 = resize_like(upconv4, skip[2])\n",
    "                    concat4 = tf.concat([upconv4, skip[2]], 3)\n",
    "                    iconv4  = conv(concat4,   128, 3, 1)\n",
    "                    pred4 = get_pred(iconv4)\n",
    "                    upred4  = upsample_nn(pred4, 2)\n",
    "\n",
    "                    upconv3 = upconv(iconv4,   64, 3, 2) #H/4\n",
    "                    concat3 = tf.concat([upconv3, skip[1], upred4], 3)\n",
    "                    iconv3  = conv(concat3,    64, 3, 1)\n",
    "                    pred3 = get_pred(iconv3)\n",
    "                    upred3  = upsample_nn(pred3, 2)\n",
    "\n",
    "                    upconv2 = upconv(iconv3,   32, 3, 2) #H/2\n",
    "                    concat2 = tf.concat([upconv2, skip[0], upred3], 3)\n",
    "                    iconv2  = conv(concat2,    32, 3, 1)\n",
    "                    pred2 = get_pred(iconv2)\n",
    "                    upred2  = upsample_nn(pred2, 2)\n",
    "\n",
    "                    upconv1 = upconv(iconv2,  16, 3, 2) #H\n",
    "                    concat1 = tf.concat([upconv1, upred2], 3)\n",
    "                    iconv1  = conv(concat1,   16, 3, 1)\n",
    "                    pred1 = get_pred(iconv1)\n",
    "\n",
    "                    return [pred1, pred2, pred3, pred4], skip[5]\n",
    "\n",
    "                # with tf.variable_scope('prediction'):\n",
    "                #     out = global_avg_pool2D(out)\n",
    "                #     out = slim.conv2d(out, self.cls, 1, activation_fn=None, biases_initializer=None)\n",
    "                #     out = tf.reshape(out, shape=[-1, self.cls])\n",
    "                #     out = tf.identity(out, name='cls_prediction')\n",
    "                #     self.output = out\n",
    "\n",
    "def shuffle_unit(x, groups):\n",
    "    with tf.variable_scope('shuffle_unit'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "        x = tf.reshape(x, shape=tf.convert_to_tensor([tf.shape(x)[0], h, w, groups, c // groups]))\n",
    "        x = tf.transpose(x, tf.convert_to_tensor([0, 1, 2, 4, 3]))\n",
    "        x = tf.reshape(x, shape=tf.convert_to_tensor([tf.shape(x)[0], h, w, c]))\n",
    "    return x\n",
    "\n",
    "def conv_bn_relu(x, out_channel, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'conv_bn_relu'):\n",
    "        x = slim.conv2d(x, out_channel, kernel_size, stride, rate=dilation,\n",
    "                        biases_initializer=None, activation_fn=None)\n",
    "        x = slim.batch_norm(x, activation_fn=tf.nn.relu, fused=False)\n",
    "    return x\n",
    "\n",
    "def conv_bn(x, out_channel, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'conv_bn'):\n",
    "        x = slim.conv2d(x, out_channel, kernel_size, stride, rate=dilation,\n",
    "                        biases_initializer=None, activation_fn=None)\n",
    "        x = slim.batch_norm(x, activation_fn=None, fused=False)\n",
    "    return x\n",
    "\n",
    "def depthwise_conv_bn(x, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'depthwise_conv_bn'):\n",
    "        x = slim.separable_conv2d(x, None, kernel_size, depth_multiplier=1, stride=stride,\n",
    "                                  rate=dilation, activation_fn=None, biases_initializer=None)\n",
    "        x = slim.batch_norm(x, activation_fn=None, fused=False)\n",
    "    return x\n",
    "\n",
    "def resolve_shape(x):\n",
    "    with tf.variable_scope(None, 'resolve_shape'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "        if h is None or w is None:\n",
    "            kernel_size = tf.convert_to_tensor([tf.shape(x)[1], tf.shape(x)[2]])\n",
    "        else:\n",
    "            kernel_size = [h, w]\n",
    "    return kernel_size\n",
    "\n",
    "def global_avg_pool2D(x):\n",
    "    with tf.variable_scope(None, 'global_pool2D'):\n",
    "        kernel_size = resolve_shape(x)\n",
    "        x = slim.avg_pool2d(x, kernel_size, stride=1)\n",
    "        x.set_shape([None, 1, 1, None])\n",
    "    return x\n",
    "\n",
    "def se_unit(x, bottleneck=2):\n",
    "    with tf.variable_scope(None, 'SE_module'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "\n",
    "        kernel_size = resolve_shape(x)\n",
    "        x_pool = slim.avg_pool2d(x, kernel_size, stride=1)\n",
    "        x_pool = tf.reshape(x_pool, shape=[-1, c])\n",
    "        fc = slim.fully_connected(x_pool, bottleneck, activation_fn=tf.nn.relu,\n",
    "                                  biases_initializer=None)\n",
    "        fc = slim.fully_connected(fc, c, activation_fn=tf.nn.sigmoid,\n",
    "                                  biases_initializer=None)\n",
    "        if n is None:\n",
    "            channel_w = tf.reshape(fc, shape=tf.convert_to_tensor([tf.shape(x)[0], 1, 1, c]))\n",
    "        else:\n",
    "            channel_w = tf.reshape(fc, shape=[n, 1, 1, c])\n",
    "\n",
    "        x = tf.multiply(x, channel_w)\n",
    "    return x\n",
    "\n",
    "def shufflenet_v2_block(x, out_channel, kernel_size, stride=1, dilation=1, shuffle_group=2):\n",
    "    with tf.variable_scope(None, 'shuffle_v2_block'):\n",
    "        if stride == 1:\n",
    "            top, bottom = tf.split(x, num_or_size_splits=2, axis=3)\n",
    "\n",
    "            half_channel = out_channel // 2\n",
    "\n",
    "            top = conv_bn_relu(top, half_channel, 1)\n",
    "            top = depthwise_conv_bn(top, kernel_size, stride, dilation)\n",
    "            top = conv_bn_relu(top, half_channel, 1)\n",
    "\n",
    "            out = tf.concat([top, bottom], axis=3)\n",
    "            out = shuffle_unit(out, shuffle_group)\n",
    "\n",
    "        else:\n",
    "            half_channel = out_channel // 2\n",
    "            b0 = conv_bn_relu(x, half_channel, 1)\n",
    "            b0 = depthwise_conv_bn(b0, kernel_size, stride, dilation)\n",
    "            b0 = conv_bn_relu(b0, half_channel, 1)\n",
    "\n",
    "            b1 = depthwise_conv_bn(x, kernel_size, stride, dilation)\n",
    "            b1 = conv_bn_relu(b1, half_channel, 1)\n",
    "\n",
    "            out = tf.concat([b0, b1], axis=3)\n",
    "            out = shuffle_unit(out, shuffle_group)\n",
    "        return out\n",
    "    \n",
    "\n",
    "def resize_like(inputs, ref):\n",
    "    iH, iW = inputs.get_shape()[1], inputs.get_shape()[2]\n",
    "    rH, rW = ref.get_shape()[1], ref.get_shape()[2]\n",
    "    if iH == rH and iW == rW:\n",
    "        return inputs\n",
    "    return tf.image.resize_nearest_neighbor(inputs, [rH.value, rW.value])\n",
    "\n",
    "def upconv(x, num_out_layers, kernel_size, scale):\n",
    "    upsample = upsample_nn(x, scale)\n",
    "    cnv = conv(upsample, num_out_layers, kernel_size, 1)\n",
    "    return cnv\n",
    "\n",
    "def upsample_nn(x, ratio):\n",
    "    h = x.get_shape()[1].value\n",
    "    w = x.get_shape()[2].value\n",
    "    return tf.image.resize_nearest_neighbor(x, [h * ratio, w * ratio])\n",
    "\n",
    "def conv(x, num_out_layers, kernel_size, stride, activation_fn=tf.nn.elu, normalizer_fn=slim.batch_norm):\n",
    "    p = np.floor((kernel_size - 1) / 2).astype(np.int32)\n",
    "    p_x = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], mode='REFLECT')\n",
    "    return slim.conv2d(p_x, num_out_layers, kernel_size, stride, 'VALID', activation_fn=activation_fn, normalizer_fn=normalizer_fn)\n",
    "\n",
    "def maxpool(x, kernel_size):\n",
    "    p = np.floor((kernel_size - 1) / 2).astype(np.int32)\n",
    "    p_x = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], mode='REFLECT')\n",
    "    return slim.max_pool2d(p_x, kernel_size)\n",
    "\n",
    "def get_pred(x):\n",
    "    disp = 5 * conv(x, 1, 3, 1, activation_fn=tf.nn.sigmoid, normalizer_fn=None) + 0.01\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gd=tf.Graph()\n",
    "Gp=tf.Graph()\n",
    "Gf=tf.Graph()\n",
    "\n",
    "with Gd.as_default():\n",
    "    loader = DataLoader(dataset_dir='../datasets/kitti_3frames_128_416',\n",
    "                                img_height=128,\n",
    "                                img_width=416,\n",
    "                                batch_size=8,\n",
    "                                num_scales=4,\n",
    "                                num_source=2,\n",
    "                                ext='jpg',\n",
    "                                mode='train_dp')\n",
    "    \n",
    "    image_stack, image_stack_norm, proj_cam2pix, proj_pix2cam = loader.load_train_batch()\n",
    "    tgt_image = image_stack[:, :, :, 3:6]\n",
    "    src0_image = image_stack[:, :, :, 0:3]\n",
    "    src1_image = image_stack[:, :, :, 6:9]\n",
    "    src_image_stack = tf.concat([src0_image, src1_image], axis=3)\n",
    "\n",
    "    tgt_image_norm = image_stack_norm[:, :, :, 3:6]\n",
    "    src0_image_norm = image_stack_norm[:, :, :, 0:3]\n",
    "    src1_image_norm = image_stack_norm[:, :, :, 6:9]\n",
    "    src_image_stack_norm = tf.concat([src0_image_norm, src1_image_norm], axis=3)\n",
    "    \n",
    "    #Depth\n",
    "#     tgt_pred_disp, tgt_disp_bottlenecks = D_Net(tgt_image_norm, weight_reg=0.05, is_training=True, reuse=False)\n",
    "    D_Model = ShuffleNetV2(input_holder=tgt_image_norm, \n",
    "                           var_scope='depth_net', \n",
    "                           model_scale=1.0, \n",
    "                           shuffle_group=2, \n",
    "                           is_training=True)\n",
    "    tgt_pred_disp, tgt_disp_bottlenecks = D_Model.build_model()\n",
    "    \n",
    "    #Get layers\n",
    "    var_depth = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*(depth_net|feature_net_disp).*\")))\n",
    "    var_enc = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*encoding.*\")))\n",
    "    var_dec = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*decoding.*\")))\n",
    "    #Get param\n",
    "    pc_depth = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_depth])\n",
    "    pc_enc = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_enc])\n",
    "    pc_dec = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_dec])\n",
    "    \n",
    "with Gp.as_default():    \n",
    "    loader = DataLoader(dataset_dir='../datasets/kitti_3frames_128_416',\n",
    "                                img_height=128,\n",
    "                                img_width=416,\n",
    "                                batch_size=8,\n",
    "                                num_scales=4,\n",
    "                                num_source=2,\n",
    "                                ext='jpg',\n",
    "                                mode='train_dp')\n",
    "    \n",
    "    image_stack, image_stack_norm, proj_cam2pix, proj_pix2cam = loader.load_train_batch()\n",
    "    tgt_image = image_stack[:, :, :, 3:6]\n",
    "    src0_image = image_stack[:, :, :, 0:3]\n",
    "    src1_image = image_stack[:, :, :, 6:9]\n",
    "    src_image_stack = tf.concat([src0_image, src1_image], axis=3)\n",
    "\n",
    "    tgt_image_norm = image_stack_norm[:, :, :, 3:6]\n",
    "    src0_image_norm = image_stack_norm[:, :, :, 0:3]\n",
    "    src1_image_norm = image_stack_norm[:, :, :, 6:9]\n",
    "    src_image_stack_norm = tf.concat([src0_image_norm, src1_image_norm], axis=3)\n",
    "    \n",
    "    \n",
    "    #Pose\n",
    "    pose_inputs = tf.concat([src_image_stack_norm[:,:,:,0:3], tgt_image_norm, src_image_stack_norm[:,:,:,3:6]], axis=3)\n",
    "    pred_poses = P_Net3(pose_inputs, None, False, 0.05)\n",
    "    var_pose = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*pose_net.*\")))\n",
    "    pc_pose = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_pose])\n",
    "    \n",
    "    config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "    sessp = tf.Session(config=config)\n",
    "    \n",
    "    pc_p = sessp.run(pc_pose)\n",
    "    \n",
    "    \n",
    "with Gf.as_default():  \n",
    "    loader = DataLoader(dataset_dir='../datasets/kitti_3frames_128_416',\n",
    "                                img_height=128,\n",
    "                                img_width=416,\n",
    "                                batch_size=8,\n",
    "                                num_scales=4,\n",
    "                                num_source=2,\n",
    "                                ext='jpg',\n",
    "                                mode='train_dp')\n",
    "    \n",
    "    image_stack, image_stack_norm, proj_cam2pix, proj_pix2cam = loader.load_train_batch()\n",
    "    tgt_image = image_stack[:, :, :, 3:6]\n",
    "    src0_image = image_stack[:, :, :, 0:3]\n",
    "    src1_image = image_stack[:, :, :, 6:9]\n",
    "    src_image_stack = tf.concat([src0_image, src1_image], axis=3)\n",
    "\n",
    "    tgt_image_norm = image_stack_norm[:, :, :, 3:6]\n",
    "    src0_image_norm = image_stack_norm[:, :, :, 0:3]\n",
    "    src1_image_norm = image_stack_norm[:, :, :, 6:9]\n",
    "    src_image_stack_norm = tf.concat([src0_image_norm, src1_image_norm], axis=3)\n",
    "    #Flow\n",
    "    feature_tgt_flow = feature_pyramid_flow(tgt_image_norm, reuse=False)\n",
    "    feature_src0_flow = feature_pyramid_flow(src_image_stack_norm[:,:,:,0:3], reuse=True)\n",
    "    flow_fw0 = construct_model_pwc_full(src_image_stack_norm[:,:,:,0:3], tgt_image_norm, feature_src0_flow, feature_tgt_flow)\n",
    "    \n",
    "    var_flow = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*(flow_net|feature_net_flow).*\")))\n",
    "    pc_flow = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_flow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=Gd) as sess_d:\n",
    "    print(\"[Info]  depth size: {:.5f}M\".format(sess_d.run(pc_depth)/1000000.0))\n",
    "    print(\"[Info] encode size: {:.5f}M\".format(sess_d.run(pc_enc)/1000000.0))\n",
    "    print(\"[Info] decode size: {:.5f}M\".format(sess_d.run(pc_dec)/1000000.0))\n",
    "    \n",
    "    \n",
    "with tf.Session(graph=Gp) as sess_p:\n",
    "    print(\"[Info] pose size: {:.5f}M\".format(sess_p.run(pc_pose)/1000000.0))\n",
    "    \n",
    "with tf.Session(graph=Gf) as sess_f:\n",
    "    print(\"[Info] flow size: {:.5f}M\".format(sess_f.run(pc_flow)/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_graph(Gd)\n",
    "stats_graph(Gp)\n",
    "stats_graph(Gf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test other parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISP_SCALING_RESNET50 = 5\n",
    "def build_resnet50(inputs, get_pred, is_training, var_scope, weight_reg=0.0001, reuse=False):\n",
    "    batch_norm_params = {'is_training': is_training}\n",
    "    with tf.variable_scope(var_scope) as sc:\n",
    "        if reuse:\n",
    "            sc.reuse_variables()\n",
    "        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                            normalizer_fn=slim.batch_norm,\n",
    "                            normalizer_params=batch_norm_params,\n",
    "                            weights_regularizer=slim.l2_regularizer(weight_reg),\n",
    "                            activation_fn=tf.nn.elu):\n",
    "            with tf.variable_scope('encoding'):\n",
    "                conv1 = conv(inputs, 64, 7, 2)      # H/2  -   64D\n",
    "                pool1 = maxpool(conv1,           3) # H/4  -   64D\n",
    "                conv2 = resblock(pool1,      64, 3) # H/8  -  256D\n",
    "                conv3 = resblock(conv2,     128, 4) # H/16 -  512D\n",
    "                conv4 = resblock(conv3,     256, 6) # H/32 - 1024D\n",
    "                conv5 = resblock(conv4,     512, 3) # H/64 - 2048D\n",
    "\n",
    "                skip1 = conv1\n",
    "                skip2 = pool1\n",
    "                skip3 = conv2\n",
    "                skip4 = conv3\n",
    "                skip5 = conv4\n",
    "            \n",
    "#             # DECODING\n",
    "#             with tf.variable_scope('decoding'):\n",
    "#                 upconv6 = upconv(conv5,   512, 3, 2) #H/32\n",
    "#                 upconv6 = resize_like(upconv6, skip5)\n",
    "#                 concat6 = tf.concat([upconv6, skip5], 3)\n",
    "#                 iconv6  = conv(concat6,   512, 3, 1)\n",
    "\n",
    "#                 upconv5 = upconv(iconv6, 256, 3, 2) #H/16\n",
    "#                 upconv5 = resize_like(upconv5, skip4)\n",
    "#                 concat5 = tf.concat([upconv5, skip4], 3)\n",
    "#                 iconv5  = conv(concat5,   256, 3, 1)\n",
    "\n",
    "#                 upconv4 = upconv(iconv5,  128, 3, 2) #H/8\n",
    "#                 upconv4 = resize_like(upconv4, skip3)\n",
    "#                 concat4 = tf.concat([upconv4, skip3], 3)\n",
    "#                 iconv4  = conv(concat4,   128, 3, 1)\n",
    "#                 pred4 = get_pred(iconv4)\n",
    "#                 upred4  = upsample_nn(pred4, 2)\n",
    "\n",
    "#                 upconv3 = upconv(iconv4,   64, 3, 2) #H/4\n",
    "#                 concat3 = tf.concat([upconv3, skip2, upred4], 3)\n",
    "#                 iconv3  = conv(concat3,    64, 3, 1)\n",
    "#                 pred3 = get_pred(iconv3)\n",
    "#                 upred3  = upsample_nn(pred3, 2)\n",
    "\n",
    "#                 upconv2 = upconv(iconv3,   32, 3, 2) #H/2\n",
    "#                 concat2 = tf.concat([upconv2, skip1, upred3], 3)\n",
    "#                 iconv2  = conv(concat2,    32, 3, 1)\n",
    "#                 pred2 = get_pred(iconv2)\n",
    "#                 upred2  = upsample_nn(pred2, 2)\n",
    "\n",
    "#                 upconv1 = upconv(iconv2,  16, 3, 2) #H\n",
    "#                 concat1 = tf.concat([upconv1, upred2], 3)\n",
    "#                 iconv1  = conv(concat1,   16, 3, 1)\n",
    "#                 pred1 = get_pred(iconv1)\n",
    "\n",
    "            return skip5\n",
    "\n",
    "def get_disp_resnet50(x):\n",
    "    disp = DISP_SCALING_RESNET50 * conv(x, 1, 3, 1, activation_fn=tf.nn.sigmoid, normalizer_fn=None) + 0.01\n",
    "    return disp\n",
    "\n",
    "def resblock(x, num_layers, num_blocks):\n",
    "    out = x\n",
    "    for i in range(num_blocks - 1):\n",
    "        out = resconv(out, num_layers, 1)\n",
    "    out = resconv(out, num_layers, 2)\n",
    "    return out\n",
    "\n",
    "def resconv(x, num_layers, stride):\n",
    "    # Actually here exists a bug: tf.shape(x)[3] != num_layers is always true,\n",
    "    # but we preserve it here for consistency with Godard's implementation.\n",
    "    do_proj = tf.shape(x)[3] != num_layers or stride == 2\n",
    "    shortcut = []\n",
    "    conv1 = conv(x,         num_layers, 1, 1)\n",
    "    conv2 = conv(conv1,     num_layers, 3, stride)\n",
    "    conv3 = conv(conv2, 4 * num_layers, 1, 1, None)\n",
    "    if do_proj:\n",
    "        shortcut = conv(x, 4 * num_layers, 1, stride, None)\n",
    "    else:\n",
    "        shortcut = x\n",
    "    return tf.nn.elu(conv3 + shortcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gtest=tf.Graph()\n",
    "with Gtest.as_default():\n",
    "    loader = DataLoader(dataset_dir='../datasets/kitti_3frames_128_416',\n",
    "                                img_height=128,\n",
    "                                img_width=416,\n",
    "                                batch_size=8,\n",
    "                                num_scales=4,\n",
    "                                num_source=2,\n",
    "                                ext='jpg',\n",
    "                                mode='train_dp')\n",
    "    \n",
    "    image_stack, image_stack_norm, proj_cam2pix, proj_pix2cam = loader.load_train_batch()\n",
    "    tgt_image = image_stack[:, :, :, 3:6]\n",
    "    src0_image = image_stack[:, :, :, 0:3]\n",
    "    src1_image = image_stack[:, :, :, 6:9]\n",
    "    src_image_stack = tf.concat([src0_image, src1_image], axis=3)\n",
    "\n",
    "    tgt_image_norm = image_stack_norm[:, :, :, 3:6]\n",
    "    src0_image_norm = image_stack_norm[:, :, :, 0:3]\n",
    "    src1_image_norm = image_stack_norm[:, :, :, 6:9]\n",
    "    src_image_stack_norm = tf.concat([src0_image_norm, src1_image_norm], axis=3)\n",
    "    \n",
    "    #Depth\n",
    "#     tgt_pred_disp, tgt_disp_bottlenecks = D_Net(tgt_image_norm, weight_reg=0.05, is_training=True, reuse=False)\n",
    "    skip = build_resnet50(tgt_image_norm, get_disp_resnet50, is_training=True, var_scope='depth_net', reuse=False)\n",
    "#     D_Model = ShuffleNetV2(input_holder=tgt_image_norm, \n",
    "#                            var_scope='depth_net', \n",
    "#                            model_scale=1.0, \n",
    "#                            shuffle_group=2, \n",
    "#                            is_training=True)\n",
    "#     tgt_pred_disp, tgt_disp_bottlenecks = D_Model.build_model()\n",
    "    \n",
    "    #Get layers\n",
    "    var_depth = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*(depth_net|feature_net_disp).*\")))\n",
    "    var_enc = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*encoding.*\")))\n",
    "    var_dec = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*decoding.*\")))\n",
    "    #Get param\n",
    "    pc_depth = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_depth])\n",
    "    pc_enc = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_enc])\n",
    "    pc_dec = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]  depth size: 38.04173M\n",
      "[Info] encode size: 38.04173M\n",
      "[Info] decode size: 0.00000M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4 ops no flops stats due to incomplete shapes.\n",
      "4 ops no flops stats due to incomplete shapes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPs: 88737443928; Trainable params: 38041728\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=Gtest) as sess_d:\n",
    "    print(\"[Info]  depth size: {:.5f}M\".format(sess_d.run(pc_depth)/1000000.0))\n",
    "    print(\"[Info] encode size: {:.5f}M\".format(sess_d.run(pc_enc)/1000000.0))\n",
    "    print(\"[Info] decode size: {:.5f}M\".format(sess_d.run(pc_dec)/1000000.0))\n",
    "stats_graph(Gtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5_tf1.9",
   "language": "python",
   "name": "python3.5_tf1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
