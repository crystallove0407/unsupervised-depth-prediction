{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from data_loader.data_loader import DataLoader\n",
    "import tensorflow as tf\n",
    "# from nets.depth_net import D_Net\n",
    "from nets.flow_net import feature_pyramid_flow, construct_model_pwc_full\n",
    "# from nets.pose_net import P_Net3\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select one or several free gpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "# use CPU only\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_graph(graph):\n",
    "    flops = tf.profiler.profile(graph,\n",
    "    options=tf.profiler.ProfileOptionBuilder.float_operation())\n",
    "    params = tf.profiler.profile(graph,    options=tf.profiler.ProfileOptionBuilder.trainable_variables_parameter())\n",
    "    print(\"FLOPs: {}; Trainable params: {}\".format(flops.total_float_ops, params.total_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleNetV2():\n",
    "\n",
    "    first_conv_channel = 24\n",
    "    \n",
    "    def __init__(self, input_holder, var_scope, model_scale=1.0, shuffle_group=2, is_training=True):\n",
    "        self.input = input_holder\n",
    "        self.output = None\n",
    "        self.shuffle_group = shuffle_group\n",
    "        self.channel_sizes = self._select_channel_size(model_scale)\n",
    "        self.var_scope = var_scope\n",
    "        self.is_training = is_training\n",
    "\n",
    "    def _select_channel_size(self, model_scale):\n",
    "        # [(out_channel, repeat_times), (out_channel, repeat_times), ...]\n",
    "        if model_scale == 0.5:\n",
    "            return [(48, 4), (96, 8), (192, 4), (1024, 1)]\n",
    "        elif model_scale == 1.0:\n",
    "            return [(116, 4), (232, 8), (464, 4), (1024, 1)]\n",
    "        elif model_scale == 1.5:\n",
    "            return [(176, 4), (352, 8), (704, 4), (1024, 1)]\n",
    "        elif model_scale == 2.0:\n",
    "            return [(244, 4), (488, 8), (976, 4), (2048, 1)]\n",
    "        else:\n",
    "            raise ValueError('Unsupported model size.')\n",
    "\n",
    "    def build_model(self):\n",
    "        with tf.variable_scope(self.var_scope) as sc:\n",
    "            with slim.arg_scope([slim.batch_norm], is_training=self.is_training):\n",
    "                skip = []\n",
    "                with tf.variable_scope('encoding'):\n",
    "                    with tf.variable_scope('init_block'):\n",
    "                        out = conv_bn_relu(self.input, self.first_conv_channel, 3, 2)\n",
    "                        skip.append(out)\n",
    "                        out = slim.max_pool2d(skip[0], 3, 2, padding='SAME')\n",
    "                        skip.append(out)\n",
    "                        \n",
    "                    for idx, block in enumerate(self.channel_sizes[:-1]):\n",
    "                        with tf.variable_scope('shuffle_block_{}'.format(idx)):\n",
    "                            out_channel, repeat = block\n",
    "\n",
    "                            # First block is downsampling\n",
    "                            print(\"[Downsample] out, out_channel:\", out.shape[-1], out_channel)\n",
    "                            out = shufflenet_v2_block(out, out_channel, 3, 2, shuffle_group=self.shuffle_group)\n",
    "\n",
    "                            # Rest blocks\n",
    "                            for i in range(repeat-1):\n",
    "                                print(\"[Rest] out, out_channel:\", out.shape[-1], out_channel)\n",
    "                                out = shufflenet_v2_block(out, out_channel, 3, shuffle_group=self.shuffle_group)\n",
    "\n",
    "                            skip.append(out)\n",
    "\n",
    "\n",
    "                    with tf.variable_scope('end_block'):\n",
    "                        out = conv_bn_relu(out, self.channel_sizes[-1][0], 1)\n",
    "                        skip.append(out)\n",
    "                for idx, sk in enumerate(skip):\n",
    "                    print(\"skip[%d]:\" % idx, sk.shape)\n",
    "                with tf.variable_scope('decoding'):\n",
    "                    # DECODING\n",
    "                    upconv6 = upconv_sep(skip[5],   512, 3, 2) #H/32\n",
    "                    upconv6 = resize_like(upconv6, skip[4])\n",
    "                    concat6 = tf.concat([upconv6, skip[4]], 3)\n",
    "#                     iconv6  = conv(concat6,   512, 3, 1)\n",
    "                    iconv6  = shufflenet_v2_block(concat6, 512, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "        \n",
    "                    upconv5 = upconv_sep(iconv6, 256, 3, 2) #H/16\n",
    "                    upconv5 = resize_like(upconv5, skip[3])\n",
    "                    concat5 = tf.concat([upconv5, skip[3]], 3)\n",
    "#                     iconv5  = conv(concat5,   256, 3, 1)\n",
    "                    iconv5  = shufflenet_v2_block(concat5, 256, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "        \n",
    "                    upconv4 = upconv_sep(iconv5,  128, 3, 2) #H/8\n",
    "                    upconv4 = resize_like(upconv4, skip[2])\n",
    "                    concat4 = tf.concat([upconv4, skip[2]], 3)\n",
    "#                     iconv4  = conv(concat4,   128, 3, 1)\n",
    "                    iconv4  = shufflenet_v2_block(concat4, 128, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "                    pred4 = get_pred(iconv4)\n",
    "                    upred4  = upsample_nn(pred4, 2)\n",
    "\n",
    "                    upconv3 = upconv_sep(iconv4,   64, 3, 2) #H/4\n",
    "                    concat3 = tf.concat([upconv3, skip[1], upred4], 3)\n",
    "#                     iconv3  = conv(concat3,    64, 3, 1)\n",
    "                    iconv3  = shufflenet_v2_block(concat3, 64, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "                    pred3 = get_pred(iconv3)\n",
    "                    upred3  = upsample_nn(pred3, 2)\n",
    "\n",
    "                    upconv2 = upconv_sep(iconv3,   32, 3, 2) #H/2\n",
    "                    concat2 = tf.concat([upconv2, skip[0], upred3], 3)\n",
    "#                     iconv2  = conv(concat2,    32, 3, 1)\n",
    "                    iconv2  = shufflenet_v2_block(concat2, 32, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "                    pred2 = get_pred(iconv2)\n",
    "                    upred2  = upsample_nn(pred2, 2)\n",
    "\n",
    "                    upconv1 = upconv_sep(iconv2,  16, 3, 2) #H\n",
    "                    concat1 = tf.concat([upconv1, upred2], 3)\n",
    "#                     iconv1  = conv(concat1,   16, 3, 1)\n",
    "                    iconv1  = shufflenet_v2_block(concat1, 16, 3, stride=1, dilation=1, shuffle_group=2)\n",
    "                    pred1 = get_pred(iconv1)\n",
    "\n",
    "                    return [pred1, pred2, pred3, pred4], skip[5]\n",
    "\n",
    "                # with tf.variable_scope('prediction'):\n",
    "                #     out = global_avg_pool2D(out)\n",
    "                #     out = slim.conv2d(out, self.cls, 1, activation_fn=None, biases_initializer=None)\n",
    "                #     out = tf.reshape(out, shape=[-1, self.cls])\n",
    "                #     out = tf.identity(out, name='cls_prediction')\n",
    "                #     self.output = out\n",
    "\n",
    "def shuffle_unit(x, groups):\n",
    "    with tf.variable_scope('shuffle_unit'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "        if c % groups == 0:\n",
    "            x = tf.reshape(x, shape=tf.convert_to_tensor([tf.shape(x)[0], h, w, groups, c // groups]))\n",
    "            x = tf.transpose(x, tf.convert_to_tensor([0, 1, 2, 4, 3]))\n",
    "            x = tf.reshape(x, shape=tf.convert_to_tensor([tf.shape(x)[0], h, w, c]))\n",
    "    return x\n",
    "\n",
    "def conv_bn_relu(x, out_channel, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'conv_bn_relu'):\n",
    "        x = slim.conv2d(x, out_channel, kernel_size, stride, rate=dilation,\n",
    "                        biases_initializer=None, activation_fn=None)\n",
    "        x = slim.batch_norm(x, activation_fn=tf.nn.relu, fused=False)\n",
    "    return x\n",
    "\n",
    "def conv_bn(x, out_channel, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'conv_bn'):\n",
    "        x = slim.conv2d(x, out_channel, kernel_size, stride, rate=dilation,\n",
    "                        biases_initializer=None, activation_fn=None)\n",
    "        x = slim.batch_norm(x, activation_fn=None, fused=False)\n",
    "    return x\n",
    "\n",
    "def depthwise_conv_bn(x, kernel_size, stride=1, dilation=1):\n",
    "    with tf.variable_scope(None, 'depthwise_conv_bn'):\n",
    "        x = slim.separable_conv2d(x, None, kernel_size, depth_multiplier=1, stride=stride,\n",
    "                                  rate=dilation, activation_fn=None, biases_initializer=None)\n",
    "        x = slim.batch_norm(x, activation_fn=None, fused=False)\n",
    "    return x\n",
    "\n",
    "def resolve_shape(x):\n",
    "    with tf.variable_scope(None, 'resolve_shape'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "        if h is None or w is None:\n",
    "            kernel_size = tf.convert_to_tensor([tf.shape(x)[1], tf.shape(x)[2]])\n",
    "        else:\n",
    "            kernel_size = [h, w]\n",
    "    return kernel_size\n",
    "\n",
    "def global_avg_pool2D(x):\n",
    "    with tf.variable_scope(None, 'global_pool2D'):\n",
    "        kernel_size = resolve_shape(x)\n",
    "        x = slim.avg_pool2d(x, kernel_size, stride=1)\n",
    "        x.set_shape([None, 1, 1, None])\n",
    "    return x\n",
    "\n",
    "def se_unit(x, bottleneck=2):\n",
    "    with tf.variable_scope(None, 'SE_module'):\n",
    "        n, h, w, c = x.get_shape().as_list()\n",
    "\n",
    "        kernel_size = resolve_shape(x)\n",
    "        x_pool = slim.avg_pool2d(x, kernel_size, stride=1)\n",
    "        x_pool = tf.reshape(x_pool, shape=[-1, c])\n",
    "        fc = slim.fully_connected(x_pool, bottleneck, activation_fn=tf.nn.relu,\n",
    "                                  biases_initializer=None)\n",
    "        fc = slim.fully_connected(fc, c, activation_fn=tf.nn.sigmoid,\n",
    "                                  biases_initializer=None)\n",
    "        if n is None:\n",
    "            channel_w = tf.reshape(fc, shape=tf.convert_to_tensor([tf.shape(x)[0], 1, 1, c]))\n",
    "        else:\n",
    "            channel_w = tf.reshape(fc, shape=[n, 1, 1, c])\n",
    "\n",
    "        x = tf.multiply(x, channel_w)\n",
    "    return x\n",
    "\n",
    "def shufflenet_v2_block(x, out_channel, kernel_size, stride=1, dilation=1, shuffle_group=2):\n",
    "    with tf.variable_scope(None, 'shuffle_v2_block'):\n",
    "        if stride == 1 and x.shape[-1] == out_channel:\n",
    "#             if x.shape[-1] != out_channel:\n",
    "#                 x = conv_bn_relu(x, out_channel, 1)\n",
    "                \n",
    "            top, bottom = tf.split(x, num_or_size_splits=2, axis=3)\n",
    "\n",
    "            half_channel = out_channel // 2\n",
    "\n",
    "            top = conv_bn_relu(top, half_channel, 1)\n",
    "            top = depthwise_conv_bn(top, kernel_size, stride, dilation)\n",
    "            top = conv_bn_relu(top, half_channel, 1)\n",
    "\n",
    "            out = tf.concat([top, bottom], axis=3)\n",
    "\n",
    "            out = shuffle_unit(out, shuffle_group)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            half_channel = out_channel // 2\n",
    "            b0 = conv_bn_relu(x, half_channel, 1)\n",
    "            b0 = depthwise_conv_bn(b0, kernel_size, stride, dilation)\n",
    "            b0 = conv_bn_relu(b0, half_channel, 1)\n",
    "\n",
    "            b1 = depthwise_conv_bn(x, kernel_size, stride, dilation)\n",
    "            b1 = conv_bn_relu(b1, half_channel, 1)\n",
    "\n",
    "            out = tf.concat([b0, b1], axis=3)\n",
    "            out = shuffle_unit(out, shuffle_group)\n",
    "       \n",
    "        return out\n",
    "    \n",
    "\n",
    "def resize_like(inputs, ref):\n",
    "    iH, iW = inputs.get_shape()[1], inputs.get_shape()[2]\n",
    "    rH, rW = ref.get_shape()[1], ref.get_shape()[2]\n",
    "    if iH == rH and iW == rW:\n",
    "        return inputs\n",
    "    return tf.image.resize_nearest_neighbor(inputs, [rH.value, rW.value])\n",
    "\n",
    "def upconv(x, num_out_layers, kernel_size, scale):\n",
    "    upsample = upsample_nn(x, scale)\n",
    "    cnv = conv(upsample, num_out_layers, kernel_size, 1)\n",
    "    return cnv\n",
    "\n",
    "def upsample_nn(x, ratio):\n",
    "    h = x.get_shape()[1].value\n",
    "    w = x.get_shape()[2].value\n",
    "    return tf.image.resize_nearest_neighbor(x, [h * ratio, w * ratio])\n",
    "\n",
    "def upconv_sep(x, num_out_layers, kernel_size, scale):\n",
    "    upsample = upsample_nn(x, scale)\n",
    "#     cnv = conv(upsample, num_out_layers, kernel_size, 1)\n",
    "    cnv  = shufflenet_v2_block(upsample, num_out_layers, kernel_size, stride=1, dilation=1, shuffle_group=2)\n",
    "    return cnv\n",
    "\n",
    "def conv(x, num_out_layers, kernel_size, stride, activation_fn=tf.nn.elu, normalizer_fn=slim.batch_norm):\n",
    "    p = np.floor((kernel_size - 1) / 2).astype(np.int32)\n",
    "    p_x = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], mode='REFLECT')\n",
    "    return slim.conv2d(p_x, num_out_layers, kernel_size, stride, 'VALID', activation_fn=activation_fn, normalizer_fn=normalizer_fn)\n",
    "\n",
    "def maxpool(x, kernel_size):\n",
    "    p = np.floor((kernel_size - 1) / 2).astype(np.int32)\n",
    "    p_x = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], mode='REFLECT')\n",
    "    return slim.max_pool2d(p_x, kernel_size)\n",
    "\n",
    "def get_pred(x):\n",
    "    disp = 5 * conv(x, 1, 3, 1, activation_fn=tf.nn.sigmoid, normalizer_fn=None) + 0.01\n",
    "    return disp\n",
    "\n",
    "# def Separable(x, in_channels, out_channels, stride=1, is_training=True,\n",
    "#         scope='separable'):\n",
    "#     with tf.variable_scope(scope):\n",
    "#         # Diagonalwise Refactorization\n",
    "#         # groups = in_channels\n",
    "#         # groups = 16\n",
    "#         groups = max(in_channels / 32, 1)\n",
    "#         x = DiagonalwiseRefactorization(x, in_channels, stride, groups,\n",
    "#                                         is_training, 'depthwise')\n",
    "\n",
    "#         # Specialized Kernel\n",
    "#         # x = Depthwise(x, in_channels, stride, is_training, 'depthwise')\n",
    "\n",
    "#         # Standard Convolution\n",
    "#         # x = Conv3x3(x, in_channels, in_channels, stride, is_training,\n",
    "#                     # 'convolution')\n",
    "#         x = Pointwise(x, in_channels, out_channels, is_training, 'pointwise')\n",
    "#         return x\n",
    "\n",
    "# def Pointwise(x, in_channels, out_channels, is_training=True,\n",
    "#         scope='pointwise'):\n",
    "#     with tf.variable_scope(scope):\n",
    "#         w = tf.get_variable('weights', (1, 1, in_channels, out_channels),\n",
    "#                             initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         x = tf.nn.conv2d(x, w, (1, 1, 1, 1), 'SAME', data_format='NCHW')\n",
    "#         x = tf.contrib.layers.batch_norm(x, center=True, scale=True,\n",
    "#                                          data_format='NCHW', fused=True,\n",
    "#                                          is_training=is_training)\n",
    "#         x = tf.nn.relu(x)\n",
    "#         return x\n",
    "\n",
    "# def DiagonalwiseRefactorization(x, in_channels, stride=1, groups=4,\n",
    "#         is_training=True, scope='depthwise'):\n",
    "#     with tf.variable_scope(scope):\n",
    "#         channels = in_channels / groups\n",
    "#         mask = tf.constant(get_mask(channels).tolist(), dtype=tf.float32,\n",
    "#                            shape=(3, 3, channels, channels))\n",
    "#         splitw = [\n",
    "#             tf.get_variable('weights_%d' % _, (3, 3, channels, channels),\n",
    "#                             initializer=tf.contrib.layers.xavier_initializer())\n",
    "#             for _ in range(groups)\n",
    "#         ]\n",
    "#         splitw = [tf.multiply(w, mask) for w in splitw]\n",
    "#         splitx = tf.split(x, groups, 1)\n",
    "#         splitx = [tf.nn.conv2d(x, w, (1, 1, stride, stride), 'SAME',\n",
    "#                                data_format='NCHW')\n",
    "#                   for x, w in zip(splitx, splitw)]\n",
    "#         x = tf.concat(splitx, 1)\n",
    "#         x = tf.contrib.layers.batch_norm(x, center=True, scale=True,\n",
    "#                                          data_format='NCHW', fused=True,\n",
    "#                                          is_training=is_training)\n",
    "#         x = tf.nn.relu(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_Net3(image_stack, disp_bottleneck_stack, joint_encoder, weight_reg=0.0004):\n",
    "    with tf.variable_scope('pose_net') as sc:\n",
    "        end_points_collection = sc.original_name_scope + '_end_points'\n",
    "        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],\n",
    "                          normalizer_fn=None,\n",
    "                          weights_regularizer=slim.l2_regularizer(weight_reg),\n",
    "                          normalizer_params=None,\n",
    "                          activation_fn=tf.nn.relu,\n",
    "                          outputs_collections=end_points_collection):\n",
    "            if not joint_encoder:\n",
    "                cnv1 = slim.conv2d(image_stack, 16, [7, 7], stride=2, scope='cnv1')\n",
    "                cnv1b = slim.conv2d(cnv1, 16, [7, 7], stride=1, scope='cnv1b')\n",
    "                cnv2 = slim.conv2d(cnv1b, 32, [5, 5], stride=2, scope='cnv2')\n",
    "                cnv2b = slim.conv2d(cnv2, 32, [5, 5], stride=1, scope='cnv2b')\n",
    "                cnv3 = slim.conv2d(cnv2b, 64, [3, 3], stride=2, scope='cnv3')\n",
    "                cnv3b = slim.conv2d(cnv3, 64, [3, 3], stride=1, scope='cnv3b')\n",
    "                cnv4 = slim.conv2d(cnv3b, 128, [3, 3], stride=2, scope='cnv4')\n",
    "                cnv4b = slim.conv2d(cnv4, 128, [3, 3], stride=1, scope='cnv4b')\n",
    "                cnv5 = slim.conv2d(cnv4b, 256, [3, 3], stride=2, scope='cnv5')\n",
    "                cnv5b = slim.conv2d(cnv5, 256, [3, 3], stride=1, scope='cnv5b')\n",
    "\n",
    "            inputs = disp_bottleneck_stack if joint_encoder else cnv5b\n",
    "\n",
    "            # Pose specific layers\n",
    "            cnv6 = slim.conv2d(inputs, 256, [3, 3], stride=2, scope='cnv6')\n",
    "            cnv6b = slim.conv2d(cnv6, 256, [3, 3], stride=1, scope='cnv6b')\n",
    "            cnv7 = slim.conv2d(cnv6b, 256, [3, 3], stride=2, scope='cnv7')\n",
    "            cnv7b = slim.conv2d(cnv7, 256, [3, 3], stride=1, scope='cnv7b')\n",
    "\n",
    "            pose_pred = slim.conv2d(\n",
    "                cnv7b,\n",
    "                6*6, [1, 1],\n",
    "                scope='pred',\n",
    "                stride=1,\n",
    "                normalizer_fn=None,\n",
    "                activation_fn=None)\n",
    "            pose_avg = tf.reduce_mean(pose_pred, [1, 2])\n",
    "            pose_final = tf.reshape(pose_avg, [-1, 1, 6*6])\n",
    "\n",
    "            tran_mag = 0.001 if joint_encoder else 1.0\n",
    "            rot_mag= 0.01\n",
    "\n",
    "            pose_final = tf.concat(\n",
    "                [tran_mag * pose_final[:, :, 0:3],   rot_mag * pose_final[:, :, 3:6],    # 0: src0 -> tgt\n",
    "                 tran_mag * pose_final[:, :, 6:9],   rot_mag * pose_final[:, :, 9:12],   # 1: tgt -> src1\n",
    "                 tran_mag * pose_final[:, :, 12:15], rot_mag * pose_final[:, :, 15:18],  # 2: src0 -> src1\n",
    "                 tran_mag * pose_final[:, :, 18:21], rot_mag * pose_final[:, :, 21:24],  # 3: tgt -> src0\n",
    "                 tran_mag * pose_final[:, :, 24:27], rot_mag * pose_final[:, :, 27:30],  # 4: src1 -> tgt\n",
    "                 tran_mag * pose_final[:, :, 30:33], rot_mag * pose_final[:, :, 33:36]], # 5: src1 -> src0\n",
    "                axis=2)\n",
    "\n",
    "            return pose_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Downsample] out, out_channel: 24 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Downsample] out, out_channel: 116 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Downsample] out, out_channel: 232 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "skip[0]: (8, 128, 416, 24)\n",
      "skip[1]: (8, 64, 208, 24)\n",
      "skip[2]: (8, 32, 104, 116)\n",
      "skip[3]: (8, 16, 52, 232)\n",
      "skip[4]: (8, 8, 26, 464)\n",
      "skip[5]: (8, 8, 26, 1024)\n",
      "(8, 256, 832, 16)\n"
     ]
    }
   ],
   "source": [
    "Gd=tf.Graph()\n",
    "Gp=tf.Graph()\n",
    "Gf=tf.Graph()\n",
    "\n",
    "batch_size = 8\n",
    "img_height = 256\n",
    "img_width = 832\n",
    "\n",
    "with Gd.as_default():\n",
    "    depth_inputs = tf.random_uniform((batch_size, img_height, img_width, 3))\n",
    "\n",
    "#     tgt_pred_disp, tgt_disp_bottlenecks = D_Net(depth_inputs, weight_reg=0.05, is_training=True, reuse=False)\n",
    "    D_Model = ShuffleNetV2(input_holder=depth_inputs, \n",
    "                           var_scope='depth_net', \n",
    "                           model_scale=1.0, \n",
    "                           shuffle_group=2, \n",
    "                           is_training=True)\n",
    "    tgt_pred_disp, tgt_disp_bottlenecks = D_Model.build_model()\n",
    "    \n",
    "    #Get layers\n",
    "    var_depth = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*(depth_net|feature_net_disp).*\")))\n",
    "    var_enc = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*encoding.*\")))\n",
    "    var_dec = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*decoding.*\")))\n",
    "    #Get param\n",
    "    pc_depth = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_depth])\n",
    "    pc_enc = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_enc])\n",
    "    pc_dec = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_dec])\n",
    "    \n",
    "with Gp.as_default():    \n",
    "    pose_inputs = tf.random_uniform((batch_size, img_height, img_width, 9))\n",
    "    pred_poses = P_Net3(pose_inputs, None, False, 0.05)\n",
    "    \n",
    "    var_pose = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*pose_net.*\")))\n",
    "    pc_pose = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_pose])\n",
    "\n",
    "    \n",
    "with Gf.as_default():  \n",
    "    \n",
    "    flow_inputs1 = tf.random_uniform((batch_size, img_height, img_width, 3))\n",
    "    flow_inputs2 = tf.random_uniform((batch_size, img_height, img_width, 3))\n",
    "    \n",
    "    #Flow\n",
    "    feature_tgt_flow = feature_pyramid_flow(flow_inputs1, reuse=False)\n",
    "    feature_src0_flow = feature_pyramid_flow(flow_inputs2, reuse=True)\n",
    "    flow_fw0 = construct_model_pwc_full(flow_inputs2, flow_inputs1, feature_src0_flow, feature_tgt_flow)\n",
    "    \n",
    "    var_flow = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\".*(flow_net|feature_net_flow).*\")))\n",
    "    pc_flow = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in var_flow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]  depth size: 2.83692M\n",
      "[Info] encode size: 1.24551M\n",
      "[Info] decode size: 1.59140M\n",
      "[Info] pose size: 3.58978M\n",
      "[Info] flow size: 5.11574M\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=Gd) as sess_d:\n",
    "    print(\"[Info]  depth size: {:.5f}M\".format(sess_d.run(pc_depth)/1000000.0))\n",
    "    print(\"[Info] encode size: {:.5f}M\".format(sess_d.run(pc_enc)/1000000.0))\n",
    "    print(\"[Info] decode size: {:.5f}M\".format(sess_d.run(pc_dec)/1000000.0))\n",
    "    \n",
    "    \n",
    "with tf.Session(graph=Gp) as sess_p:\n",
    "    print(\"[Info] pose size: {:.5f}M\".format(sess_p.run(pc_pose)/1000000.0))\n",
    "    \n",
    "with tf.Session(graph=Gf) as sess_f:\n",
    "    print(\"[Info] flow size: {:.5f}M\".format(sess_f.run(pc_flow)/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_graph(Gd)\n",
    "stats_graph(Gp)\n",
    "stats_graph(Gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5_tf1.9",
   "language": "python",
   "name": "python3.5_tf1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
