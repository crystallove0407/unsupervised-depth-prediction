{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 選擇使用的GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select one or several free gpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "# use CPU only\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 到當前資料夾\n",
    "- cd C:/Users/Garin/Desktop/學長畢業資料/實驗程式yu/\n",
    "\n",
    "## 3. 同步程式\n",
    "### - local -> server\n",
    "- scp -r -P 2222 ./config garin@140.113.214.40:/home/garin/Documents/depth/\n",
    "- scp -r -P 2222 ./src garin@140.113.214.40:/home/garin/Documents/depth/\n",
    "\n",
    "### - server -> local \n",
    "- scp -r -P 2222 garin@140.113.214.40:/home/garin/Documents/depth/config .\n",
    "- scp -r -P 2222 garin@140.113.214.40:/home/garin/Documents/depth/src ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_preparation/kitti_data_prepare.py \\\n",
    "--dataset_dir=/home/mjchiu/Documents/darknet-depth/dataset/KITTI/image/ \\\n",
    "--dataset_name=kitti_raw_eigen \\\n",
    "--dump_root=/home/garin/Documents/depth/datasets/kitti_3frames_256_832/ \\\n",
    "--seq_length=3 \\\n",
    "--img_height=256 \\\n",
    "--img_width=832 \\\n",
    "--num_threads=16 \\\n",
    "--remove_static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./main.py -c ../config/flow3.ini -t train_flow --cont_model=../results/KITTI_RAW_128_416_UnDepthflow_flow_pwc_b8_3frames/checkpoints/kitti_3frames/model-170987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train depth & pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./main.py -c ../config/dp3.ini -t train_dp \\\n",
    "--restore_flow_model=../results/KITTI_RAW_256_832_UnDepthflow_flow_pwc_b8_3frames/checkpoints/kitti_3frames/model-392302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### continue training depth and pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Loading the model for 3 frames...\n",
      "[Info] Building depth and pose network ...\n",
      "[Info] img_height: 256 img_width 832\n",
      "[Info] Building depth and pose network ...\n",
      "[Info] img_height: 256 img_width 832\n",
      "[Info] Model size: 6.42670M\n",
      "[Info] Continue training. Restoreing: ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-40237\n",
      "INFO:tensorflow:Restoring parameters from ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-40237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-40237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 5] [    5/10059] total steps:[ 40241] lr:[0.00010000] time: 626.24s (626s total) loss: 140.839\n",
      "Epoch: [ 5] [   15/10059] total steps:[ 40251] lr:[0.00010000] time: 97.07s (723s total) loss: 113.184\n",
      "Epoch: [ 5] [   25/10059] total steps:[ 40261] lr:[0.00010000] time: 67.04s (790s total) loss: 181.558\n",
      "Epoch: [ 5] [   35/10059] total steps:[ 40271] lr:[0.00010000] time: 45.61s (835s total) loss: 178.848\n",
      "Epoch: [ 5] [   45/10059] total steps:[ 40281] lr:[0.00010000] time: 42.39s (878s total) loss: 206.756\n",
      "Epoch: [ 5] [   55/10059] total steps:[ 40291] lr:[0.00010000] time: 33.21s (911s total) loss: 172.879\n",
      "Epoch: [ 5] [   65/10059] total steps:[ 40301] lr:[0.00010000] time: 239.57s (1151s total) loss: 171.485\n",
      "Epoch: [ 5] [   75/10059] total steps:[ 40311] lr:[0.00010000] time: 26.73s (1177s total) loss: 223.368\n",
      "Epoch: [ 5] [   85/10059] total steps:[ 40321] lr:[0.00010000] time: 22.62s (1200s total) loss: 152.167\n",
      "Epoch: [ 5] [   95/10059] total steps:[ 40331] lr:[0.00010000] time: 22.08s (1222s total) loss: 206.723\n",
      "Epoch: [ 5] [  105/10059] total steps:[ 40341] lr:[0.00010000] time: 19.22s (1241s total) loss: 158.528\n",
      "Epoch: [ 5] [  115/10059] total steps:[ 40351] lr:[0.00010000] time: 18.47s (1260s total) loss: 217.367\n",
      "Epoch: [ 5] [  125/10059] total steps:[ 40361] lr:[0.00010000] time: 17.06s (1277s total) loss: 147.651\n",
      "Epoch: [ 5] [  135/10059] total steps:[ 40371] lr:[0.00010000] time: 16.58s (1293s total) loss: 139.147\n",
      "Epoch: [ 5] [  145/10059] total steps:[ 40381] lr:[0.00010000] time: 15.24s (1309s total) loss: 192.033\n",
      "Epoch: [ 5] [  155/10059] total steps:[ 40391] lr:[0.00010000] time: 15.37s (1324s total) loss: 171.321\n",
      "Epoch: [ 5] [  165/10059] total steps:[ 40401] lr:[0.00010000] time: 15.06s (1339s total) loss: 141.448\n",
      "Epoch: [ 5] [  175/10059] total steps:[ 40411] lr:[0.00010000] time: 15.13s (1354s total) loss: 131.333\n",
      "Epoch: [ 5] [  185/10059] total steps:[ 40421] lr:[0.00010000] time: 15.23s (1369s total) loss: 187.823\n",
      "Epoch: [ 5] [  195/10059] total steps:[ 40431] lr:[0.00010000] time: 15.03s (1384s total) loss: 112.609\n",
      "Epoch: [ 5] [  205/10059] total steps:[ 40441] lr:[0.00010000] time: 14.84s (1399s total) loss: 146.715\n",
      "Epoch: [ 5] [  215/10059] total steps:[ 40451] lr:[0.00010000] time: 15.01s (1414s total) loss: 176.389\n",
      "Epoch: [ 5] [  225/10059] total steps:[ 40461] lr:[0.00010000] time: 15.14s (1429s total) loss: 134.440\n",
      "Epoch: [ 5] [  235/10059] total steps:[ 40471] lr:[0.00010000] time: 15.26s (1445s total) loss: 139.216\n",
      "Epoch: [ 5] [  245/10059] total steps:[ 40481] lr:[0.00010000] time: 15.29s (1460s total) loss: 251.184\n",
      "Epoch: [ 5] [  255/10059] total steps:[ 40491] lr:[0.00010000] time: 15.38s (1475s total) loss: 163.327\n",
      "Epoch: [ 5] [  265/10059] total steps:[ 40501] lr:[0.00010000] time: 15.08s (1490s total) loss: 125.819\n",
      "Epoch: [ 5] [  275/10059] total steps:[ 40511] lr:[0.00010000] time: 15.17s (1506s total) loss: 156.838\n",
      "Epoch: [ 5] [  285/10059] total steps:[ 40521] lr:[0.00010000] time: 15.09s (1521s total) loss: 234.985\n",
      "Epoch: [ 5] [  295/10059] total steps:[ 40531] lr:[0.00010000] time: 15.11s (1536s total) loss: 106.661\n",
      "Epoch: [ 5] [  305/10059] total steps:[ 40541] lr:[0.00010000] time: 15.29s (1551s total) loss: 164.448\n",
      "Epoch: [ 5] [  315/10059] total steps:[ 40551] lr:[0.00010000] time: 15.56s (1567s total) loss: 128.422\n",
      "Epoch: [ 5] [  325/10059] total steps:[ 40561] lr:[0.00010000] time: 15.21s (1582s total) loss: 174.511\n",
      "Epoch: [ 5] [  335/10059] total steps:[ 40571] lr:[0.00010000] time: 15.35s (1597s total) loss: 165.382\n",
      "Epoch: [ 5] [  345/10059] total steps:[ 40581] lr:[0.00010000] time: 15.08s (1612s total) loss: 149.073\n",
      "Epoch: [ 5] [  355/10059] total steps:[ 40591] lr:[0.00010000] time: 15.29s (1628s total) loss: 146.367\n",
      "Epoch: [ 5] [  365/10059] total steps:[ 40601] lr:[0.00010000] time: 15.44s (1643s total) loss: 127.557\n",
      "Epoch: [ 5] [  375/10059] total steps:[ 40611] lr:[0.00010000] time: 15.40s (1658s total) loss: 170.129\n",
      "Epoch: [ 5] [  385/10059] total steps:[ 40621] lr:[0.00010000] time: 15.21s (1674s total) loss: 164.128\n",
      "Epoch: [ 5] [  395/10059] total steps:[ 40631] lr:[0.00010000] time: 15.32s (1689s total) loss: 192.060\n",
      "Epoch: [ 5] [  405/10059] total steps:[ 40641] lr:[0.00010000] time: 15.28s (1704s total) loss: 164.908\n",
      "Epoch: [ 5] [  415/10059] total steps:[ 40651] lr:[0.00010000] time: 15.21s (1719s total) loss: 199.866\n",
      "Epoch: [ 5] [  425/10059] total steps:[ 40661] lr:[0.00010000] time: 15.28s (1735s total) loss: 160.021\n",
      "Epoch: [ 5] [  435/10059] total steps:[ 40671] lr:[0.00010000] time: 15.30s (1750s total) loss: 240.160\n",
      "Epoch: [ 5] [  445/10059] total steps:[ 40681] lr:[0.00010000] time: 15.19s (1765s total) loss: 131.914\n",
      "Epoch: [ 5] [  455/10059] total steps:[ 40691] lr:[0.00010000] time: 15.46s (1781s total) loss: 153.975\n",
      "Epoch: [ 5] [  465/10059] total steps:[ 40701] lr:[0.00010000] time: 15.35s (1796s total) loss: 139.657\n",
      "Epoch: [ 5] [  475/10059] total steps:[ 40711] lr:[0.00010000] time: 15.25s (1811s total) loss: 185.696\n",
      "Epoch: [ 5] [  485/10059] total steps:[ 40721] lr:[0.00010000] time: 15.36s (1827s total) loss: 182.705\n",
      "Epoch: [ 5] [  495/10059] total steps:[ 40731] lr:[0.00010000] time: 15.26s (1842s total) loss: 160.296\n",
      "Epoch: [ 5] [  505/10059] total steps:[ 40741] lr:[0.00010000] time: 15.30s (1857s total) loss: 152.150\n",
      "Epoch: [ 5] [  515/10059] total steps:[ 40751] lr:[0.00010000] time: 15.33s (1873s total) loss: 184.798\n",
      "Epoch: [ 5] [  525/10059] total steps:[ 40761] lr:[0.00010000] time: 15.38s (1888s total) loss: 184.294\n",
      "Epoch: [ 5] [  535/10059] total steps:[ 40771] lr:[0.00010000] time: 15.34s (1903s total) loss: 124.169\n",
      "Epoch: [ 5] [  545/10059] total steps:[ 40781] lr:[0.00010000] time: 15.44s (1919s total) loss: 168.399\n",
      "Epoch: [ 5] [  555/10059] total steps:[ 40791] lr:[0.00010000] time: 15.36s (1934s total) loss: 149.685\n",
      "Epoch: [ 5] [  565/10059] total steps:[ 40801] lr:[0.00010000] time: 15.77s (1950s total) loss: 153.401\n",
      "Epoch: [ 5] [  575/10059] total steps:[ 40811] lr:[0.00010000] time: 15.27s (1965s total) loss: 181.166\n",
      "Epoch: [ 5] [  585/10059] total steps:[ 40821] lr:[0.00010000] time: 15.50s (1981s total) loss: 112.366\n",
      "Epoch: [ 5] [  595/10059] total steps:[ 40831] lr:[0.00010000] time: 15.33s (1996s total) loss: 178.337\n",
      "Epoch: [ 5] [  605/10059] total steps:[ 40841] lr:[0.00010000] time: 15.35s (2011s total) loss: 133.853\n",
      "Epoch: [ 5] [  615/10059] total steps:[ 40851] lr:[0.00010000] time: 15.64s (2027s total) loss: 165.096\n",
      "Epoch: [ 5] [  625/10059] total steps:[ 40861] lr:[0.00010000] time: 15.28s (2042s total) loss: 132.775\n",
      "Epoch: [ 5] [  635/10059] total steps:[ 40871] lr:[0.00010000] time: 15.20s (2057s total) loss: 88.300\n",
      "Epoch: [ 5] [  645/10059] total steps:[ 40881] lr:[0.00010000] time: 15.34s (2073s total) loss: 117.491\n",
      "Epoch: [ 5] [  655/10059] total steps:[ 40891] lr:[0.00010000] time: 15.20s (2088s total) loss: 123.348\n",
      "Epoch: [ 5] [  665/10059] total steps:[ 40901] lr:[0.00010000] time: 15.35s (2103s total) loss: 183.549\n",
      "Epoch: [ 5] [  675/10059] total steps:[ 40911] lr:[0.00010000] time: 15.19s (2118s total) loss: 201.602\n",
      "Epoch: [ 5] [  685/10059] total steps:[ 40921] lr:[0.00010000] time: 15.38s (2134s total) loss: 147.720\n",
      "Epoch: [ 5] [  695/10059] total steps:[ 40931] lr:[0.00010000] time: 15.26s (2149s total) loss: 163.124\n",
      "Epoch: [ 5] [  705/10059] total steps:[ 40941] lr:[0.00010000] time: 15.37s (2164s total) loss: 225.337\n",
      "Epoch: [ 5] [  715/10059] total steps:[ 40951] lr:[0.00010000] time: 15.38s (2180s total) loss: 256.476\n",
      "Epoch: [ 5] [  725/10059] total steps:[ 40961] lr:[0.00010000] time: 15.34s (2195s total) loss: 210.480\n",
      "Epoch: [ 5] [  735/10059] total steps:[ 40971] lr:[0.00010000] time: 15.34s (2211s total) loss: 122.810\n",
      "Epoch: [ 5] [  745/10059] total steps:[ 40981] lr:[0.00010000] time: 15.38s (2226s total) loss: 171.986\n",
      "Epoch: [ 5] [  755/10059] total steps:[ 40991] lr:[0.00010000] time: 15.37s (2241s total) loss: 152.382\n",
      "Epoch: [ 5] [  765/10059] total steps:[ 41001] lr:[0.00010000] time: 15.42s (2257s total) loss: 138.274\n",
      "Epoch: [ 5] [  775/10059] total steps:[ 41011] lr:[0.00010000] time: 15.35s (2272s total) loss: 159.501\n",
      "Epoch: [ 5] [  785/10059] total steps:[ 41021] lr:[0.00010000] time: 15.41s (2287s total) loss: 153.910\n",
      "Epoch: [ 5] [  795/10059] total steps:[ 41031] lr:[0.00010000] time: 15.51s (2303s total) loss: 154.706\n",
      "Epoch: [ 5] [  805/10059] total steps:[ 41041] lr:[0.00010000] time: 15.42s (2318s total) loss: 147.447\n",
      "Epoch: [ 5] [  815/10059] total steps:[ 41051] lr:[0.00010000] time: 15.35s (2334s total) loss: 119.438\n",
      "Epoch: [ 5] [  825/10059] total steps:[ 41061] lr:[0.00010000] time: 15.45s (2349s total) loss: 123.257\n",
      "Epoch: [ 5] [  835/10059] total steps:[ 41071] lr:[0.00010000] time: 15.42s (2365s total) loss: 198.324\n",
      "Epoch: [ 5] [  845/10059] total steps:[ 41081] lr:[0.00010000] time: 15.38s (2380s total) loss: 121.884\n",
      "Epoch: [ 5] [  855/10059] total steps:[ 41091] lr:[0.00010000] time: 15.38s (2395s total) loss: 169.648\n",
      "Epoch: [ 5] [  865/10059] total steps:[ 41101] lr:[0.00010000] time: 15.42s (2411s total) loss: 123.637\n",
      "Epoch: [ 5] [  875/10059] total steps:[ 41111] lr:[0.00010000] time: 15.41s (2426s total) loss: 131.020\n",
      "Epoch: [ 5] [  885/10059] total steps:[ 41121] lr:[0.00010000] time: 15.33s (2442s total) loss: 156.434\n",
      "Epoch: [ 5] [  895/10059] total steps:[ 41131] lr:[0.00010000] time: 15.45s (2457s total) loss: 103.162\n",
      "Epoch: [ 5] [  905/10059] total steps:[ 41141] lr:[0.00010000] time: 15.39s (2472s total) loss: 106.208\n",
      "Epoch: [ 5] [  915/10059] total steps:[ 41151] lr:[0.00010000] time: 15.43s (2488s total) loss: 178.440\n",
      "Epoch: [ 5] [  925/10059] total steps:[ 41161] lr:[0.00010000] time: 15.34s (2503s total) loss: 153.719\n",
      "Epoch: [ 5] [  935/10059] total steps:[ 41171] lr:[0.00010000] time: 15.50s (2519s total) loss: 143.362\n",
      "Epoch: [ 5] [  945/10059] total steps:[ 41181] lr:[0.00010000] time: 15.46s (2534s total) loss: 146.489\n",
      "Epoch: [ 5] [  955/10059] total steps:[ 41191] lr:[0.00010000] time: 15.45s (2550s total) loss: 166.776\n",
      "Epoch: [ 5] [  965/10059] total steps:[ 41201] lr:[0.00010000] time: 15.49s (2565s total) loss: 167.353\n",
      "Epoch: [ 5] [  975/10059] total steps:[ 41211] lr:[0.00010000] time: 15.23s (2580s total) loss: 159.373\n",
      "Epoch: [ 5] [  985/10059] total steps:[ 41221] lr:[0.00010000] time: 15.39s (2596s total) loss: 136.714\n",
      "Epoch: [ 5] [  995/10059] total steps:[ 41231] lr:[0.00010000] time: 15.51s (2611s total) loss: 154.722\n",
      "Epoch: [ 5] [ 1005/10059] total steps:[ 41241] lr:[0.00010000] time: 15.37s (2627s total) loss: 167.620\n",
      "Epoch: [ 5] [ 1015/10059] total steps:[ 41251] lr:[0.00010000] time: 15.32s (2642s total) loss: 154.660\n",
      "Epoch: [ 5] [ 1025/10059] total steps:[ 41261] lr:[0.00010000] time: 15.44s (2657s total) loss: 174.380\n",
      "Epoch: [ 5] [ 1035/10059] total steps:[ 41271] lr:[0.00010000] time: 15.36s (2673s total) loss: 143.298\n",
      "Epoch: [ 5] [ 1045/10059] total steps:[ 41281] lr:[0.00010000] time: 15.50s (2688s total) loss: 158.564\n",
      "Epoch: [ 5] [ 1055/10059] total steps:[ 41291] lr:[0.00010000] time: 15.47s (2704s total) loss: 120.087\n",
      "Epoch: [ 5] [ 1065/10059] total steps:[ 41301] lr:[0.00010000] time: 15.23s (2719s total) loss: 155.378\n",
      "Epoch: [ 5] [ 1075/10059] total steps:[ 41311] lr:[0.00010000] time: 15.48s (2734s total) loss: 222.013\n",
      "Epoch: [ 5] [ 1085/10059] total steps:[ 41321] lr:[0.00010000] time: 15.32s (2750s total) loss: 102.189\n",
      "Epoch: [ 5] [ 1095/10059] total steps:[ 41331] lr:[0.00010000] time: 15.29s (2765s total) loss: 130.379\n",
      "Epoch: [ 5] [ 1105/10059] total steps:[ 41341] lr:[0.00010000] time: 15.43s (2780s total) loss: 173.103\n",
      "Epoch: [ 5] [ 1115/10059] total steps:[ 41351] lr:[0.00010000] time: 15.21s (2796s total) loss: 161.253\n",
      "Epoch: [ 5] [ 1125/10059] total steps:[ 41361] lr:[0.00010000] time: 15.42s (2811s total) loss: 149.885\n",
      "Epoch: [ 5] [ 1135/10059] total steps:[ 41371] lr:[0.00010000] time: 15.27s (2826s total) loss: 203.682\n",
      "Epoch: [ 5] [ 1145/10059] total steps:[ 41381] lr:[0.00010000] time: 15.36s (2842s total) loss: 145.863\n",
      "Epoch: [ 5] [ 1155/10059] total steps:[ 41391] lr:[0.00010000] time: 15.28s (2857s total) loss: 190.742\n",
      "Epoch: [ 5] [ 1165/10059] total steps:[ 41401] lr:[0.00010000] time: 15.67s (2873s total) loss: 157.638\n",
      "Epoch: [ 5] [ 1175/10059] total steps:[ 41411] lr:[0.00010000] time: 15.32s (2888s total) loss: 138.703\n",
      "Epoch: [ 5] [ 1185/10059] total steps:[ 41421] lr:[0.00010000] time: 15.51s (2903s total) loss: 235.011\n",
      "Epoch: [ 5] [ 1195/10059] total steps:[ 41431] lr:[0.00010000] time: 15.27s (2919s total) loss: 148.670\n",
      "Epoch: [ 5] [ 1205/10059] total steps:[ 41441] lr:[0.00010000] time: 15.37s (2934s total) loss: 135.676\n",
      "Epoch: [ 5] [ 1215/10059] total steps:[ 41451] lr:[0.00010000] time: 15.33s (2949s total) loss: 149.670\n",
      "Epoch: [ 5] [ 1225/10059] total steps:[ 41461] lr:[0.00010000] time: 15.34s (2965s total) loss: 163.180\n",
      "Epoch: [ 5] [ 1235/10059] total steps:[ 41471] lr:[0.00010000] time: 15.55s (2980s total) loss: 99.573\n",
      "Epoch: [ 5] [ 1245/10059] total steps:[ 41481] lr:[0.00010000] time: 15.48s (2996s total) loss: 145.100\n",
      "Epoch: [ 5] [ 1255/10059] total steps:[ 41491] lr:[0.00010000] time: 15.47s (3011s total) loss: 154.175\n",
      "Epoch: [ 5] [ 1265/10059] total steps:[ 41501] lr:[0.00010000] time: 15.39s (3027s total) loss: 189.090\n",
      "Epoch: [ 5] [ 1275/10059] total steps:[ 41511] lr:[0.00010000] time: 15.54s (3042s total) loss: 185.008\n",
      "Epoch: [ 5] [ 1285/10059] total steps:[ 41521] lr:[0.00010000] time: 15.36s (3058s total) loss: 173.931\n",
      "Epoch: [ 5] [ 1295/10059] total steps:[ 41531] lr:[0.00010000] time: 15.26s (3073s total) loss: 208.850\n",
      "Epoch: [ 5] [ 1305/10059] total steps:[ 41541] lr:[0.00010000] time: 15.39s (3088s total) loss: 111.369\n",
      "Epoch: [ 5] [ 1315/10059] total steps:[ 41551] lr:[0.00010000] time: 15.70s (3104s total) loss: 217.154\n",
      "Epoch: [ 5] [ 1325/10059] total steps:[ 41561] lr:[0.00010000] time: 15.42s (3119s total) loss: 180.182\n",
      "Epoch: [ 5] [ 1335/10059] total steps:[ 41571] lr:[0.00010000] time: 15.24s (3135s total) loss: 112.313\n",
      "Epoch: [ 5] [ 1345/10059] total steps:[ 41581] lr:[0.00010000] time: 15.35s (3150s total) loss: 91.336\n",
      "Epoch: [ 5] [ 1355/10059] total steps:[ 41591] lr:[0.00010000] time: 15.30s (3165s total) loss: 196.476\n",
      "Epoch: [ 5] [ 1365/10059] total steps:[ 41601] lr:[0.00010000] time: 15.41s (3181s total) loss: 139.971\n",
      "Epoch: [ 5] [ 1375/10059] total steps:[ 41611] lr:[0.00010000] time: 15.35s (3196s total) loss: 173.516\n",
      "Epoch: [ 5] [ 1385/10059] total steps:[ 41621] lr:[0.00010000] time: 15.44s (3211s total) loss: 119.027\n",
      "Epoch: [ 5] [ 1395/10059] total steps:[ 41631] lr:[0.00010000] time: 15.44s (3227s total) loss: 145.909\n",
      "Epoch: [ 5] [ 1405/10059] total steps:[ 41641] lr:[0.00010000] time: 15.45s (3242s total) loss: 170.158\n",
      "Epoch: [ 5] [ 1415/10059] total steps:[ 41651] lr:[0.00010000] time: 15.51s (3258s total) loss: 173.017\n",
      "Epoch: [ 5] [ 1425/10059] total steps:[ 41661] lr:[0.00010000] time: 15.46s (3273s total) loss: 126.738\n",
      "Epoch: [ 5] [ 1435/10059] total steps:[ 41671] lr:[0.00010000] time: 15.43s (3289s total) loss: 184.224\n",
      "Epoch: [ 5] [ 1445/10059] total steps:[ 41681] lr:[0.00010000] time: 15.33s (3304s total) loss: 166.650\n",
      "Epoch: [ 5] [ 1455/10059] total steps:[ 41691] lr:[0.00010000] time: 15.18s (3319s total) loss: 132.862\n",
      "Epoch: [ 5] [ 1465/10059] total steps:[ 41701] lr:[0.00010000] time: 15.37s (3335s total) loss: 155.514\n",
      "Epoch: [ 5] [ 1475/10059] total steps:[ 41711] lr:[0.00010000] time: 15.55s (3350s total) loss: 208.894\n",
      "Epoch: [ 5] [ 1485/10059] total steps:[ 41721] lr:[0.00010000] time: 15.25s (3365s total) loss: 147.411\n",
      "Epoch: [ 5] [ 1495/10059] total steps:[ 41731] lr:[0.00010000] time: 15.48s (3381s total) loss: 133.882\n",
      "Epoch: [ 5] [ 1505/10059] total steps:[ 41741] lr:[0.00010000] time: 15.30s (3396s total) loss: 171.485\n",
      "Epoch: [ 5] [ 1515/10059] total steps:[ 41751] lr:[0.00010000] time: 15.35s (3411s total) loss: 122.675\n",
      "Epoch: [ 5] [ 1525/10059] total steps:[ 41761] lr:[0.00010000] time: 15.46s (3427s total) loss: 195.969\n",
      "Epoch: [ 5] [ 1535/10059] total steps:[ 41771] lr:[0.00010000] time: 15.29s (3442s total) loss: 189.465\n",
      "Epoch: [ 5] [ 1545/10059] total steps:[ 41781] lr:[0.00010000] time: 15.46s (3458s total) loss: 121.100\n",
      "Epoch: [ 5] [ 1555/10059] total steps:[ 41791] lr:[0.00010000] time: 15.43s (3473s total) loss: 157.665\n",
      "Epoch: [ 5] [ 1565/10059] total steps:[ 41801] lr:[0.00010000] time: 15.30s (3488s total) loss: 189.051\n",
      "Epoch: [ 5] [ 1575/10059] total steps:[ 41811] lr:[0.00010000] time: 15.44s (3504s total) loss: 137.461\n",
      "Epoch: [ 5] [ 1585/10059] total steps:[ 41821] lr:[0.00010000] time: 15.31s (3519s total) loss: 200.551\n",
      "Epoch: [ 5] [ 1595/10059] total steps:[ 41831] lr:[0.00010000] time: 15.44s (3535s total) loss: 121.435\n",
      "Epoch: [ 5] [ 1605/10059] total steps:[ 41841] lr:[0.00010000] time: 15.27s (3550s total) loss: 164.537\n",
      "Epoch: [ 5] [ 1615/10059] total steps:[ 41851] lr:[0.00010000] time: 15.49s (3565s total) loss: 158.611\n",
      "Epoch: [ 5] [ 1625/10059] total steps:[ 41861] lr:[0.00010000] time: 15.35s (3581s total) loss: 175.502\n",
      "Epoch: [ 5] [ 1635/10059] total steps:[ 41871] lr:[0.00010000] time: 15.36s (3596s total) loss: 228.279\n",
      "Epoch: [ 5] [ 1645/10059] total steps:[ 41881] lr:[0.00010000] time: 15.30s (3611s total) loss: 121.910\n",
      "Epoch: [ 5] [ 1655/10059] total steps:[ 41891] lr:[0.00010000] time: 15.54s (3627s total) loss: 159.683\n",
      "Epoch: [ 5] [ 1665/10059] total steps:[ 41901] lr:[0.00010000] time: 15.38s (3642s total) loss: 166.471\n",
      "Epoch: [ 5] [ 1675/10059] total steps:[ 41911] lr:[0.00010000] time: 15.37s (3658s total) loss: 166.842\n",
      "Epoch: [ 5] [ 1685/10059] total steps:[ 41921] lr:[0.00010000] time: 15.33s (3673s total) loss: 181.881\n",
      "Epoch: [ 5] [ 1695/10059] total steps:[ 41931] lr:[0.00010000] time: 15.34s (3688s total) loss: 171.930\n",
      "Epoch: [ 5] [ 1705/10059] total steps:[ 41941] lr:[0.00010000] time: 15.36s (3704s total) loss: 110.440\n",
      "Epoch: [ 5] [ 1715/10059] total steps:[ 41951] lr:[0.00010000] time: 15.39s (3719s total) loss: 142.492\n",
      "Epoch: [ 5] [ 1725/10059] total steps:[ 41961] lr:[0.00010000] time: 15.50s (3735s total) loss: 159.635\n",
      "Epoch: [ 5] [ 1735/10059] total steps:[ 41971] lr:[0.00010000] time: 15.40s (3750s total) loss: 161.605\n",
      "Epoch: [ 5] [ 1745/10059] total steps:[ 41981] lr:[0.00010000] time: 15.30s (3765s total) loss: 152.963\n",
      "Epoch: [ 5] [ 1755/10059] total steps:[ 41991] lr:[0.00010000] time: 15.40s (3781s total) loss: 138.090\n",
      "Epoch: [ 5] [ 1765/10059] total steps:[ 42001] lr:[0.00010000] time: 15.29s (3796s total) loss: 144.546\n",
      "Epoch: [ 5] [ 1775/10059] total steps:[ 42011] lr:[0.00010000] time: 15.31s (3811s total) loss: 133.908\n",
      "Epoch: [ 5] [ 1785/10059] total steps:[ 42021] lr:[0.00010000] time: 15.39s (3827s total) loss: 179.396\n",
      "Epoch: [ 5] [ 1795/10059] total steps:[ 42031] lr:[0.00010000] time: 15.30s (3842s total) loss: 152.246\n",
      "Epoch: [ 5] [ 1805/10059] total steps:[ 42041] lr:[0.00010000] time: 15.44s (3857s total) loss: 191.087\n",
      "Epoch: [ 5] [ 1815/10059] total steps:[ 42051] lr:[0.00010000] time: 15.30s (3873s total) loss: 117.857\n",
      "Epoch: [ 5] [ 1825/10059] total steps:[ 42061] lr:[0.00010000] time: 15.20s (3888s total) loss: 150.711\n",
      "Epoch: [ 5] [ 1835/10059] total steps:[ 42071] lr:[0.00010000] time: 15.26s (3903s total) loss: 162.669\n",
      "Epoch: [ 5] [ 1845/10059] total steps:[ 42081] lr:[0.00010000] time: 15.39s (3919s total) loss: 176.327\n",
      "Epoch: [ 5] [ 1855/10059] total steps:[ 42091] lr:[0.00010000] time: 15.38s (3934s total) loss: 144.355\n",
      "Epoch: [ 5] [ 1865/10059] total steps:[ 42101] lr:[0.00010000] time: 15.34s (3949s total) loss: 139.428\n",
      "Epoch: [ 5] [ 1875/10059] total steps:[ 42111] lr:[0.00010000] time: 15.41s (3965s total) loss: 116.825\n",
      "Epoch: [ 5] [ 1885/10059] total steps:[ 42121] lr:[0.00010000] time: 15.72s (3980s total) loss: 196.630\n",
      "Epoch: [ 5] [ 1895/10059] total steps:[ 42131] lr:[0.00010000] time: 15.49s (3996s total) loss: 195.738\n",
      "Epoch: [ 5] [ 1905/10059] total steps:[ 42141] lr:[0.00010000] time: 15.48s (4011s total) loss: 118.938\n",
      "Epoch: [ 5] [ 1915/10059] total steps:[ 42151] lr:[0.00010000] time: 15.33s (4027s total) loss: 117.613\n",
      "Epoch: [ 5] [ 1925/10059] total steps:[ 42161] lr:[0.00010000] time: 15.22s (4042s total) loss: 171.199\n",
      "Epoch: [ 5] [ 1935/10059] total steps:[ 42171] lr:[0.00010000] time: 15.26s (4057s total) loss: 170.226\n",
      "Epoch: [ 5] [ 1945/10059] total steps:[ 42181] lr:[0.00010000] time: 15.36s (4073s total) loss: 151.536\n",
      "Epoch: [ 5] [ 1955/10059] total steps:[ 42191] lr:[0.00010000] time: 15.34s (4088s total) loss: 128.048\n",
      "Epoch: [ 5] [ 1965/10059] total steps:[ 42201] lr:[0.00010000] time: 15.37s (4103s total) loss: 179.854\n",
      "Epoch: [ 5] [ 1975/10059] total steps:[ 42211] lr:[0.00010000] time: 15.23s (4119s total) loss: 130.554\n",
      "Epoch: [ 5] [ 1985/10059] total steps:[ 42221] lr:[0.00010000] time: 15.38s (4134s total) loss: 143.787\n",
      "Epoch: [ 5] [ 1995/10059] total steps:[ 42231] lr:[0.00010000] time: 15.43s (4149s total) loss: 136.995\n",
      "Epoch: [ 5] [ 2005/10059] total steps:[ 42241] lr:[0.00010000] time: 15.33s (4165s total) loss: 110.649\n",
      "Epoch: [ 5] [ 2015/10059] total steps:[ 42251] lr:[0.00010000] time: 15.48s (4180s total) loss: 141.326\n",
      "Epoch: [ 5] [ 2025/10059] total steps:[ 42261] lr:[0.00010000] time: 15.39s (4196s total) loss: 175.455\n",
      "Epoch: [ 5] [ 2035/10059] total steps:[ 42271] lr:[0.00010000] time: 15.30s (4211s total) loss: 115.198\n",
      "Epoch: [ 5] [ 2045/10059] total steps:[ 42281] lr:[0.00010000] time: 15.30s (4226s total) loss: 179.011\n",
      "Epoch: [ 5] [ 2055/10059] total steps:[ 42291] lr:[0.00010000] time: 15.45s (4242s total) loss: 136.970\n",
      "Epoch: [ 5] [ 2065/10059] total steps:[ 42301] lr:[0.00010000] time: 15.28s (4257s total) loss: 162.990\n",
      "Epoch: [ 5] [ 2075/10059] total steps:[ 42311] lr:[0.00010000] time: 15.32s (4272s total) loss: 116.136\n",
      "Epoch: [ 5] [ 2085/10059] total steps:[ 42321] lr:[0.00010000] time: 15.37s (4288s total) loss: 144.972\n",
      "Epoch: [ 5] [ 2095/10059] total steps:[ 42331] lr:[0.00010000] time: 15.30s (4303s total) loss: 183.039\n",
      "Epoch: [ 5] [ 2105/10059] total steps:[ 42341] lr:[0.00010000] time: 15.27s (4318s total) loss: 145.215\n",
      "Epoch: [ 5] [ 2115/10059] total steps:[ 42351] lr:[0.00010000] time: 15.51s (4334s total) loss: 137.290\n",
      "Epoch: [ 5] [ 2125/10059] total steps:[ 42361] lr:[0.00010000] time: 15.41s (4349s total) loss: 160.024\n",
      "Epoch: [ 5] [ 2135/10059] total steps:[ 42371] lr:[0.00010000] time: 15.40s (4364s total) loss: 151.455\n",
      "Epoch: [ 5] [ 2145/10059] total steps:[ 42381] lr:[0.00010000] time: 15.36s (4380s total) loss: 149.462\n",
      "Epoch: [ 5] [ 2155/10059] total steps:[ 42391] lr:[0.00010000] time: 15.35s (4395s total) loss: 198.590\n",
      "Epoch: [ 5] [ 2165/10059] total steps:[ 42401] lr:[0.00010000] time: 15.43s (4411s total) loss: 147.110\n",
      "Epoch: [ 5] [ 2175/10059] total steps:[ 42411] lr:[0.00010000] time: 15.59s (4426s total) loss: 161.843\n",
      "Epoch: [ 5] [ 2185/10059] total steps:[ 42421] lr:[0.00010000] time: 15.56s (4442s total) loss: 190.046\n",
      "Epoch: [ 5] [ 2195/10059] total steps:[ 42431] lr:[0.00010000] time: 15.23s (4457s total) loss: 183.359\n",
      "Epoch: [ 5] [ 2205/10059] total steps:[ 42441] lr:[0.00010000] time: 15.54s (4473s total) loss: 128.430\n",
      "Epoch: [ 5] [ 2215/10059] total steps:[ 42451] lr:[0.00010000] time: 15.42s (4488s total) loss: 145.217\n",
      "Epoch: [ 5] [ 2225/10059] total steps:[ 42461] lr:[0.00010000] time: 15.56s (4503s total) loss: 141.754\n",
      "Epoch: [ 5] [ 2235/10059] total steps:[ 42471] lr:[0.00010000] time: 15.36s (4519s total) loss: 202.244\n",
      "Epoch: [ 5] [ 2245/10059] total steps:[ 42481] lr:[0.00010000] time: 15.55s (4534s total) loss: 93.076\n",
      "Epoch: [ 5] [ 2255/10059] total steps:[ 42491] lr:[0.00010000] time: 15.19s (4550s total) loss: 165.786\n",
      "Epoch: [ 5] [ 2265/10059] total steps:[ 42501] lr:[0.00010000] time: 15.38s (4565s total) loss: 186.599\n",
      "Epoch: [ 5] [ 2275/10059] total steps:[ 42511] lr:[0.00010000] time: 15.42s (4580s total) loss: 195.005\n",
      "Epoch: [ 5] [ 2285/10059] total steps:[ 42521] lr:[0.00010000] time: 15.39s (4596s total) loss: 173.353\n",
      "Epoch: [ 5] [ 2295/10059] total steps:[ 42531] lr:[0.00010000] time: 15.40s (4611s total) loss: 146.617\n",
      "Epoch: [ 5] [ 2305/10059] total steps:[ 42541] lr:[0.00010000] time: 15.32s (4627s total) loss: 133.470\n",
      "Epoch: [ 5] [ 2315/10059] total steps:[ 42551] lr:[0.00010000] time: 15.50s (4642s total) loss: 176.526\n",
      "Epoch: [ 5] [ 2325/10059] total steps:[ 42561] lr:[0.00010000] time: 15.30s (4657s total) loss: 220.515\n",
      "Epoch: [ 5] [ 2335/10059] total steps:[ 42571] lr:[0.00010000] time: 15.26s (4673s total) loss: 198.711\n",
      "Epoch: [ 5] [ 2345/10059] total steps:[ 42581] lr:[0.00010000] time: 441.27s (5114s total) loss: 117.630\n",
      "Epoch: [ 5] [ 2355/10059] total steps:[ 42591] lr:[0.00010000] time: 15.00s (5129s total) loss: 144.777\n",
      "Epoch: [ 5] [ 2365/10059] total steps:[ 42601] lr:[0.00010000] time: 88.96s (5218s total) loss: 197.698\n",
      "Epoch: [ 5] [ 2375/10059] total steps:[ 42611] lr:[0.00010000] time: 15.14s (5233s total) loss: 171.948\n",
      "Epoch: [ 5] [ 2385/10059] total steps:[ 42621] lr:[0.00010000] time: 14.77s (5248s total) loss: 133.819\n",
      "Epoch: [ 5] [ 2395/10059] total steps:[ 42631] lr:[0.00010000] time: 14.79s (5262s total) loss: 192.260\n",
      "Epoch: [ 5] [ 2405/10059] total steps:[ 42641] lr:[0.00010000] time: 14.78s (5277s total) loss: 117.518\n",
      "Epoch: [ 5] [ 2415/10059] total steps:[ 42651] lr:[0.00010000] time: 15.20s (5292s total) loss: 153.805\n",
      "Epoch: [ 5] [ 2425/10059] total steps:[ 42661] lr:[0.00010000] time: 15.23s (5308s total) loss: 156.679\n",
      "Epoch: [ 5] [ 2435/10059] total steps:[ 42671] lr:[0.00010000] time: 14.82s (5323s total) loss: 141.708\n",
      "Epoch: [ 5] [ 2445/10059] total steps:[ 42681] lr:[0.00010000] time: 15.27s (5338s total) loss: 136.319\n",
      "Epoch: [ 5] [ 2455/10059] total steps:[ 42691] lr:[0.00010000] time: 14.94s (5353s total) loss: 153.229\n",
      "Epoch: [ 5] [ 2465/10059] total steps:[ 42701] lr:[0.00010000] time: 15.37s (5368s total) loss: 209.294\n",
      "Epoch: [ 5] [ 2475/10059] total steps:[ 42711] lr:[0.00010000] time: 15.20s (5383s total) loss: 177.013\n",
      "Epoch: [ 5] [ 2485/10059] total steps:[ 42721] lr:[0.00010000] time: 15.10s (5398s total) loss: 217.336\n",
      "Epoch: [ 5] [ 2495/10059] total steps:[ 42731] lr:[0.00010000] time: 15.05s (5413s total) loss: 133.661\n",
      "Epoch: [ 5] [ 2505/10059] total steps:[ 42741] lr:[0.00010000] time: 15.18s (5429s total) loss: 121.755\n",
      "Epoch: [ 5] [ 2515/10059] total steps:[ 42751] lr:[0.00010000] time: 15.20s (5444s total) loss: 183.441\n",
      "Epoch: [ 5] [ 2525/10059] total steps:[ 42761] lr:[0.00010000] time: 15.53s (5459s total) loss: 157.825\n",
      "Epoch: [ 5] [ 2535/10059] total steps:[ 42771] lr:[0.00010000] time: 15.31s (5475s total) loss: 104.420\n",
      "Epoch: [ 5] [ 2545/10059] total steps:[ 42781] lr:[0.00010000] time: 15.13s (5490s total) loss: 174.598\n",
      "Epoch: [ 5] [ 2555/10059] total steps:[ 42791] lr:[0.00010000] time: 15.39s (5505s total) loss: 123.212\n",
      "Epoch: [ 5] [ 2565/10059] total steps:[ 42801] lr:[0.00010000] time: 15.58s (5521s total) loss: 130.845\n",
      "Epoch: [ 5] [ 2575/10059] total steps:[ 42811] lr:[0.00010000] time: 15.34s (5536s total) loss: 195.887\n",
      "Epoch: [ 5] [ 2585/10059] total steps:[ 42821] lr:[0.00010000] time: 15.30s (5551s total) loss: 93.099\n",
      "Epoch: [ 5] [ 2595/10059] total steps:[ 42831] lr:[0.00010000] time: 15.30s (5567s total) loss: 204.159\n",
      "Epoch: [ 5] [ 2605/10059] total steps:[ 42841] lr:[0.00010000] time: 16.69s (5583s total) loss: 176.655\n",
      "Epoch: [ 5] [ 2615/10059] total steps:[ 42851] lr:[0.00010000] time: 15.22s (5599s total) loss: 133.674\n",
      "Epoch: [ 5] [ 2625/10059] total steps:[ 42861] lr:[0.00010000] time: 15.31s (5614s total) loss: 120.840\n",
      "Epoch: [ 5] [ 2635/10059] total steps:[ 42871] lr:[0.00010000] time: 15.24s (5629s total) loss: 84.931\n",
      "Epoch: [ 5] [ 2645/10059] total steps:[ 42881] lr:[0.00010000] time: 15.57s (5645s total) loss: 107.134\n",
      "Epoch: [ 5] [ 2655/10059] total steps:[ 42891] lr:[0.00010000] time: 15.34s (5660s total) loss: 185.666\n",
      "Epoch: [ 5] [ 2665/10059] total steps:[ 42901] lr:[0.00010000] time: 15.83s (5676s total) loss: 181.529\n",
      "Epoch: [ 5] [ 2675/10059] total steps:[ 42911] lr:[0.00010000] time: 15.39s (5691s total) loss: 139.116\n",
      "Epoch: [ 5] [ 2685/10059] total steps:[ 42921] lr:[0.00010000] time: 16.83s (5708s total) loss: 141.438\n",
      "Epoch: [ 5] [ 2695/10059] total steps:[ 42931] lr:[0.00010000] time: 15.46s (5724s total) loss: 177.674\n",
      "Epoch: [ 5] [ 2705/10059] total steps:[ 42941] lr:[0.00010000] time: 15.27s (5739s total) loss: 106.772\n",
      "Epoch: [ 5] [ 2715/10059] total steps:[ 42951] lr:[0.00010000] time: 15.39s (5754s total) loss: 73.956\n",
      "Epoch: [ 5] [ 2725/10059] total steps:[ 42961] lr:[0.00010000] time: 15.33s (5770s total) loss: 199.005\n",
      "Epoch: [ 5] [ 2735/10059] total steps:[ 42971] lr:[0.00010000] time: 15.33s (5785s total) loss: 152.019\n",
      "Epoch: [ 5] [ 2745/10059] total steps:[ 42981] lr:[0.00010000] time: 15.11s (5800s total) loss: 128.134\n",
      "Epoch: [ 5] [ 2755/10059] total steps:[ 42991] lr:[0.00010000] time: 15.40s (5815s total) loss: 197.324\n",
      "Epoch: [ 5] [ 2765/10059] total steps:[ 43001] lr:[0.00010000] time: 15.35s (5831s total) loss: 148.020\n",
      "Epoch: [ 5] [ 2775/10059] total steps:[ 43011] lr:[0.00010000] time: 15.66s (5846s total) loss: 132.562\n",
      "Epoch: [ 5] [ 2785/10059] total steps:[ 43021] lr:[0.00010000] time: 15.36s (5862s total) loss: 111.448\n",
      "Epoch: [ 5] [ 2795/10059] total steps:[ 43031] lr:[0.00010000] time: 15.35s (5877s total) loss: 101.982\n",
      "Epoch: [ 5] [ 2805/10059] total steps:[ 43041] lr:[0.00010000] time: 15.37s (5893s total) loss: 130.506\n",
      "Epoch: [ 5] [ 2815/10059] total steps:[ 43051] lr:[0.00010000] time: 15.34s (5908s total) loss: 158.654\n",
      "Epoch: [ 5] [ 2825/10059] total steps:[ 43061] lr:[0.00010000] time: 15.28s (5923s total) loss: 206.486\n",
      "Epoch: [ 5] [ 2835/10059] total steps:[ 43071] lr:[0.00010000] time: 15.37s (5939s total) loss: 171.410\n",
      "Epoch: [ 5] [ 2845/10059] total steps:[ 43081] lr:[0.00010000] time: 15.22s (5954s total) loss: 160.541\n",
      "Epoch: [ 5] [ 2855/10059] total steps:[ 43091] lr:[0.00010000] time: 15.41s (5969s total) loss: 200.761\n",
      "Epoch: [ 5] [ 2865/10059] total steps:[ 43101] lr:[0.00010000] time: 15.52s (5985s total) loss: 194.306\n",
      "Epoch: [ 5] [ 2875/10059] total steps:[ 43111] lr:[0.00010000] time: 15.43s (6000s total) loss: 191.371\n",
      "Epoch: [ 5] [ 2885/10059] total steps:[ 43121] lr:[0.00010000] time: 15.30s (6015s total) loss: 107.696\n",
      "Epoch: [ 5] [ 2895/10059] total steps:[ 43131] lr:[0.00010000] time: 15.44s (6031s total) loss: 118.618\n",
      "Epoch: [ 5] [ 2905/10059] total steps:[ 43141] lr:[0.00010000] time: 15.54s (6046s total) loss: 228.862\n",
      "Epoch: [ 5] [ 2915/10059] total steps:[ 43151] lr:[0.00010000] time: 15.60s (6062s total) loss: 140.932\n",
      "Epoch: [ 5] [ 2925/10059] total steps:[ 43161] lr:[0.00010000] time: 15.39s (6077s total) loss: 149.185\n",
      "Epoch: [ 5] [ 2935/10059] total steps:[ 43171] lr:[0.00010000] time: 15.32s (6093s total) loss: 150.080\n",
      "Epoch: [ 5] [ 2945/10059] total steps:[ 43181] lr:[0.00010000] time: 15.42s (6108s total) loss: 150.127\n",
      "Epoch: [ 5] [ 2955/10059] total steps:[ 43191] lr:[0.00010000] time: 15.49s (6124s total) loss: 203.608\n",
      "Epoch: [ 5] [ 2965/10059] total steps:[ 43201] lr:[0.00010000] time: 15.45s (6139s total) loss: 179.525\n",
      "Epoch: [ 5] [ 2975/10059] total steps:[ 43211] lr:[0.00010000] time: 15.59s (6155s total) loss: 203.877\n",
      "Epoch: [ 5] [ 2985/10059] total steps:[ 43221] lr:[0.00010000] time: 15.38s (6170s total) loss: 124.561\n",
      "Epoch: [ 5] [ 2995/10059] total steps:[ 43231] lr:[0.00010000] time: 15.52s (6186s total) loss: 129.658\n",
      "Epoch: [ 5] [ 3005/10059] total steps:[ 43241] lr:[0.00010000] time: 15.57s (6201s total) loss: 156.057\n",
      "Epoch: [ 5] [ 3015/10059] total steps:[ 43251] lr:[0.00010000] time: 15.45s (6217s total) loss: 151.888\n",
      "Epoch: [ 5] [ 3025/10059] total steps:[ 43261] lr:[0.00010000] time: 15.32s (6232s total) loss: 163.333\n",
      "Epoch: [ 5] [ 3035/10059] total steps:[ 43271] lr:[0.00010000] time: 15.53s (6247s total) loss: 190.620\n",
      "Epoch: [ 5] [ 3045/10059] total steps:[ 43281] lr:[0.00010000] time: 15.73s (6263s total) loss: 215.698\n",
      "Epoch: [ 5] [ 3055/10059] total steps:[ 43291] lr:[0.00010000] time: 15.43s (6279s total) loss: 170.399\n",
      "Epoch: [ 5] [ 3065/10059] total steps:[ 43301] lr:[0.00010000] time: 15.40s (6294s total) loss: 164.424\n",
      "Epoch: [ 5] [ 3075/10059] total steps:[ 43311] lr:[0.00010000] time: 15.51s (6309s total) loss: 188.684\n",
      "Epoch: [ 5] [ 3085/10059] total steps:[ 43321] lr:[0.00010000] time: 15.38s (6325s total) loss: 111.046\n",
      "Epoch: [ 5] [ 3095/10059] total steps:[ 43331] lr:[0.00010000] time: 15.62s (6340s total) loss: 184.942\n",
      "Epoch: [ 5] [ 3105/10059] total steps:[ 43341] lr:[0.00010000] time: 15.44s (6356s total) loss: 146.475\n",
      "Epoch: [ 5] [ 3115/10059] total steps:[ 43351] lr:[0.00010000] time: 15.54s (6371s total) loss: 181.902\n",
      "Epoch: [ 5] [ 3125/10059] total steps:[ 43361] lr:[0.00010000] time: 15.31s (6387s total) loss: 124.071\n",
      "Epoch: [ 5] [ 3135/10059] total steps:[ 43371] lr:[0.00010000] time: 15.29s (6402s total) loss: 235.475\n",
      "Epoch: [ 5] [ 3145/10059] total steps:[ 43381] lr:[0.00010000] time: 15.36s (6417s total) loss: 126.136\n",
      "Epoch: [ 5] [ 3155/10059] total steps:[ 43391] lr:[0.00010000] time: 15.52s (6433s total) loss: 186.772\n",
      "Epoch: [ 5] [ 3165/10059] total steps:[ 43401] lr:[0.00010000] time: 15.41s (6448s total) loss: 131.826\n",
      "Epoch: [ 5] [ 3175/10059] total steps:[ 43411] lr:[0.00010000] time: 15.51s (6464s total) loss: 106.663\n",
      "Epoch: [ 5] [ 3185/10059] total steps:[ 43421] lr:[0.00010000] time: 15.60s (6479s total) loss: 167.115\n",
      "Epoch: [ 5] [ 3195/10059] total steps:[ 43431] lr:[0.00010000] time: 15.14s (6495s total) loss: 116.036\n",
      "Epoch: [ 5] [ 3205/10059] total steps:[ 43441] lr:[0.00010000] time: 15.47s (6510s total) loss: 158.909\n",
      "Epoch: [ 5] [ 3215/10059] total steps:[ 43451] lr:[0.00010000] time: 15.43s (6525s total) loss: 173.252\n",
      "Epoch: [ 5] [ 3225/10059] total steps:[ 43461] lr:[0.00010000] time: 15.43s (6541s total) loss: 150.702\n",
      "Epoch: [ 5] [ 3235/10059] total steps:[ 43471] lr:[0.00010000] time: 15.49s (6556s total) loss: 151.772\n",
      "Epoch: [ 5] [ 3245/10059] total steps:[ 43481] lr:[0.00010000] time: 15.37s (6572s total) loss: 129.454\n",
      "Epoch: [ 5] [ 3255/10059] total steps:[ 43491] lr:[0.00010000] time: 15.47s (6587s total) loss: 117.753\n",
      "Epoch: [ 5] [ 3265/10059] total steps:[ 43501] lr:[0.00010000] time: 15.63s (6603s total) loss: 95.805\n",
      "Epoch: [ 5] [ 3275/10059] total steps:[ 43511] lr:[0.00010000] time: 15.52s (6618s total) loss: 124.238\n",
      "Epoch: [ 5] [ 3285/10059] total steps:[ 43521] lr:[0.00010000] time: 15.39s (6634s total) loss: 110.669\n",
      "Epoch: [ 5] [ 3295/10059] total steps:[ 43531] lr:[0.00010000] time: 15.19s (6649s total) loss: 126.307\n",
      "Epoch: [ 5] [ 3305/10059] total steps:[ 43541] lr:[0.00010000] time: 15.58s (6665s total) loss: 149.258\n",
      "Epoch: [ 5] [ 3315/10059] total steps:[ 43551] lr:[0.00010000] time: 15.45s (6680s total) loss: 137.941\n",
      "Epoch: [ 5] [ 3325/10059] total steps:[ 43561] lr:[0.00010000] time: 15.35s (6695s total) loss: 205.358\n",
      "Epoch: [ 5] [ 3335/10059] total steps:[ 43571] lr:[0.00010000] time: 15.51s (6711s total) loss: 173.523\n",
      "Epoch: [ 5] [ 3345/10059] total steps:[ 43581] lr:[0.00010000] time: 15.31s (6726s total) loss: 110.976\n",
      "Epoch: [ 5] [ 3355/10059] total steps:[ 43591] lr:[0.00010000] time: 15.22s (6741s total) loss: 213.808\n",
      "Epoch: [ 5] [ 3365/10059] total steps:[ 43601] lr:[0.00010000] time: 15.50s (6757s total) loss: 228.470\n",
      "Epoch: [ 5] [ 3375/10059] total steps:[ 43611] lr:[0.00010000] time: 15.44s (6772s total) loss: 146.311\n",
      "Epoch: [ 5] [ 3385/10059] total steps:[ 43621] lr:[0.00010000] time: 15.38s (6788s total) loss: 186.407\n",
      "Epoch: [ 5] [ 3395/10059] total steps:[ 43631] lr:[0.00010000] time: 15.36s (6803s total) loss: 152.581\n",
      "Epoch: [ 5] [ 3405/10059] total steps:[ 43641] lr:[0.00010000] time: 15.76s (6819s total) loss: 216.420\n",
      "Epoch: [ 5] [ 3415/10059] total steps:[ 43651] lr:[0.00010000] time: 15.43s (6834s total) loss: 127.926\n",
      "Epoch: [ 5] [ 3425/10059] total steps:[ 43661] lr:[0.00010000] time: 15.51s (6850s total) loss: 137.017\n",
      "Epoch: [ 5] [ 3435/10059] total steps:[ 43671] lr:[0.00010000] time: 15.39s (6865s total) loss: 100.197\n",
      "Epoch: [ 5] [ 3445/10059] total steps:[ 43681] lr:[0.00010000] time: 15.36s (6881s total) loss: 188.240\n",
      "Epoch: [ 5] [ 3455/10059] total steps:[ 43691] lr:[0.00010000] time: 15.52s (6896s total) loss: 125.263\n",
      "Epoch: [ 5] [ 3465/10059] total steps:[ 43701] lr:[0.00010000] time: 15.37s (6911s total) loss: 166.023\n",
      "Epoch: [ 5] [ 3475/10059] total steps:[ 43711] lr:[0.00010000] time: 15.43s (6927s total) loss: 168.233\n",
      "Epoch: [ 5] [ 3485/10059] total steps:[ 43721] lr:[0.00010000] time: 15.53s (6942s total) loss: 136.385\n",
      "Epoch: [ 5] [ 3495/10059] total steps:[ 43731] lr:[0.00010000] time: 15.49s (6958s total) loss: 139.707\n",
      "Epoch: [ 5] [ 3505/10059] total steps:[ 43741] lr:[0.00010000] time: 15.38s (6973s total) loss: 188.661\n",
      "Epoch: [ 5] [ 3515/10059] total steps:[ 43751] lr:[0.00010000] time: 15.34s (6989s total) loss: 141.213\n",
      "Epoch: [ 5] [ 3525/10059] total steps:[ 43761] lr:[0.00010000] time: 15.36s (7004s total) loss: 158.929\n",
      "Epoch: [ 5] [ 3535/10059] total steps:[ 43771] lr:[0.00010000] time: 15.32s (7019s total) loss: 149.912\n",
      "Epoch: [ 5] [ 3545/10059] total steps:[ 43781] lr:[0.00010000] time: 15.32s (7035s total) loss: 115.725\n",
      "Epoch: [ 5] [ 3555/10059] total steps:[ 43791] lr:[0.00010000] time: 15.30s (7050s total) loss: 135.298\n",
      "Epoch: [ 5] [ 3565/10059] total steps:[ 43801] lr:[0.00010000] time: 15.46s (7065s total) loss: 154.888\n",
      "Epoch: [ 5] [ 3575/10059] total steps:[ 43811] lr:[0.00010000] time: 15.55s (7081s total) loss: 146.411\n",
      "Epoch: [ 5] [ 3585/10059] total steps:[ 43821] lr:[0.00010000] time: 15.40s (7096s total) loss: 169.145\n",
      "Epoch: [ 5] [ 3595/10059] total steps:[ 43831] lr:[0.00010000] time: 15.44s (7112s total) loss: 186.351\n",
      "Epoch: [ 5] [ 3605/10059] total steps:[ 43841] lr:[0.00010000] time: 15.33s (7127s total) loss: 164.455\n",
      "Epoch: [ 5] [ 3615/10059] total steps:[ 43851] lr:[0.00010000] time: 15.27s (7142s total) loss: 159.427\n",
      "Epoch: [ 5] [ 3625/10059] total steps:[ 43861] lr:[0.00010000] time: 15.41s (7158s total) loss: 164.503\n",
      "Epoch: [ 5] [ 3635/10059] total steps:[ 43871] lr:[0.00010000] time: 15.40s (7173s total) loss: 189.823\n",
      "Epoch: [ 5] [ 3645/10059] total steps:[ 43881] lr:[0.00010000] time: 15.35s (7189s total) loss: 138.910\n",
      "Epoch: [ 5] [ 3655/10059] total steps:[ 43891] lr:[0.00010000] time: 15.38s (7204s total) loss: 148.943\n",
      "Epoch: [ 5] [ 3665/10059] total steps:[ 43901] lr:[0.00010000] time: 15.45s (7219s total) loss: 188.688\n",
      "Epoch: [ 5] [ 3675/10059] total steps:[ 43911] lr:[0.00010000] time: 15.31s (7235s total) loss: 163.096\n",
      "Epoch: [ 5] [ 3685/10059] total steps:[ 43921] lr:[0.00010000] time: 15.38s (7250s total) loss: 126.582\n",
      "Epoch: [ 5] [ 3695/10059] total steps:[ 43931] lr:[0.00010000] time: 15.36s (7265s total) loss: 142.292\n",
      "Epoch: [ 5] [ 3705/10059] total steps:[ 43941] lr:[0.00010000] time: 15.39s (7281s total) loss: 202.696\n",
      "Epoch: [ 5] [ 3715/10059] total steps:[ 43951] lr:[0.00010000] time: 15.34s (7296s total) loss: 148.602\n",
      "Epoch: [ 5] [ 3725/10059] total steps:[ 43961] lr:[0.00010000] time: 15.42s (7312s total) loss: 141.042\n",
      "Epoch: [ 5] [ 3735/10059] total steps:[ 43971] lr:[0.00010000] time: 15.38s (7327s total) loss: 165.633\n",
      "Epoch: [ 5] [ 3745/10059] total steps:[ 43981] lr:[0.00010000] time: 15.30s (7342s total) loss: 117.265\n",
      "Epoch: [ 5] [ 3755/10059] total steps:[ 43991] lr:[0.00010000] time: 15.40s (7358s total) loss: 173.098\n",
      "Epoch: [ 5] [ 3765/10059] total steps:[ 44001] lr:[0.00010000] time: 15.48s (7373s total) loss: 162.170\n",
      "Epoch: [ 5] [ 3775/10059] total steps:[ 44011] lr:[0.00010000] time: 15.52s (7389s total) loss: 174.627\n",
      "Epoch: [ 5] [ 3785/10059] total steps:[ 44021] lr:[0.00010000] time: 15.42s (7404s total) loss: 176.234\n",
      "Epoch: [ 5] [ 3795/10059] total steps:[ 44031] lr:[0.00010000] time: 15.48s (7420s total) loss: 162.717\n",
      "Epoch: [ 5] [ 3805/10059] total steps:[ 44041] lr:[0.00010000] time: 15.29s (7435s total) loss: 145.181\n",
      "Epoch: [ 5] [ 3815/10059] total steps:[ 44051] lr:[0.00010000] time: 15.28s (7450s total) loss: 210.360\n",
      "Epoch: [ 5] [ 3825/10059] total steps:[ 44061] lr:[0.00010000] time: 15.36s (7465s total) loss: 146.167\n",
      "Epoch: [ 5] [ 3835/10059] total steps:[ 44071] lr:[0.00010000] time: 15.47s (7481s total) loss: 147.944\n",
      "Epoch: [ 5] [ 3845/10059] total steps:[ 44081] lr:[0.00010000] time: 15.40s (7496s total) loss: 198.666\n",
      "Epoch: [ 5] [ 3855/10059] total steps:[ 44091] lr:[0.00010000] time: 15.33s (7512s total) loss: 153.221\n",
      "Epoch: [ 5] [ 3865/10059] total steps:[ 44101] lr:[0.00010000] time: 15.46s (7527s total) loss: 189.352\n",
      "Epoch: [ 5] [ 3875/10059] total steps:[ 44111] lr:[0.00010000] time: 15.55s (7543s total) loss: 174.023\n",
      "Epoch: [ 5] [ 3885/10059] total steps:[ 44121] lr:[0.00010000] time: 15.61s (7558s total) loss: 166.922\n",
      "Epoch: [ 5] [ 3895/10059] total steps:[ 44131] lr:[0.00010000] time: 15.43s (7574s total) loss: 129.711\n",
      "Epoch: [ 5] [ 3905/10059] total steps:[ 44141] lr:[0.00010000] time: 15.42s (7589s total) loss: 142.395\n",
      "Epoch: [ 5] [ 3915/10059] total steps:[ 44151] lr:[0.00010000] time: 15.33s (7604s total) loss: 129.323\n",
      "Epoch: [ 5] [ 3925/10059] total steps:[ 44161] lr:[0.00010000] time: 15.38s (7620s total) loss: 191.629\n",
      "Epoch: [ 5] [ 3935/10059] total steps:[ 44171] lr:[0.00010000] time: 15.36s (7635s total) loss: 110.318\n",
      "Epoch: [ 5] [ 3945/10059] total steps:[ 44181] lr:[0.00010000] time: 15.41s (7651s total) loss: 139.972\n",
      "Epoch: [ 5] [ 3955/10059] total steps:[ 44191] lr:[0.00010000] time: 15.31s (7666s total) loss: 220.242\n",
      "Epoch: [ 5] [ 3965/10059] total steps:[ 44201] lr:[0.00010000] time: 15.39s (7681s total) loss: 101.713\n",
      "Epoch: [ 5] [ 3975/10059] total steps:[ 44211] lr:[0.00010000] time: 15.30s (7697s total) loss: 126.450\n",
      "Epoch: [ 5] [ 3985/10059] total steps:[ 44221] lr:[0.00010000] time: 15.46s (7712s total) loss: 204.561\n",
      "Epoch: [ 5] [ 3995/10059] total steps:[ 44231] lr:[0.00010000] time: 15.40s (7728s total) loss: 157.621\n",
      "Epoch: [ 5] [ 4005/10059] total steps:[ 44241] lr:[0.00010000] time: 15.40s (7743s total) loss: 120.562\n",
      "Epoch: [ 5] [ 4015/10059] total steps:[ 44251] lr:[0.00010000] time: 15.53s (7758s total) loss: 138.003\n",
      "Epoch: [ 5] [ 4025/10059] total steps:[ 44261] lr:[0.00010000] time: 15.31s (7774s total) loss: 115.601\n",
      "Epoch: [ 5] [ 4035/10059] total steps:[ 44271] lr:[0.00010000] time: 15.37s (7789s total) loss: 216.057\n",
      "Epoch: [ 5] [ 4045/10059] total steps:[ 44281] lr:[0.00010000] time: 15.55s (7805s total) loss: 189.181\n",
      "Epoch: [ 5] [ 4055/10059] total steps:[ 44291] lr:[0.00010000] time: 15.35s (7820s total) loss: 126.933\n",
      "Epoch: [ 5] [ 4065/10059] total steps:[ 44301] lr:[0.00010000] time: 15.46s (7835s total) loss: 136.210\n",
      "Epoch: [ 5] [ 4075/10059] total steps:[ 44311] lr:[0.00010000] time: 15.37s (7851s total) loss: 117.133\n",
      "Epoch: [ 5] [ 4085/10059] total steps:[ 44321] lr:[0.00010000] time: 15.44s (7866s total) loss: 182.941\n",
      "Epoch: [ 5] [ 4095/10059] total steps:[ 44331] lr:[0.00010000] time: 15.38s (7882s total) loss: 138.446\n",
      "Epoch: [ 5] [ 4105/10059] total steps:[ 44341] lr:[0.00010000] time: 15.59s (7897s total) loss: 150.770\n",
      "Epoch: [ 5] [ 4115/10059] total steps:[ 44351] lr:[0.00010000] time: 15.25s (7913s total) loss: 147.269\n",
      "Epoch: [ 5] [ 4125/10059] total steps:[ 44361] lr:[0.00010000] time: 15.36s (7928s total) loss: 138.784\n",
      "Epoch: [ 5] [ 4135/10059] total steps:[ 44371] lr:[0.00010000] time: 15.38s (7943s total) loss: 130.030\n",
      "Epoch: [ 5] [ 4145/10059] total steps:[ 44381] lr:[0.00010000] time: 15.60s (7959s total) loss: 106.274\n",
      "Epoch: [ 5] [ 4155/10059] total steps:[ 44391] lr:[0.00010000] time: 15.31s (7974s total) loss: 103.265\n",
      "Epoch: [ 5] [ 4165/10059] total steps:[ 44401] lr:[0.00010000] time: 15.40s (7990s total) loss: 126.767\n",
      "Epoch: [ 5] [ 4175/10059] total steps:[ 44411] lr:[0.00010000] time: 15.31s (8005s total) loss: 164.964\n",
      "Epoch: [ 5] [ 4185/10059] total steps:[ 44421] lr:[0.00010000] time: 15.43s (8020s total) loss: 176.711\n",
      "Epoch: [ 5] [ 4195/10059] total steps:[ 44431] lr:[0.00010000] time: 15.36s (8036s total) loss: 134.089\n",
      "Epoch: [ 5] [ 4205/10059] total steps:[ 44441] lr:[0.00010000] time: 15.31s (8051s total) loss: 187.281\n",
      "Epoch: [ 5] [ 4215/10059] total steps:[ 44451] lr:[0.00010000] time: 15.50s (8066s total) loss: 132.285\n",
      "Epoch: [ 5] [ 4225/10059] total steps:[ 44461] lr:[0.00010000] time: 15.42s (8082s total) loss: 134.830\n",
      "Epoch: [ 5] [ 4235/10059] total steps:[ 44471] lr:[0.00010000] time: 15.38s (8097s total) loss: 155.226\n",
      "Epoch: [ 5] [ 4245/10059] total steps:[ 44481] lr:[0.00010000] time: 15.31s (8113s total) loss: 114.895\n",
      "Epoch: [ 5] [ 4255/10059] total steps:[ 44491] lr:[0.00010000] time: 15.36s (8128s total) loss: 220.799\n",
      "Epoch: [ 5] [ 4265/10059] total steps:[ 44501] lr:[0.00010000] time: 15.37s (8143s total) loss: 164.720\n",
      "Epoch: [ 5] [ 4275/10059] total steps:[ 44511] lr:[0.00010000] time: 15.48s (8159s total) loss: 177.969\n",
      "Epoch: [ 5] [ 4285/10059] total steps:[ 44521] lr:[0.00010000] time: 15.35s (8174s total) loss: 158.844\n",
      "Epoch: [ 5] [ 4295/10059] total steps:[ 44531] lr:[0.00010000] time: 15.50s (8190s total) loss: 151.257\n",
      "Epoch: [ 5] [ 4305/10059] total steps:[ 44541] lr:[0.00010000] time: 15.28s (8205s total) loss: 172.942\n",
      "Epoch: [ 5] [ 4315/10059] total steps:[ 44551] lr:[0.00010000] time: 15.43s (8220s total) loss: 94.842\n",
      "Epoch: [ 5] [ 4325/10059] total steps:[ 44561] lr:[0.00010000] time: 15.39s (8236s total) loss: 192.983\n",
      "Epoch: [ 5] [ 4335/10059] total steps:[ 44571] lr:[0.00010000] time: 15.44s (8251s total) loss: 161.716\n",
      "Epoch: [ 5] [ 4345/10059] total steps:[ 44581] lr:[0.00010000] time: 15.25s (8266s total) loss: 112.584\n",
      "Epoch: [ 5] [ 4355/10059] total steps:[ 44591] lr:[0.00010000] time: 15.22s (8282s total) loss: 154.335\n",
      "Epoch: [ 5] [ 4365/10059] total steps:[ 44601] lr:[0.00010000] time: 15.55s (8297s total) loss: 151.125\n",
      "Epoch: [ 5] [ 4375/10059] total steps:[ 44611] lr:[0.00010000] time: 15.50s (8313s total) loss: 91.074\n",
      "Epoch: [ 5] [ 4385/10059] total steps:[ 44621] lr:[0.00010000] time: 15.29s (8328s total) loss: 155.486\n",
      "Epoch: [ 5] [ 4395/10059] total steps:[ 44631] lr:[0.00010000] time: 15.45s (8343s total) loss: 121.991\n",
      "Epoch: [ 5] [ 4405/10059] total steps:[ 44641] lr:[0.00010000] time: 15.28s (8359s total) loss: 162.653\n",
      "Epoch: [ 5] [ 4415/10059] total steps:[ 44651] lr:[0.00010000] time: 15.39s (8374s total) loss: 185.482\n",
      "Epoch: [ 5] [ 4425/10059] total steps:[ 44661] lr:[0.00010000] time: 15.38s (8390s total) loss: 214.764\n",
      "Epoch: [ 5] [ 4435/10059] total steps:[ 44671] lr:[0.00010000] time: 15.46s (8405s total) loss: 196.099\n",
      "Epoch: [ 5] [ 4445/10059] total steps:[ 44681] lr:[0.00010000] time: 15.41s (8420s total) loss: 141.386\n",
      "Epoch: [ 5] [ 4455/10059] total steps:[ 44691] lr:[0.00010000] time: 15.34s (8436s total) loss: 148.308\n",
      "Epoch: [ 5] [ 4465/10059] total steps:[ 44701] lr:[0.00010000] time: 15.50s (8451s total) loss: 156.863\n",
      "Epoch: [ 5] [ 4475/10059] total steps:[ 44711] lr:[0.00010000] time: 15.30s (8467s total) loss: 163.865\n",
      "Epoch: [ 5] [ 4485/10059] total steps:[ 44721] lr:[0.00010000] time: 15.27s (8482s total) loss: 186.919\n",
      "Epoch: [ 5] [ 4495/10059] total steps:[ 44731] lr:[0.00010000] time: 15.34s (8497s total) loss: 165.591\n",
      "Epoch: [ 5] [ 4505/10059] total steps:[ 44741] lr:[0.00010000] time: 15.32s (8512s total) loss: 150.281\n",
      "Epoch: [ 5] [ 4515/10059] total steps:[ 44751] lr:[0.00010000] time: 15.34s (8528s total) loss: 191.606\n",
      "Epoch: [ 5] [ 4525/10059] total steps:[ 44761] lr:[0.00010000] time: 15.34s (8543s total) loss: 209.184\n",
      "Epoch: [ 5] [ 4535/10059] total steps:[ 44771] lr:[0.00010000] time: 15.48s (8559s total) loss: 142.868\n",
      "Epoch: [ 5] [ 4545/10059] total steps:[ 44781] lr:[0.00010000] time: 15.33s (8574s total) loss: 128.527\n",
      "Epoch: [ 5] [ 4555/10059] total steps:[ 44791] lr:[0.00010000] time: 15.28s (8589s total) loss: 113.925\n",
      "Epoch: [ 5] [ 4565/10059] total steps:[ 44801] lr:[0.00010000] time: 15.30s (8605s total) loss: 235.692\n",
      "Epoch: [ 5] [ 4575/10059] total steps:[ 44811] lr:[0.00010000] time: 15.43s (8620s total) loss: 84.755\n",
      "Epoch: [ 5] [ 4585/10059] total steps:[ 44821] lr:[0.00010000] time: 15.35s (8635s total) loss: 197.982\n",
      "Epoch: [ 5] [ 4595/10059] total steps:[ 44831] lr:[0.00010000] time: 15.35s (8651s total) loss: 152.977\n",
      "Epoch: [ 5] [ 4605/10059] total steps:[ 44841] lr:[0.00010000] time: 15.33s (8666s total) loss: 167.687\n",
      "Epoch: [ 5] [ 4615/10059] total steps:[ 44851] lr:[0.00010000] time: 15.31s (8681s total) loss: 151.190\n",
      "Epoch: [ 5] [ 4625/10059] total steps:[ 44861] lr:[0.00010000] time: 15.40s (8697s total) loss: 150.028\n",
      "Epoch: [ 5] [ 4635/10059] total steps:[ 44871] lr:[0.00010000] time: 15.26s (8712s total) loss: 164.044\n",
      "Epoch: [ 5] [ 4645/10059] total steps:[ 44881] lr:[0.00010000] time: 15.49s (8727s total) loss: 91.135\n",
      "Epoch: [ 5] [ 4655/10059] total steps:[ 44891] lr:[0.00010000] time: 15.51s (8743s total) loss: 147.027\n",
      "Epoch: [ 5] [ 4665/10059] total steps:[ 44901] lr:[0.00010000] time: 15.23s (8758s total) loss: 82.932\n",
      "Epoch: [ 5] [ 4675/10059] total steps:[ 44911] lr:[0.00010000] time: 15.37s (8774s total) loss: 133.013\n",
      "Epoch: [ 5] [ 4685/10059] total steps:[ 44921] lr:[0.00010000] time: 15.40s (8789s total) loss: 153.710\n",
      "Epoch: [ 5] [ 4695/10059] total steps:[ 44931] lr:[0.00010000] time: 15.29s (8804s total) loss: 135.890\n",
      "Epoch: [ 5] [ 4705/10059] total steps:[ 44941] lr:[0.00010000] time: 15.23s (8819s total) loss: 138.601\n",
      "Epoch: [ 5] [ 4715/10059] total steps:[ 44951] lr:[0.00010000] time: 15.51s (8835s total) loss: 121.063\n",
      "Epoch: [ 5] [ 4725/10059] total steps:[ 44961] lr:[0.00010000] time: 15.37s (8850s total) loss: 154.063\n",
      "Epoch: [ 5] [ 4735/10059] total steps:[ 44971] lr:[0.00010000] time: 15.38s (8866s total) loss: 156.964\n",
      "Epoch: [ 5] [ 4745/10059] total steps:[ 44981] lr:[0.00010000] time: 15.31s (8881s total) loss: 127.460\n",
      "Epoch: [ 5] [ 4755/10059] total steps:[ 44991] lr:[0.00010000] time: 15.60s (8897s total) loss: 117.652\n",
      "Epoch: [ 5] [ 4765/10059] total steps:[ 45001] lr:[0.00010000] time: 15.43s (8912s total) loss: 259.798\n",
      "Epoch: [ 5] [ 4775/10059] total steps:[ 45011] lr:[0.00010000] time: 15.36s (8927s total) loss: 210.335\n",
      "Epoch: [ 5] [ 4785/10059] total steps:[ 45021] lr:[0.00010000] time: 15.44s (8943s total) loss: 126.846\n",
      "Epoch: [ 5] [ 4795/10059] total steps:[ 45031] lr:[0.00010000] time: 15.28s (8958s total) loss: 212.600\n",
      "Epoch: [ 5] [ 4805/10059] total steps:[ 45041] lr:[0.00010000] time: 15.29s (8973s total) loss: 121.845\n",
      "Epoch: [ 5] [ 4815/10059] total steps:[ 45051] lr:[0.00010000] time: 15.61s (8989s total) loss: 175.795\n",
      "Epoch: [ 5] [ 4825/10059] total steps:[ 45061] lr:[0.00010000] time: 15.51s (9005s total) loss: 156.294\n",
      "Epoch: [ 5] [ 4835/10059] total steps:[ 45071] lr:[0.00010000] time: 15.43s (9020s total) loss: 121.083\n",
      "Epoch: [ 5] [ 4845/10059] total steps:[ 45081] lr:[0.00010000] time: 15.32s (9035s total) loss: 182.478\n",
      "Epoch: [ 5] [ 4855/10059] total steps:[ 45091] lr:[0.00010000] time: 15.35s (9051s total) loss: 125.222\n",
      "Epoch: [ 5] [ 4865/10059] total steps:[ 45101] lr:[0.00010000] time: 15.41s (9066s total) loss: 267.285\n",
      "Epoch: [ 5] [ 4875/10059] total steps:[ 45111] lr:[0.00010000] time: 15.50s (9082s total) loss: 191.424\n",
      "Epoch: [ 5] [ 4885/10059] total steps:[ 45121] lr:[0.00010000] time: 15.46s (9097s total) loss: 131.442\n",
      "Epoch: [ 5] [ 4895/10059] total steps:[ 45131] lr:[0.00010000] time: 15.35s (9112s total) loss: 156.429\n",
      "Epoch: [ 5] [ 4905/10059] total steps:[ 45141] lr:[0.00010000] time: 15.44s (9128s total) loss: 152.696\n",
      "Epoch: [ 5] [ 4915/10059] total steps:[ 45151] lr:[0.00010000] time: 15.49s (9143s total) loss: 142.300\n",
      "Epoch: [ 5] [ 4925/10059] total steps:[ 45161] lr:[0.00010000] time: 15.40s (9159s total) loss: 137.505\n",
      "Epoch: [ 5] [ 4935/10059] total steps:[ 45171] lr:[0.00010000] time: 15.38s (9174s total) loss: 142.455\n",
      "Epoch: [ 5] [ 4945/10059] total steps:[ 45181] lr:[0.00010000] time: 15.37s (9189s total) loss: 144.688\n",
      "Epoch: [ 5] [ 4955/10059] total steps:[ 45191] lr:[0.00010000] time: 15.40s (9205s total) loss: 110.107\n",
      "Epoch: [ 5] [ 4965/10059] total steps:[ 45201] lr:[0.00010000] time: 15.54s (9220s total) loss: 115.610\n",
      "Epoch: [ 5] [ 4975/10059] total steps:[ 45211] lr:[0.00010000] time: 15.42s (9236s total) loss: 124.353\n",
      "Epoch: [ 5] [ 4985/10059] total steps:[ 45221] lr:[0.00010000] time: 15.33s (9251s total) loss: 148.265\n",
      "Epoch: [ 5] [ 4995/10059] total steps:[ 45231] lr:[0.00010000] time: 15.27s (9266s total) loss: 169.991\n",
      "Epoch: [ 5] [ 5005/10059] total steps:[ 45241] lr:[0.00010000] time: 17.15s (9284s total) loss: 110.746\n",
      "Epoch: [ 5] [ 5015/10059] total steps:[ 45251] lr:[0.00010000] time: 15.43s (9299s total) loss: 151.835\n",
      "Epoch: [ 5] [ 5025/10059] total steps:[ 45261] lr:[0.00010000] time: 15.41s (9314s total) loss: 131.637\n",
      "Epoch: [ 5] [ 5035/10059] total steps:[ 45271] lr:[0.00010000] time: 16.00s (9330s total) loss: 207.961\n"
     ]
    }
   ],
   "source": [
    "%run ./main.py -c ../config/dp3.ini -t train_dp \\\n",
    "--cont_model=../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-40237 \\\n",
    "--restore_flow_model=../results/KITTI_RAW_256_832_UnDepthflow_flow_pwc_b8_3frames/checkpoints/kitti_3frames/model-392302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Evaluate kitti depth...\n",
      "[Info] Reading datalist from: /home/garin/Documents/depth/src/kitti_eval/kitti/test_files_eigen.txt\n",
      "[Info] Loading images from: /home/waterman/dataset/KITTI\n",
      "[Info] Reshaing image to size: (256, 832)\n",
      "[Info] Restoring model: ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-40237\n",
      "[Info] Data number: 697\n",
      "[Info] FPS: 25.871\n",
      "[Info] Saving to ../results/kitti/test_kitti.npy\n"
     ]
    }
   ],
   "source": [
    "%run ./main.py -c ../config/test_dp_kitti.ini -t kitti_eval \\\n",
    "--restore_dp_model=../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-40237\n",
    "# --restore_dp_model=../results/KITTI_RAW_128_416_UnDepthflow_dp_b4_resnet50_3frames/checkpoints/kitti_3frames/model-342007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ../results/kitti/test_kitti.npy...\n",
      "[Info] Saving depth resutls to: ../results/kitti_depths\n",
      "[NUM TEST]: 697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garin/Documents/depth/src/kitti_eval/eval_depth.py:127: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  misc.imsave(\"%s/%s_pred_depth.png\" % (depth_path, filename), colored_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   abs_rel,     sq_rel,        rms,    log_rms,         a1,         a2,         a3\n",
      "    0.1745,     1.4951,     6.1608,     0.2511,     0.7555,     0.9169,     0.9682\n"
     ]
    }
   ],
   "source": [
    "%run kitti_eval/eval_depth.py --split=eigen --kitti_dir=/home/waterman/dataset/KITTI/ \\\n",
    "--pred_file=../results/kitti/test_kitti.npy \\\n",
    "--depth_results=../results/kitti_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 將結果傳回本地端 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scp -r -P 2222 garin@140.113.214.40:/home/garin/Documents/depth/results/kitti_depths/ C:/Users/Garin/Desktop/學長畢業資料/實驗程式yu/result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tensorboard --logdir=../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_3frames/ \\\n",
    "--samples_per_plugin images=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5_tf1.9",
   "language": "python",
   "name": "python3.5_tf1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
