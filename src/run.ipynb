{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 選擇使用的GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select one or several free gpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "# use CPU only\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 到當前資料夾\n",
    "- cd C:/Users/Garin/Desktop/學長畢業資料/實驗程式yu/\n",
    "\n",
    "## 3. 同步程式\n",
    "### - local -> server\n",
    "- scp -r -P 2222 ./config garin@140.113.214.40:/home/garin/Documents/depth/\n",
    "- scp -r -P 2222 ./src garin@140.113.214.40:/home/garin/Documents/depth/\n",
    "\n",
    "### - server -> local \n",
    "- scp -r -P 2222 garin@140.113.214.40:/home/garin/Documents/depth/config .\n",
    "- scp -r -P 2222 garin@140.113.214.40:/home/garin/Documents/depth/src ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_preparation/kitti_data_prepare.py \\\n",
    "--dataset_dir=/home/mjchiu/Documents/darknet-depth/dataset/KITTI/image/ \\\n",
    "--dataset_name=kitti_raw_eigen \\\n",
    "--dump_root=/home/garin/Documents/depth/datasets/kitti_3frames_256_832/ \\\n",
    "--seq_length=3 \\\n",
    "--img_height=256 \\\n",
    "--img_width=832 \\\n",
    "--num_threads=16 \\\n",
    "--remove_static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./main.py -c ../config/flow3.ini -t train_flow --cont_model=../results/KITTI_RAW_128_416_UnDepthflow_flow_pwc_b8_3frames/checkpoints/kitti_3frames/model-170987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train depth & pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./main.py -c ../config/dp3.ini -t train_dp \\\n",
    "--restore_flow_model=../results/KITTI_RAW_256_832_UnDepthflow_flow_pwc_b8_3frames/checkpoints/kitti_3frames/model-392302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### continue training depth and pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Loading the model for 3 frames...\n",
      "[Info] Building depth and pose network ...\n",
      "[Info] img_height: 256 img_width 832\n",
      "[Info] Building depth and pose network ...\n",
      "[Info] img_height: 256 img_width 832\n",
      "[Info] Model size: 6.42670M\n",
      "[Info] Continue training. Restoreing: ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-100591\n",
      "INFO:tensorflow:Restoring parameters from ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-100591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-100591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11] [   11/10059] total steps:[100601] lr:[0.00005000] time: 633.80s (633s total) loss: 170.927\n",
      "Epoch: [11] [   21/10059] total steps:[100611] lr:[0.00005000] time: 225.72s (859s total) loss: 112.482\n",
      "Epoch: [11] [   31/10059] total steps:[100621] lr:[0.00005000] time: 16.91s (876s total) loss: 107.570\n",
      "Epoch: [11] [   41/10059] total steps:[100631] lr:[0.00005000] time: 15.16s (891s total) loss: 129.715\n",
      "Epoch: [11] [   51/10059] total steps:[100641] lr:[0.00005000] time: 15.22s (906s total) loss: 184.795\n",
      "Epoch: [11] [   61/10059] total steps:[100651] lr:[0.00005000] time: 15.10s (921s total) loss: 133.360\n",
      "Epoch: [11] [   71/10059] total steps:[100661] lr:[0.00005000] time: 14.97s (936s total) loss: 92.018\n",
      "Epoch: [11] [   81/10059] total steps:[100671] lr:[0.00005000] time: 14.67s (951s total) loss: 172.264\n",
      "Epoch: [11] [   91/10059] total steps:[100681] lr:[0.00005000] time: 14.89s (966s total) loss: 108.800\n",
      "Epoch: [11] [  101/10059] total steps:[100691] lr:[0.00005000] time: 15.00s (981s total) loss: 98.013\n",
      "Epoch: [11] [  111/10059] total steps:[100701] lr:[0.00005000] time: 14.88s (996s total) loss: 157.940\n",
      "Epoch: [11] [  121/10059] total steps:[100711] lr:[0.00005000] time: 15.00s (1011s total) loss: 127.703\n",
      "Epoch: [11] [  131/10059] total steps:[100721] lr:[0.00005000] time: 14.77s (1026s total) loss: 132.887\n",
      "Epoch: [11] [  141/10059] total steps:[100731] lr:[0.00005000] time: 14.72s (1040s total) loss: 160.486\n",
      "Epoch: [11] [  151/10059] total steps:[100741] lr:[0.00005000] time: 14.77s (1055s total) loss: 153.677\n",
      "Epoch: [11] [  161/10059] total steps:[100751] lr:[0.00005000] time: 14.65s (1070s total) loss: 117.939\n",
      "Epoch: [11] [  171/10059] total steps:[100761] lr:[0.00005000] time: 14.62s (1084s total) loss: 135.838\n",
      "Epoch: [11] [  181/10059] total steps:[100771] lr:[0.00005000] time: 14.78s (1099s total) loss: 103.380\n",
      "Epoch: [11] [  191/10059] total steps:[100781] lr:[0.00005000] time: 14.76s (1114s total) loss: 167.068\n",
      "Epoch: [11] [  201/10059] total steps:[100791] lr:[0.00005000] time: 14.77s (1129s total) loss: 174.414\n",
      "Epoch: [11] [  211/10059] total steps:[100801] lr:[0.00005000] time: 379.81s (1508s total) loss: 129.701\n",
      "Epoch: [11] [  221/10059] total steps:[100811] lr:[0.00005000] time: 87.64s (1596s total) loss: 115.416\n",
      "Epoch: [11] [  231/10059] total steps:[100821] lr:[0.00005000] time: 15.07s (1611s total) loss: 99.250\n",
      "Epoch: [11] [  241/10059] total steps:[100831] lr:[0.00005000] time: 14.83s (1626s total) loss: 165.864\n",
      "Epoch: [11] [  251/10059] total steps:[100841] lr:[0.00005000] time: 15.21s (1641s total) loss: 112.801\n",
      "Epoch: [11] [  261/10059] total steps:[100851] lr:[0.00005000] time: 14.88s (1656s total) loss: 143.567\n",
      "Epoch: [11] [  271/10059] total steps:[100861] lr:[0.00005000] time: 15.16s (1671s total) loss: 138.350\n",
      "Epoch: [11] [  281/10059] total steps:[100871] lr:[0.00005000] time: 15.21s (1686s total) loss: 109.596\n",
      "Epoch: [11] [  291/10059] total steps:[100881] lr:[0.00005000] time: 14.97s (1701s total) loss: 128.227\n",
      "Epoch: [11] [  301/10059] total steps:[100891] lr:[0.00005000] time: 15.08s (1717s total) loss: 110.137\n",
      "Epoch: [11] [  311/10059] total steps:[100901] lr:[0.00005000] time: 15.31s (1732s total) loss: 211.363\n",
      "Epoch: [11] [  321/10059] total steps:[100911] lr:[0.00005000] time: 14.80s (1747s total) loss: 111.379\n",
      "Epoch: [11] [  331/10059] total steps:[100921] lr:[0.00005000] time: 15.08s (1762s total) loss: 133.079\n",
      "Epoch: [11] [  341/10059] total steps:[100931] lr:[0.00005000] time: 14.89s (1777s total) loss: 174.784\n",
      "Epoch: [11] [  351/10059] total steps:[100941] lr:[0.00005000] time: 14.82s (1791s total) loss: 106.446\n",
      "Epoch: [11] [  361/10059] total steps:[100951] lr:[0.00005000] time: 15.07s (1807s total) loss: 184.064\n",
      "Epoch: [11] [  371/10059] total steps:[100961] lr:[0.00005000] time: 15.27s (1822s total) loss: 172.022\n",
      "Epoch: [11] [  381/10059] total steps:[100971] lr:[0.00005000] time: 15.14s (1837s total) loss: 153.043\n",
      "Epoch: [11] [  391/10059] total steps:[100981] lr:[0.00005000] time: 15.28s (1852s total) loss: 117.885\n",
      "Epoch: [11] [  401/10059] total steps:[100991] lr:[0.00005000] time: 14.91s (1867s total) loss: 182.760\n",
      "Epoch: [11] [  411/10059] total steps:[101001] lr:[0.00005000] time: 15.22s (1882s total) loss: 134.477\n",
      "Epoch: [11] [  421/10059] total steps:[101011] lr:[0.00005000] time: 14.94s (1897s total) loss: 173.074\n",
      "Epoch: [11] [  431/10059] total steps:[101021] lr:[0.00005000] time: 14.93s (1912s total) loss: 123.249\n",
      "Epoch: [11] [  441/10059] total steps:[101031] lr:[0.00005000] time: 15.08s (1927s total) loss: 131.151\n",
      "Epoch: [11] [  451/10059] total steps:[101041] lr:[0.00005000] time: 15.10s (1942s total) loss: 83.816\n",
      "Epoch: [11] [  461/10059] total steps:[101051] lr:[0.00005000] time: 15.02s (1957s total) loss: 92.254\n",
      "Epoch: [11] [  471/10059] total steps:[101061] lr:[0.00005000] time: 14.97s (1972s total) loss: 122.658\n",
      "Epoch: [11] [  481/10059] total steps:[101071] lr:[0.00005000] time: 14.95s (1987s total) loss: 135.673\n",
      "Epoch: [11] [  491/10059] total steps:[101081] lr:[0.00005000] time: 15.28s (2003s total) loss: 166.203\n",
      "Epoch: [11] [  501/10059] total steps:[101091] lr:[0.00005000] time: 15.42s (2018s total) loss: 115.007\n",
      "Epoch: [11] [  511/10059] total steps:[101101] lr:[0.00005000] time: 15.02s (2033s total) loss: 165.236\n",
      "Epoch: [11] [  521/10059] total steps:[101111] lr:[0.00005000] time: 15.18s (2048s total) loss: 87.769\n",
      "Epoch: [11] [  531/10059] total steps:[101121] lr:[0.00005000] time: 14.80s (2063s total) loss: 98.617\n",
      "Epoch: [11] [  541/10059] total steps:[101131] lr:[0.00005000] time: 14.83s (2078s total) loss: 168.878\n",
      "Epoch: [11] [  551/10059] total steps:[101141] lr:[0.00005000] time: 14.82s (2093s total) loss: 128.883\n",
      "Epoch: [11] [  561/10059] total steps:[101151] lr:[0.00005000] time: 15.15s (2108s total) loss: 73.864\n",
      "Epoch: [11] [  571/10059] total steps:[101161] lr:[0.00005000] time: 14.93s (2123s total) loss: 119.168\n",
      "Epoch: [11] [  581/10059] total steps:[101171] lr:[0.00005000] time: 14.88s (2138s total) loss: 128.051\n",
      "Epoch: [11] [  591/10059] total steps:[101181] lr:[0.00005000] time: 14.99s (2153s total) loss: 106.882\n",
      "Epoch: [11] [  601/10059] total steps:[101191] lr:[0.00005000] time: 15.18s (2168s total) loss: 132.339\n",
      "Epoch: [11] [  611/10059] total steps:[101201] lr:[0.00005000] time: 14.98s (2183s total) loss: 159.209\n",
      "Epoch: [11] [  621/10059] total steps:[101211] lr:[0.00005000] time: 15.39s (2198s total) loss: 170.660\n",
      "Epoch: [11] [  631/10059] total steps:[101221] lr:[0.00005000] time: 14.93s (2213s total) loss: 146.703\n",
      "Epoch: [11] [  641/10059] total steps:[101231] lr:[0.00005000] time: 14.72s (2228s total) loss: 118.670\n",
      "Epoch: [11] [  651/10059] total steps:[101241] lr:[0.00005000] time: 14.82s (2243s total) loss: 140.911\n",
      "Epoch: [11] [  661/10059] total steps:[101251] lr:[0.00005000] time: 14.93s (2258s total) loss: 127.882\n",
      "Epoch: [11] [  671/10059] total steps:[101261] lr:[0.00005000] time: 14.90s (2272s total) loss: 159.654\n",
      "Epoch: [11] [  681/10059] total steps:[101271] lr:[0.00005000] time: 14.79s (2287s total) loss: 100.147\n",
      "Epoch: [11] [  691/10059] total steps:[101281] lr:[0.00005000] time: 15.47s (2303s total) loss: 156.043\n",
      "Epoch: [11] [  701/10059] total steps:[101291] lr:[0.00005000] time: 14.61s (2317s total) loss: 137.657\n",
      "Epoch: [11] [  711/10059] total steps:[101301] lr:[0.00005000] time: 15.10s (2332s total) loss: 128.154\n",
      "Epoch: [11] [  721/10059] total steps:[101311] lr:[0.00005000] time: 14.88s (2347s total) loss: 136.708\n",
      "Epoch: [11] [  731/10059] total steps:[101321] lr:[0.00005000] time: 14.70s (2362s total) loss: 115.179\n",
      "Epoch: [11] [  741/10059] total steps:[101331] lr:[0.00005000] time: 14.94s (2377s total) loss: 137.700\n",
      "Epoch: [11] [  751/10059] total steps:[101341] lr:[0.00005000] time: 14.92s (2392s total) loss: 201.111\n",
      "Epoch: [11] [  761/10059] total steps:[101351] lr:[0.00005000] time: 14.90s (2407s total) loss: 209.467\n",
      "Epoch: [11] [  771/10059] total steps:[101361] lr:[0.00005000] time: 14.83s (2422s total) loss: 123.378\n",
      "Epoch: [11] [  781/10059] total steps:[101371] lr:[0.00005000] time: 14.90s (2437s total) loss: 172.168\n",
      "Epoch: [11] [  791/10059] total steps:[101381] lr:[0.00005000] time: 14.84s (2451s total) loss: 149.556\n",
      "Epoch: [11] [  801/10059] total steps:[101391] lr:[0.00005000] time: 14.99s (2466s total) loss: 183.184\n",
      "Epoch: [11] [  811/10059] total steps:[101401] lr:[0.00005000] time: 15.15s (2481s total) loss: 127.395\n",
      "Epoch: [11] [  821/10059] total steps:[101411] lr:[0.00005000] time: 14.89s (2496s total) loss: 125.644\n",
      "Epoch: [11] [  831/10059] total steps:[101421] lr:[0.00005000] time: 14.85s (2511s total) loss: 130.230\n",
      "Epoch: [11] [  841/10059] total steps:[101431] lr:[0.00005000] time: 14.94s (2526s total) loss: 108.389\n",
      "Epoch: [11] [  851/10059] total steps:[101441] lr:[0.00005000] time: 14.85s (2541s total) loss: 105.641\n",
      "Epoch: [11] [  861/10059] total steps:[101451] lr:[0.00005000] time: 15.01s (2556s total) loss: 121.022\n",
      "Epoch: [11] [  871/10059] total steps:[101461] lr:[0.00005000] time: 14.76s (2571s total) loss: 87.448\n",
      "Epoch: [11] [  881/10059] total steps:[101471] lr:[0.00005000] time: 15.00s (2586s total) loss: 134.253\n",
      "Epoch: [11] [  891/10059] total steps:[101481] lr:[0.00005000] time: 14.94s (2601s total) loss: 112.468\n",
      "Epoch: [11] [  901/10059] total steps:[101491] lr:[0.00005000] time: 14.84s (2616s total) loss: 128.308\n",
      "Epoch: [11] [  911/10059] total steps:[101501] lr:[0.00005000] time: 15.00s (2631s total) loss: 118.927\n",
      "Epoch: [11] [  921/10059] total steps:[101511] lr:[0.00005000] time: 14.76s (2645s total) loss: 178.234\n",
      "Epoch: [11] [  931/10059] total steps:[101521] lr:[0.00005000] time: 14.84s (2660s total) loss: 111.604\n",
      "Epoch: [11] [  941/10059] total steps:[101531] lr:[0.00005000] time: 14.84s (2675s total) loss: 118.344\n",
      "Epoch: [11] [  951/10059] total steps:[101541] lr:[0.00005000] time: 14.84s (2690s total) loss: 99.338\n",
      "Epoch: [11] [  961/10059] total steps:[101551] lr:[0.00005000] time: 14.85s (2705s total) loss: 147.129\n",
      "Epoch: [11] [  971/10059] total steps:[101561] lr:[0.00005000] time: 14.83s (2720s total) loss: 159.049\n",
      "Epoch: [11] [  981/10059] total steps:[101571] lr:[0.00005000] time: 15.02s (2735s total) loss: 134.010\n",
      "Epoch: [11] [  991/10059] total steps:[101581] lr:[0.00005000] time: 14.77s (2749s total) loss: 170.254\n",
      "Epoch: [11] [ 1001/10059] total steps:[101591] lr:[0.00005000] time: 14.85s (2764s total) loss: 206.991\n",
      "Epoch: [11] [ 1011/10059] total steps:[101601] lr:[0.00005000] time: 14.71s (2779s total) loss: 148.359\n",
      "Epoch: [11] [ 1021/10059] total steps:[101611] lr:[0.00005000] time: 14.88s (2794s total) loss: 136.027\n",
      "Epoch: [11] [ 1031/10059] total steps:[101621] lr:[0.00005000] time: 14.89s (2809s total) loss: 122.737\n",
      "Epoch: [11] [ 1041/10059] total steps:[101631] lr:[0.00005000] time: 14.83s (2823s total) loss: 117.284\n",
      "Epoch: [11] [ 1051/10059] total steps:[101641] lr:[0.00005000] time: 14.85s (2838s total) loss: 110.895\n",
      "Epoch: [11] [ 1061/10059] total steps:[101651] lr:[0.00005000] time: 15.11s (2853s total) loss: 104.026\n",
      "Epoch: [11] [ 1071/10059] total steps:[101661] lr:[0.00005000] time: 15.16s (2869s total) loss: 177.291\n",
      "Epoch: [11] [ 1081/10059] total steps:[101671] lr:[0.00005000] time: 14.69s (2883s total) loss: 199.521\n",
      "Epoch: [11] [ 1091/10059] total steps:[101681] lr:[0.00005000] time: 15.07s (2898s total) loss: 118.017\n",
      "Epoch: [11] [ 1101/10059] total steps:[101691] lr:[0.00005000] time: 14.83s (2913s total) loss: 141.032\n",
      "Epoch: [11] [ 1111/10059] total steps:[101701] lr:[0.00005000] time: 15.16s (2928s total) loss: 165.724\n",
      "Epoch: [11] [ 1121/10059] total steps:[101711] lr:[0.00005000] time: 15.01s (2943s total) loss: 90.347\n",
      "Epoch: [11] [ 1131/10059] total steps:[101721] lr:[0.00005000] time: 14.96s (2958s total) loss: 122.756\n",
      "Epoch: [11] [ 1141/10059] total steps:[101731] lr:[0.00005000] time: 14.88s (2973s total) loss: 122.700\n",
      "Epoch: [11] [ 1151/10059] total steps:[101741] lr:[0.00005000] time: 14.75s (2988s total) loss: 115.231\n",
      "Epoch: [11] [ 1161/10059] total steps:[101751] lr:[0.00005000] time: 14.99s (3003s total) loss: 85.613\n",
      "Epoch: [11] [ 1171/10059] total steps:[101761] lr:[0.00005000] time: 14.95s (3018s total) loss: 112.758\n",
      "Epoch: [11] [ 1181/10059] total steps:[101771] lr:[0.00005000] time: 14.91s (3033s total) loss: 161.364\n",
      "Epoch: [11] [ 1191/10059] total steps:[101781] lr:[0.00005000] time: 15.65s (3048s total) loss: 98.211\n",
      "Epoch: [11] [ 1201/10059] total steps:[101791] lr:[0.00005000] time: 14.76s (3063s total) loss: 86.966\n",
      "Epoch: [11] [ 1211/10059] total steps:[101801] lr:[0.00005000] time: 15.10s (3078s total) loss: 160.287\n",
      "Epoch: [11] [ 1221/10059] total steps:[101811] lr:[0.00005000] time: 14.91s (3093s total) loss: 115.478\n",
      "Epoch: [11] [ 1231/10059] total steps:[101821] lr:[0.00005000] time: 14.83s (3108s total) loss: 141.295\n",
      "Epoch: [11] [ 1241/10059] total steps:[101831] lr:[0.00005000] time: 14.88s (3123s total) loss: 145.395\n",
      "Epoch: [11] [ 1251/10059] total steps:[101841] lr:[0.00005000] time: 14.76s (3138s total) loss: 165.868\n",
      "Epoch: [11] [ 1261/10059] total steps:[101851] lr:[0.00005000] time: 14.80s (3153s total) loss: 141.980\n",
      "Epoch: [11] [ 1271/10059] total steps:[101861] lr:[0.00005000] time: 14.81s (3167s total) loss: 110.692\n",
      "Epoch: [11] [ 1281/10059] total steps:[101871] lr:[0.00005000] time: 14.86s (3182s total) loss: 203.136\n",
      "Epoch: [11] [ 1291/10059] total steps:[101881] lr:[0.00005000] time: 14.76s (3197s total) loss: 182.193\n",
      "Epoch: [11] [ 1301/10059] total steps:[101891] lr:[0.00005000] time: 15.09s (3212s total) loss: 143.480\n",
      "Epoch: [11] [ 1311/10059] total steps:[101901] lr:[0.00005000] time: 14.77s (3227s total) loss: 146.162\n",
      "Epoch: [11] [ 1321/10059] total steps:[101911] lr:[0.00005000] time: 14.96s (3242s total) loss: 182.146\n",
      "Epoch: [11] [ 1331/10059] total steps:[101921] lr:[0.00005000] time: 14.87s (3257s total) loss: 137.790\n",
      "Epoch: [11] [ 1341/10059] total steps:[101931] lr:[0.00005000] time: 14.87s (3271s total) loss: 168.115\n",
      "Epoch: [11] [ 1351/10059] total steps:[101941] lr:[0.00005000] time: 16.01s (3288s total) loss: 156.077\n",
      "Epoch: [11] [ 1361/10059] total steps:[101951] lr:[0.00005000] time: 14.83s (3302s total) loss: 116.438\n",
      "Epoch: [11] [ 1371/10059] total steps:[101961] lr:[0.00005000] time: 15.11s (3317s total) loss: 205.451\n",
      "Epoch: [11] [ 1381/10059] total steps:[101971] lr:[0.00005000] time: 14.76s (3332s total) loss: 106.171\n",
      "Epoch: [11] [ 1391/10059] total steps:[101981] lr:[0.00005000] time: 14.84s (3347s total) loss: 113.153\n",
      "Epoch: [11] [ 1401/10059] total steps:[101991] lr:[0.00005000] time: 14.98s (3362s total) loss: 126.466\n",
      "Epoch: [11] [ 1411/10059] total steps:[102001] lr:[0.00005000] time: 14.84s (3377s total) loss: 74.614\n",
      "Epoch: [11] [ 1421/10059] total steps:[102011] lr:[0.00005000] time: 14.97s (3392s total) loss: 166.009\n",
      "Epoch: [11] [ 1431/10059] total steps:[102021] lr:[0.00005000] time: 14.83s (3407s total) loss: 82.619\n",
      "Epoch: [11] [ 1441/10059] total steps:[102031] lr:[0.00005000] time: 14.89s (3422s total) loss: 144.150\n",
      "Epoch: [11] [ 1451/10059] total steps:[102041] lr:[0.00005000] time: 14.74s (3436s total) loss: 133.900\n",
      "Epoch: [11] [ 1461/10059] total steps:[102051] lr:[0.00005000] time: 15.19s (3452s total) loss: 151.561\n",
      "Epoch: [11] [ 1471/10059] total steps:[102061] lr:[0.00005000] time: 14.76s (3466s total) loss: 165.461\n",
      "Epoch: [11] [ 1481/10059] total steps:[102071] lr:[0.00005000] time: 14.93s (3481s total) loss: 187.513\n",
      "Epoch: [11] [ 1491/10059] total steps:[102081] lr:[0.00005000] time: 14.77s (3496s total) loss: 134.636\n",
      "Epoch: [11] [ 1501/10059] total steps:[102091] lr:[0.00005000] time: 15.07s (3511s total) loss: 120.998\n",
      "Epoch: [11] [ 1511/10059] total steps:[102101] lr:[0.00005000] time: 14.86s (3526s total) loss: 122.349\n",
      "Epoch: [11] [ 1521/10059] total steps:[102111] lr:[0.00005000] time: 15.01s (3541s total) loss: 137.544\n",
      "Epoch: [11] [ 1531/10059] total steps:[102121] lr:[0.00005000] time: 14.74s (3556s total) loss: 56.681\n",
      "Epoch: [11] [ 1541/10059] total steps:[102131] lr:[0.00005000] time: 14.86s (3571s total) loss: 132.091\n",
      "Epoch: [11] [ 1551/10059] total steps:[102141] lr:[0.00005000] time: 14.89s (3585s total) loss: 175.158\n",
      "Epoch: [11] [ 1561/10059] total steps:[102151] lr:[0.00005000] time: 14.87s (3600s total) loss: 173.336\n",
      "Epoch: [11] [ 1571/10059] total steps:[102161] lr:[0.00005000] time: 14.91s (3615s total) loss: 158.873\n",
      "Epoch: [11] [ 1581/10059] total steps:[102171] lr:[0.00005000] time: 14.94s (3630s total) loss: 104.545\n",
      "Epoch: [11] [ 1591/10059] total steps:[102181] lr:[0.00005000] time: 14.75s (3645s total) loss: 159.403\n",
      "Epoch: [11] [ 1601/10059] total steps:[102191] lr:[0.00005000] time: 14.76s (3660s total) loss: 106.837\n",
      "Epoch: [11] [ 1611/10059] total steps:[102201] lr:[0.00005000] time: 14.90s (3675s total) loss: 202.740\n",
      "Epoch: [11] [ 1621/10059] total steps:[102211] lr:[0.00005000] time: 15.06s (3690s total) loss: 126.620\n",
      "Epoch: [11] [ 1631/10059] total steps:[102221] lr:[0.00005000] time: 14.76s (3704s total) loss: 134.385\n",
      "Epoch: [11] [ 1641/10059] total steps:[102231] lr:[0.00005000] time: 14.99s (3719s total) loss: 95.533\n",
      "Epoch: [11] [ 1651/10059] total steps:[102241] lr:[0.00005000] time: 14.83s (3734s total) loss: 198.730\n",
      "Epoch: [11] [ 1661/10059] total steps:[102251] lr:[0.00005000] time: 14.87s (3749s total) loss: 124.551\n",
      "Epoch: [11] [ 1671/10059] total steps:[102261] lr:[0.00005000] time: 14.91s (3764s total) loss: 136.644\n",
      "Epoch: [11] [ 1681/10059] total steps:[102271] lr:[0.00005000] time: 14.80s (3779s total) loss: 157.407\n",
      "Epoch: [11] [ 1691/10059] total steps:[102281] lr:[0.00005000] time: 14.83s (3794s total) loss: 146.386\n",
      "Epoch: [11] [ 1701/10059] total steps:[102291] lr:[0.00005000] time: 14.88s (3808s total) loss: 103.287\n",
      "Epoch: [11] [ 1711/10059] total steps:[102301] lr:[0.00005000] time: 14.88s (3823s total) loss: 145.327\n",
      "Epoch: [11] [ 1721/10059] total steps:[102311] lr:[0.00005000] time: 14.92s (3838s total) loss: 127.778\n",
      "Epoch: [11] [ 1731/10059] total steps:[102321] lr:[0.00005000] time: 15.08s (3853s total) loss: 105.210\n",
      "Epoch: [11] [ 1741/10059] total steps:[102331] lr:[0.00005000] time: 14.93s (3868s total) loss: 177.645\n",
      "Epoch: [11] [ 1751/10059] total steps:[102341] lr:[0.00005000] time: 14.90s (3883s total) loss: 116.484\n",
      "Epoch: [11] [ 1761/10059] total steps:[102351] lr:[0.00005000] time: 14.89s (3898s total) loss: 146.476\n",
      "Epoch: [11] [ 1771/10059] total steps:[102361] lr:[0.00005000] time: 14.83s (3913s total) loss: 177.445\n",
      "Epoch: [11] [ 1781/10059] total steps:[102371] lr:[0.00005000] time: 14.97s (3928s total) loss: 98.376\n",
      "Epoch: [11] [ 1791/10059] total steps:[102381] lr:[0.00005000] time: 14.85s (3943s total) loss: 111.824\n",
      "Epoch: [11] [ 1801/10059] total steps:[102391] lr:[0.00005000] time: 14.78s (3957s total) loss: 163.243\n",
      "Epoch: [11] [ 1811/10059] total steps:[102401] lr:[0.00005000] time: 14.92s (3972s total) loss: 117.768\n",
      "Epoch: [11] [ 1821/10059] total steps:[102411] lr:[0.00005000] time: 14.92s (3987s total) loss: 114.403\n",
      "Epoch: [11] [ 1831/10059] total steps:[102421] lr:[0.00005000] time: 14.82s (4002s total) loss: 110.888\n",
      "Epoch: [11] [ 1841/10059] total steps:[102431] lr:[0.00005000] time: 14.81s (4017s total) loss: 148.673\n",
      "Epoch: [11] [ 1851/10059] total steps:[102441] lr:[0.00005000] time: 14.78s (4032s total) loss: 165.045\n",
      "Epoch: [11] [ 1861/10059] total steps:[102451] lr:[0.00005000] time: 14.66s (4046s total) loss: 146.867\n",
      "Epoch: [11] [ 1871/10059] total steps:[102461] lr:[0.00005000] time: 14.83s (4061s total) loss: 102.701\n",
      "Epoch: [11] [ 1881/10059] total steps:[102471] lr:[0.00005000] time: 14.86s (4076s total) loss: 171.997\n",
      "Epoch: [11] [ 1891/10059] total steps:[102481] lr:[0.00005000] time: 14.85s (4091s total) loss: 201.112\n",
      "Epoch: [11] [ 1901/10059] total steps:[102491] lr:[0.00005000] time: 14.68s (4106s total) loss: 143.063\n",
      "Epoch: [11] [ 1911/10059] total steps:[102501] lr:[0.00005000] time: 14.82s (4120s total) loss: 193.186\n",
      "Epoch: [11] [ 1921/10059] total steps:[102511] lr:[0.00005000] time: 14.95s (4135s total) loss: 133.924\n",
      "Epoch: [11] [ 1931/10059] total steps:[102521] lr:[0.00005000] time: 14.98s (4150s total) loss: 144.002\n",
      "Epoch: [11] [ 1941/10059] total steps:[102531] lr:[0.00005000] time: 14.82s (4165s total) loss: 193.757\n",
      "Epoch: [11] [ 1951/10059] total steps:[102541] lr:[0.00005000] time: 14.78s (4180s total) loss: 138.245\n",
      "Epoch: [11] [ 1961/10059] total steps:[102551] lr:[0.00005000] time: 14.74s (4195s total) loss: 182.748\n",
      "Epoch: [11] [ 1971/10059] total steps:[102561] lr:[0.00005000] time: 14.69s (4209s total) loss: 156.962\n",
      "Epoch: [11] [ 1981/10059] total steps:[102571] lr:[0.00005000] time: 14.72s (4224s total) loss: 121.193\n",
      "Epoch: [11] [ 1991/10059] total steps:[102581] lr:[0.00005000] time: 14.77s (4239s total) loss: 117.469\n",
      "Epoch: [11] [ 2001/10059] total steps:[102591] lr:[0.00005000] time: 14.82s (4254s total) loss: 151.111\n",
      "Epoch: [11] [ 2011/10059] total steps:[102601] lr:[0.00005000] time: 14.86s (4269s total) loss: 150.556\n",
      "Epoch: [11] [ 2021/10059] total steps:[102611] lr:[0.00005000] time: 14.69s (4283s total) loss: 131.406\n",
      "Epoch: [11] [ 2031/10059] total steps:[102621] lr:[0.00005000] time: 14.78s (4298s total) loss: 99.461\n",
      "Epoch: [11] [ 2041/10059] total steps:[102631] lr:[0.00005000] time: 14.87s (4313s total) loss: 102.349\n",
      "Epoch: [11] [ 2051/10059] total steps:[102641] lr:[0.00005000] time: 14.86s (4328s total) loss: 63.697\n",
      "Epoch: [11] [ 2061/10059] total steps:[102651] lr:[0.00005000] time: 14.81s (4343s total) loss: 169.282\n",
      "Epoch: [11] [ 2071/10059] total steps:[102661] lr:[0.00005000] time: 14.71s (4357s total) loss: 154.244\n",
      "Epoch: [11] [ 2081/10059] total steps:[102671] lr:[0.00005000] time: 14.76s (4372s total) loss: 108.919\n",
      "Epoch: [11] [ 2091/10059] total steps:[102681] lr:[0.00005000] time: 14.79s (4387s total) loss: 131.120\n",
      "Epoch: [11] [ 2101/10059] total steps:[102691] lr:[0.00005000] time: 14.80s (4402s total) loss: 110.593\n",
      "Epoch: [11] [ 2111/10059] total steps:[102701] lr:[0.00005000] time: 14.92s (4417s total) loss: 67.119\n",
      "Epoch: [11] [ 2121/10059] total steps:[102711] lr:[0.00005000] time: 14.92s (4431s total) loss: 97.690\n",
      "Epoch: [11] [ 2131/10059] total steps:[102721] lr:[0.00005000] time: 14.83s (4446s total) loss: 96.254\n",
      "Epoch: [11] [ 2141/10059] total steps:[102731] lr:[0.00005000] time: 14.85s (4461s total) loss: 164.727\n",
      "Epoch: [11] [ 2151/10059] total steps:[102741] lr:[0.00005000] time: 14.77s (4476s total) loss: 106.782\n",
      "Epoch: [11] [ 2161/10059] total steps:[102751] lr:[0.00005000] time: 14.95s (4491s total) loss: 119.988\n",
      "Epoch: [11] [ 2171/10059] total steps:[102761] lr:[0.00005000] time: 14.80s (4506s total) loss: 148.340\n",
      "Epoch: [11] [ 2181/10059] total steps:[102771] lr:[0.00005000] time: 14.81s (4521s total) loss: 163.366\n",
      "Epoch: [11] [ 2191/10059] total steps:[102781] lr:[0.00005000] time: 14.95s (4535s total) loss: 132.829\n",
      "Epoch: [11] [ 2201/10059] total steps:[102791] lr:[0.00005000] time: 14.85s (4550s total) loss: 108.668\n",
      "Epoch: [11] [ 2211/10059] total steps:[102801] lr:[0.00005000] time: 14.90s (4565s total) loss: 158.210\n",
      "Epoch: [11] [ 2221/10059] total steps:[102811] lr:[0.00005000] time: 14.71s (4580s total) loss: 125.596\n",
      "Epoch: [11] [ 2231/10059] total steps:[102821] lr:[0.00005000] time: 14.69s (4595s total) loss: 127.256\n",
      "Epoch: [11] [ 2241/10059] total steps:[102831] lr:[0.00005000] time: 14.79s (4609s total) loss: 166.484\n",
      "Epoch: [11] [ 2251/10059] total steps:[102841] lr:[0.00005000] time: 14.81s (4624s total) loss: 142.100\n",
      "Epoch: [11] [ 2261/10059] total steps:[102851] lr:[0.00005000] time: 14.79s (4639s total) loss: 119.179\n",
      "Epoch: [11] [ 2271/10059] total steps:[102861] lr:[0.00005000] time: 14.72s (4654s total) loss: 133.233\n",
      "Epoch: [11] [ 2281/10059] total steps:[102871] lr:[0.00005000] time: 14.73s (4668s total) loss: 111.961\n",
      "Epoch: [11] [ 2291/10059] total steps:[102881] lr:[0.00005000] time: 14.81s (4683s total) loss: 128.699\n",
      "Epoch: [11] [ 2301/10059] total steps:[102891] lr:[0.00005000] time: 14.84s (4698s total) loss: 153.856\n",
      "Epoch: [11] [ 2311/10059] total steps:[102901] lr:[0.00005000] time: 14.83s (4713s total) loss: 152.913\n",
      "Epoch: [11] [ 2321/10059] total steps:[102911] lr:[0.00005000] time: 14.82s (4728s total) loss: 77.551\n",
      "Epoch: [11] [ 2331/10059] total steps:[102921] lr:[0.00005000] time: 14.79s (4743s total) loss: 123.131\n",
      "Epoch: [11] [ 2341/10059] total steps:[102931] lr:[0.00005000] time: 14.72s (4757s total) loss: 177.157\n",
      "Epoch: [11] [ 2351/10059] total steps:[102941] lr:[0.00005000] time: 14.83s (4772s total) loss: 117.125\n",
      "Epoch: [11] [ 2361/10059] total steps:[102951] lr:[0.00005000] time: 14.60s (4787s total) loss: 115.906\n",
      "Epoch: [11] [ 2371/10059] total steps:[102961] lr:[0.00005000] time: 14.73s (4801s total) loss: 101.208\n",
      "Epoch: [11] [ 2381/10059] total steps:[102971] lr:[0.00005000] time: 14.86s (4816s total) loss: 138.809\n",
      "Epoch: [11] [ 2391/10059] total steps:[102981] lr:[0.00005000] time: 14.74s (4831s total) loss: 149.845\n",
      "Epoch: [11] [ 2401/10059] total steps:[102991] lr:[0.00005000] time: 14.75s (4846s total) loss: 111.333\n",
      "Epoch: [11] [ 2411/10059] total steps:[103001] lr:[0.00005000] time: 14.74s (4861s total) loss: 138.294\n",
      "Epoch: [11] [ 2421/10059] total steps:[103011] lr:[0.00005000] time: 15.02s (4876s total) loss: 120.157\n",
      "Epoch: [11] [ 2431/10059] total steps:[103021] lr:[0.00005000] time: 14.70s (4890s total) loss: 75.084\n",
      "Epoch: [11] [ 2441/10059] total steps:[103031] lr:[0.00005000] time: 14.75s (4905s total) loss: 142.956\n",
      "Epoch: [11] [ 2451/10059] total steps:[103041] lr:[0.00005000] time: 14.86s (4920s total) loss: 144.788\n",
      "Epoch: [11] [ 2461/10059] total steps:[103051] lr:[0.00005000] time: 14.87s (4935s total) loss: 127.754\n",
      "Epoch: [11] [ 2471/10059] total steps:[103061] lr:[0.00005000] time: 14.76s (4949s total) loss: 127.276\n",
      "Epoch: [11] [ 2481/10059] total steps:[103071] lr:[0.00005000] time: 14.79s (4964s total) loss: 113.661\n",
      "Epoch: [11] [ 2491/10059] total steps:[103081] lr:[0.00005000] time: 14.93s (4979s total) loss: 141.486\n",
      "Epoch: [11] [ 2501/10059] total steps:[103091] lr:[0.00005000] time: 14.75s (4994s total) loss: 141.624\n",
      "Epoch: [11] [ 2511/10059] total steps:[103101] lr:[0.00005000] time: 14.72s (5009s total) loss: 162.865\n",
      "Epoch: [11] [ 2521/10059] total steps:[103111] lr:[0.00005000] time: 14.74s (5023s total) loss: 209.435\n",
      "Epoch: [11] [ 2531/10059] total steps:[103121] lr:[0.00005000] time: 14.73s (5038s total) loss: 117.946\n",
      "Epoch: [11] [ 2541/10059] total steps:[103131] lr:[0.00005000] time: 14.73s (5053s total) loss: 184.771\n",
      "Epoch: [11] [ 2551/10059] total steps:[103141] lr:[0.00005000] time: 14.91s (5068s total) loss: 122.591\n",
      "Epoch: [11] [ 2561/10059] total steps:[103151] lr:[0.00005000] time: 14.85s (5083s total) loss: 121.159\n",
      "Epoch: [11] [ 2571/10059] total steps:[103161] lr:[0.00005000] time: 14.80s (5097s total) loss: 119.914\n",
      "Epoch: [11] [ 2581/10059] total steps:[103171] lr:[0.00005000] time: 14.67s (5112s total) loss: 147.385\n",
      "Epoch: [11] [ 2591/10059] total steps:[103181] lr:[0.00005000] time: 14.90s (5127s total) loss: 205.535\n",
      "Epoch: [11] [ 2601/10059] total steps:[103191] lr:[0.00005000] time: 14.75s (5142s total) loss: 95.151\n",
      "Epoch: [11] [ 2611/10059] total steps:[103201] lr:[0.00005000] time: 14.81s (5157s total) loss: 126.249\n",
      "Epoch: [11] [ 2621/10059] total steps:[103211] lr:[0.00005000] time: 14.81s (5171s total) loss: 100.030\n",
      "Epoch: [11] [ 2631/10059] total steps:[103221] lr:[0.00005000] time: 14.73s (5186s total) loss: 89.930\n",
      "Epoch: [11] [ 2641/10059] total steps:[103231] lr:[0.00005000] time: 14.75s (5201s total) loss: 120.113\n",
      "Epoch: [11] [ 2651/10059] total steps:[103241] lr:[0.00005000] time: 14.82s (5216s total) loss: 160.796\n",
      "Epoch: [11] [ 2661/10059] total steps:[103251] lr:[0.00005000] time: 14.80s (5230s total) loss: 92.728\n",
      "Epoch: [11] [ 2671/10059] total steps:[103261] lr:[0.00005000] time: 14.80s (5245s total) loss: 131.725\n",
      "Epoch: [11] [ 2681/10059] total steps:[103271] lr:[0.00005000] time: 14.80s (5260s total) loss: 106.373\n",
      "Epoch: [11] [ 2691/10059] total steps:[103281] lr:[0.00005000] time: 14.95s (5275s total) loss: 148.053\n",
      "Epoch: [11] [ 2701/10059] total steps:[103291] lr:[0.00005000] time: 14.77s (5290s total) loss: 102.506\n",
      "Epoch: [11] [ 2711/10059] total steps:[103301] lr:[0.00005000] time: 14.79s (5305s total) loss: 153.396\n",
      "Epoch: [11] [ 2721/10059] total steps:[103311] lr:[0.00005000] time: 14.78s (5319s total) loss: 132.410\n",
      "Epoch: [11] [ 2731/10059] total steps:[103321] lr:[0.00005000] time: 14.83s (5334s total) loss: 77.035\n",
      "Epoch: [11] [ 2741/10059] total steps:[103331] lr:[0.00005000] time: 14.81s (5349s total) loss: 133.917\n",
      "Epoch: [11] [ 2751/10059] total steps:[103341] lr:[0.00005000] time: 14.71s (5364s total) loss: 145.673\n",
      "Epoch: [11] [ 2761/10059] total steps:[103351] lr:[0.00005000] time: 14.77s (5378s total) loss: 148.349\n",
      "Epoch: [11] [ 2771/10059] total steps:[103361] lr:[0.00005000] time: 14.84s (5393s total) loss: 125.152\n",
      "Epoch: [11] [ 2781/10059] total steps:[103371] lr:[0.00005000] time: 16.45s (5410s total) loss: 118.318\n",
      "Epoch: [11] [ 2791/10059] total steps:[103381] lr:[0.00005000] time: 14.94s (5425s total) loss: 163.889\n",
      "Epoch: [11] [ 2801/10059] total steps:[103391] lr:[0.00005000] time: 14.79s (5439s total) loss: 168.323\n",
      "Epoch: [11] [ 2811/10059] total steps:[103401] lr:[0.00005000] time: 14.76s (5454s total) loss: 168.327\n",
      "Epoch: [11] [ 2821/10059] total steps:[103411] lr:[0.00005000] time: 14.74s (5469s total) loss: 168.934\n",
      "Epoch: [11] [ 2831/10059] total steps:[103421] lr:[0.00005000] time: 14.74s (5484s total) loss: 113.247\n",
      "Epoch: [11] [ 2841/10059] total steps:[103431] lr:[0.00005000] time: 14.77s (5499s total) loss: 113.968\n",
      "Epoch: [11] [ 2851/10059] total steps:[103441] lr:[0.00005000] time: 14.75s (5513s total) loss: 132.900\n",
      "Epoch: [11] [ 2861/10059] total steps:[103451] lr:[0.00005000] time: 14.87s (5528s total) loss: 129.692\n",
      "Epoch: [11] [ 2871/10059] total steps:[103461] lr:[0.00005000] time: 14.88s (5543s total) loss: 91.174\n",
      "Epoch: [11] [ 2881/10059] total steps:[103471] lr:[0.00005000] time: 14.81s (5558s total) loss: 128.302\n",
      "Epoch: [11] [ 2891/10059] total steps:[103481] lr:[0.00005000] time: 14.83s (5573s total) loss: 112.789\n",
      "Epoch: [11] [ 2901/10059] total steps:[103491] lr:[0.00005000] time: 14.71s (5587s total) loss: 109.827\n",
      "Epoch: [11] [ 2911/10059] total steps:[103501] lr:[0.00005000] time: 14.81s (5602s total) loss: 137.699\n",
      "Epoch: [11] [ 2921/10059] total steps:[103511] lr:[0.00005000] time: 14.92s (5617s total) loss: 145.612\n",
      "Epoch: [11] [ 2931/10059] total steps:[103521] lr:[0.00005000] time: 14.78s (5632s total) loss: 103.662\n",
      "Epoch: [11] [ 2941/10059] total steps:[103531] lr:[0.00005000] time: 14.82s (5647s total) loss: 127.295\n",
      "Epoch: [11] [ 2951/10059] total steps:[103541] lr:[0.00005000] time: 14.79s (5661s total) loss: 201.848\n",
      "Epoch: [11] [ 2961/10059] total steps:[103551] lr:[0.00005000] time: 14.81s (5676s total) loss: 183.108\n",
      "Epoch: [11] [ 2971/10059] total steps:[103561] lr:[0.00005000] time: 14.65s (5691s total) loss: 126.154\n",
      "Epoch: [11] [ 2981/10059] total steps:[103571] lr:[0.00005000] time: 14.74s (5706s total) loss: 204.464\n",
      "Epoch: [11] [ 2991/10059] total steps:[103581] lr:[0.00005000] time: 14.80s (5720s total) loss: 190.690\n",
      "Epoch: [11] [ 3001/10059] total steps:[103591] lr:[0.00005000] time: 14.84s (5735s total) loss: 134.808\n",
      "Epoch: [11] [ 3011/10059] total steps:[103601] lr:[0.00005000] time: 14.81s (5750s total) loss: 120.167\n",
      "Epoch: [11] [ 3021/10059] total steps:[103611] lr:[0.00005000] time: 14.75s (5765s total) loss: 119.368\n",
      "Epoch: [11] [ 3031/10059] total steps:[103621] lr:[0.00005000] time: 14.79s (5780s total) loss: 157.962\n",
      "Epoch: [11] [ 3041/10059] total steps:[103631] lr:[0.00005000] time: 14.79s (5794s total) loss: 107.805\n",
      "Epoch: [11] [ 3051/10059] total steps:[103641] lr:[0.00005000] time: 14.68s (5809s total) loss: 130.684\n",
      "Epoch: [11] [ 3061/10059] total steps:[103651] lr:[0.00005000] time: 14.85s (5824s total) loss: 105.218\n",
      "Epoch: [11] [ 3071/10059] total steps:[103661] lr:[0.00005000] time: 14.77s (5839s total) loss: 140.306\n",
      "Epoch: [11] [ 3081/10059] total steps:[103671] lr:[0.00005000] time: 14.81s (5854s total) loss: 137.770\n",
      "Epoch: [11] [ 3091/10059] total steps:[103681] lr:[0.00005000] time: 14.79s (5868s total) loss: 106.232\n",
      "Epoch: [11] [ 3101/10059] total steps:[103691] lr:[0.00005000] time: 15.02s (5883s total) loss: 156.740\n",
      "Epoch: [11] [ 3111/10059] total steps:[103701] lr:[0.00005000] time: 14.92s (5898s total) loss: 154.883\n",
      "Epoch: [11] [ 3121/10059] total steps:[103711] lr:[0.00005000] time: 14.80s (5913s total) loss: 167.760\n",
      "Epoch: [11] [ 3131/10059] total steps:[103721] lr:[0.00005000] time: 14.95s (5928s total) loss: 159.217\n",
      "Epoch: [11] [ 3141/10059] total steps:[103731] lr:[0.00005000] time: 15.04s (5943s total) loss: 126.462\n",
      "Epoch: [11] [ 3151/10059] total steps:[103741] lr:[0.00005000] time: 14.83s (5958s total) loss: 150.152\n",
      "Epoch: [11] [ 3161/10059] total steps:[103751] lr:[0.00005000] time: 14.83s (5973s total) loss: 136.993\n",
      "Epoch: [11] [ 3171/10059] total steps:[103761] lr:[0.00005000] time: 14.79s (5988s total) loss: 90.080\n",
      "Epoch: [11] [ 3181/10059] total steps:[103771] lr:[0.00005000] time: 15.08s (6003s total) loss: 128.894\n",
      "Epoch: [11] [ 3191/10059] total steps:[103781] lr:[0.00005000] time: 14.79s (6017s total) loss: 95.964\n",
      "Epoch: [11] [ 3201/10059] total steps:[103791] lr:[0.00005000] time: 14.84s (6032s total) loss: 111.357\n",
      "Epoch: [11] [ 3211/10059] total steps:[103801] lr:[0.00005000] time: 14.74s (6047s total) loss: 188.737\n",
      "Epoch: [11] [ 3221/10059] total steps:[103811] lr:[0.00005000] time: 14.73s (6062s total) loss: 195.032\n",
      "Epoch: [11] [ 3231/10059] total steps:[103821] lr:[0.00005000] time: 14.69s (6076s total) loss: 182.625\n",
      "Epoch: [11] [ 3241/10059] total steps:[103831] lr:[0.00005000] time: 14.77s (6091s total) loss: 145.984\n",
      "Epoch: [11] [ 3251/10059] total steps:[103841] lr:[0.00005000] time: 15.00s (6106s total) loss: 140.095\n",
      "Epoch: [11] [ 3261/10059] total steps:[103851] lr:[0.00005000] time: 14.67s (6121s total) loss: 110.484\n",
      "Epoch: [11] [ 3271/10059] total steps:[103861] lr:[0.00005000] time: 14.83s (6136s total) loss: 108.738\n",
      "Epoch: [11] [ 3281/10059] total steps:[103871] lr:[0.00005000] time: 14.75s (6150s total) loss: 138.271\n",
      "Epoch: [11] [ 3291/10059] total steps:[103881] lr:[0.00005000] time: 14.78s (6165s total) loss: 135.276\n",
      "Epoch: [11] [ 3301/10059] total steps:[103891] lr:[0.00005000] time: 14.73s (6180s total) loss: 212.881\n",
      "Epoch: [11] [ 3311/10059] total steps:[103901] lr:[0.00005000] time: 14.88s (6195s total) loss: 98.620\n",
      "Epoch: [11] [ 3321/10059] total steps:[103911] lr:[0.00005000] time: 14.82s (6210s total) loss: 115.402\n",
      "Epoch: [11] [ 3331/10059] total steps:[103921] lr:[0.00005000] time: 14.69s (6224s total) loss: 101.906\n",
      "Epoch: [11] [ 3341/10059] total steps:[103931] lr:[0.00005000] time: 14.89s (6239s total) loss: 127.254\n",
      "Epoch: [11] [ 3351/10059] total steps:[103941] lr:[0.00005000] time: 14.75s (6254s total) loss: 140.244\n",
      "Epoch: [11] [ 3361/10059] total steps:[103951] lr:[0.00005000] time: 14.69s (6269s total) loss: 88.908\n",
      "Epoch: [11] [ 3371/10059] total steps:[103961] lr:[0.00005000] time: 14.76s (6283s total) loss: 143.468\n",
      "Epoch: [11] [ 3381/10059] total steps:[103971] lr:[0.00005000] time: 14.76s (6298s total) loss: 112.089\n",
      "Epoch: [11] [ 3391/10059] total steps:[103981] lr:[0.00005000] time: 14.83s (6313s total) loss: 148.686\n",
      "Epoch: [11] [ 3401/10059] total steps:[103991] lr:[0.00005000] time: 14.79s (6328s total) loss: 149.173\n",
      "Epoch: [11] [ 3411/10059] total steps:[104001] lr:[0.00005000] time: 14.99s (6343s total) loss: 132.863\n",
      "Epoch: [11] [ 3421/10059] total steps:[104011] lr:[0.00005000] time: 14.65s (6357s total) loss: 117.161\n",
      "Epoch: [11] [ 3431/10059] total steps:[104021] lr:[0.00005000] time: 14.75s (6372s total) loss: 168.668\n",
      "Epoch: [11] [ 3441/10059] total steps:[104031] lr:[0.00005000] time: 14.64s (6387s total) loss: 100.910\n",
      "Epoch: [11] [ 3451/10059] total steps:[104041] lr:[0.00005000] time: 14.95s (6402s total) loss: 123.619\n",
      "Epoch: [11] [ 3461/10059] total steps:[104051] lr:[0.00005000] time: 14.83s (6417s total) loss: 135.939\n",
      "Epoch: [11] [ 3471/10059] total steps:[104061] lr:[0.00005000] time: 14.71s (6431s total) loss: 118.541\n",
      "Epoch: [11] [ 3481/10059] total steps:[104071] lr:[0.00005000] time: 14.68s (6446s total) loss: 109.744\n",
      "Epoch: [11] [ 3491/10059] total steps:[104081] lr:[0.00005000] time: 14.87s (6461s total) loss: 181.945\n",
      "Epoch: [11] [ 3501/10059] total steps:[104091] lr:[0.00005000] time: 14.76s (6476s total) loss: 94.523\n",
      "Epoch: [11] [ 3511/10059] total steps:[104101] lr:[0.00005000] time: 14.81s (6490s total) loss: 141.292\n",
      "Epoch: [11] [ 3521/10059] total steps:[104111] lr:[0.00005000] time: 14.78s (6505s total) loss: 129.239\n",
      "Epoch: [11] [ 3531/10059] total steps:[104121] lr:[0.00005000] time: 14.72s (6520s total) loss: 134.828\n",
      "Epoch: [11] [ 3541/10059] total steps:[104131] lr:[0.00005000] time: 14.87s (6535s total) loss: 165.777\n",
      "Epoch: [11] [ 3551/10059] total steps:[104141] lr:[0.00005000] time: 14.73s (6550s total) loss: 223.638\n",
      "Epoch: [11] [ 3561/10059] total steps:[104151] lr:[0.00005000] time: 14.79s (6564s total) loss: 113.488\n",
      "Epoch: [11] [ 3571/10059] total steps:[104161] lr:[0.00005000] time: 14.71s (6579s total) loss: 187.868\n",
      "Epoch: [11] [ 3581/10059] total steps:[104171] lr:[0.00005000] time: 14.68s (6594s total) loss: 116.018\n",
      "Epoch: [11] [ 3591/10059] total steps:[104181] lr:[0.00005000] time: 14.72s (6608s total) loss: 100.935\n",
      "Epoch: [11] [ 3601/10059] total steps:[104191] lr:[0.00005000] time: 14.77s (6623s total) loss: 84.807\n",
      "Epoch: [11] [ 3611/10059] total steps:[104201] lr:[0.00005000] time: 14.76s (6638s total) loss: 108.888\n",
      "Epoch: [11] [ 3621/10059] total steps:[104211] lr:[0.00005000] time: 14.82s (6653s total) loss: 169.925\n",
      "Epoch: [11] [ 3631/10059] total steps:[104221] lr:[0.00005000] time: 14.70s (6668s total) loss: 157.239\n",
      "Epoch: [11] [ 3641/10059] total steps:[104231] lr:[0.00005000] time: 14.72s (6682s total) loss: 118.000\n",
      "Epoch: [11] [ 3651/10059] total steps:[104241] lr:[0.00005000] time: 14.68s (6697s total) loss: 143.103\n",
      "Epoch: [11] [ 3661/10059] total steps:[104251] lr:[0.00005000] time: 14.69s (6712s total) loss: 119.589\n",
      "Epoch: [11] [ 3671/10059] total steps:[104261] lr:[0.00005000] time: 14.68s (6726s total) loss: 119.525\n",
      "Epoch: [11] [ 3681/10059] total steps:[104271] lr:[0.00005000] time: 14.82s (6741s total) loss: 173.147\n",
      "Epoch: [11] [ 3691/10059] total steps:[104281] lr:[0.00005000] time: 14.93s (6756s total) loss: 105.087\n",
      "Epoch: [11] [ 3701/10059] total steps:[104291] lr:[0.00005000] time: 14.66s (6771s total) loss: 110.971\n",
      "Epoch: [11] [ 3711/10059] total steps:[104301] lr:[0.00005000] time: 14.71s (6785s total) loss: 154.148\n",
      "Epoch: [11] [ 3721/10059] total steps:[104311] lr:[0.00005000] time: 14.83s (6800s total) loss: 183.856\n",
      "Epoch: [11] [ 3731/10059] total steps:[104321] lr:[0.00005000] time: 14.80s (6815s total) loss: 147.555\n",
      "Epoch: [11] [ 3741/10059] total steps:[104331] lr:[0.00005000] time: 14.73s (6830s total) loss: 115.318\n",
      "Epoch: [11] [ 3751/10059] total steps:[104341] lr:[0.00005000] time: 14.83s (6845s total) loss: 169.364\n",
      "Epoch: [11] [ 3761/10059] total steps:[104351] lr:[0.00005000] time: 14.67s (6859s total) loss: 143.667\n",
      "Epoch: [11] [ 3771/10059] total steps:[104361] lr:[0.00005000] time: 14.81s (6874s total) loss: 187.859\n",
      "Epoch: [11] [ 3781/10059] total steps:[104371] lr:[0.00005000] time: 14.75s (6889s total) loss: 102.020\n",
      "Epoch: [11] [ 3791/10059] total steps:[104381] lr:[0.00005000] time: 14.82s (6904s total) loss: 176.845\n",
      "Epoch: [11] [ 3801/10059] total steps:[104391] lr:[0.00005000] time: 14.73s (6918s total) loss: 194.004\n",
      "Epoch: [11] [ 3811/10059] total steps:[104401] lr:[0.00005000] time: 14.87s (6933s total) loss: 128.135\n",
      "Epoch: [11] [ 3821/10059] total steps:[104411] lr:[0.00005000] time: 14.71s (6948s total) loss: 155.939\n",
      "Epoch: [11] [ 3831/10059] total steps:[104421] lr:[0.00005000] time: 14.96s (6963s total) loss: 131.384\n",
      "Epoch: [11] [ 3841/10059] total steps:[104431] lr:[0.00005000] time: 14.63s (6978s total) loss: 132.648\n",
      "Epoch: [11] [ 3851/10059] total steps:[104441] lr:[0.00005000] time: 14.74s (6992s total) loss: 140.329\n",
      "Epoch: [11] [ 3861/10059] total steps:[104451] lr:[0.00005000] time: 14.77s (7007s total) loss: 208.496\n",
      "Epoch: [11] [ 3871/10059] total steps:[104461] lr:[0.00005000] time: 14.82s (7022s total) loss: 121.234\n",
      "Epoch: [11] [ 3881/10059] total steps:[104471] lr:[0.00005000] time: 14.87s (7037s total) loss: 147.476\n",
      "Epoch: [11] [ 3891/10059] total steps:[104481] lr:[0.00005000] time: 14.73s (7051s total) loss: 141.397\n",
      "Epoch: [11] [ 3901/10059] total steps:[104491] lr:[0.00005000] time: 14.79s (7066s total) loss: 174.601\n",
      "Epoch: [11] [ 3911/10059] total steps:[104501] lr:[0.00005000] time: 14.79s (7081s total) loss: 148.256\n",
      "Epoch: [11] [ 3921/10059] total steps:[104511] lr:[0.00005000] time: 14.77s (7096s total) loss: 146.445\n",
      "Epoch: [11] [ 3931/10059] total steps:[104521] lr:[0.00005000] time: 14.81s (7111s total) loss: 140.023\n",
      "Epoch: [11] [ 3941/10059] total steps:[104531] lr:[0.00005000] time: 14.78s (7125s total) loss: 154.338\n",
      "Epoch: [11] [ 3951/10059] total steps:[104541] lr:[0.00005000] time: 14.77s (7140s total) loss: 131.215\n",
      "Epoch: [11] [ 3961/10059] total steps:[104551] lr:[0.00005000] time: 14.69s (7155s total) loss: 130.896\n",
      "Epoch: [11] [ 3971/10059] total steps:[104561] lr:[0.00005000] time: 14.85s (7170s total) loss: 117.647\n",
      "Epoch: [11] [ 3981/10059] total steps:[104571] lr:[0.00005000] time: 14.93s (7185s total) loss: 76.343\n",
      "Epoch: [11] [ 3991/10059] total steps:[104581] lr:[0.00005000] time: 14.73s (7199s total) loss: 113.124\n",
      "Epoch: [11] [ 4001/10059] total steps:[104591] lr:[0.00005000] time: 14.71s (7214s total) loss: 95.517\n",
      "Epoch: [11] [ 4011/10059] total steps:[104601] lr:[0.00005000] time: 14.85s (7229s total) loss: 113.802\n",
      "Epoch: [11] [ 4021/10059] total steps:[104611] lr:[0.00005000] time: 14.73s (7244s total) loss: 149.565\n",
      "Epoch: [11] [ 4031/10059] total steps:[104621] lr:[0.00005000] time: 14.82s (7259s total) loss: 122.851\n",
      "Epoch: [11] [ 4041/10059] total steps:[104631] lr:[0.00005000] time: 14.81s (7273s total) loss: 141.668\n",
      "Epoch: [11] [ 4051/10059] total steps:[104641] lr:[0.00005000] time: 14.76s (7288s total) loss: 142.848\n",
      "Epoch: [11] [ 4061/10059] total steps:[104651] lr:[0.00005000] time: 14.90s (7303s total) loss: 126.277\n",
      "Epoch: [11] [ 4071/10059] total steps:[104661] lr:[0.00005000] time: 14.93s (7318s total) loss: 120.215\n",
      "Epoch: [11] [ 4081/10059] total steps:[104671] lr:[0.00005000] time: 14.75s (7333s total) loss: 152.972\n",
      "Epoch: [11] [ 4091/10059] total steps:[104681] lr:[0.00005000] time: 14.71s (7347s total) loss: 127.054\n",
      "Epoch: [11] [ 4101/10059] total steps:[104691] lr:[0.00005000] time: 14.83s (7362s total) loss: 131.309\n",
      "Epoch: [11] [ 4111/10059] total steps:[104701] lr:[0.00005000] time: 14.90s (7377s total) loss: 122.104\n",
      "Epoch: [11] [ 4121/10059] total steps:[104711] lr:[0.00005000] time: 14.73s (7392s total) loss: 137.723\n",
      "Epoch: [11] [ 4131/10059] total steps:[104721] lr:[0.00005000] time: 14.89s (7407s total) loss: 107.884\n",
      "Epoch: [11] [ 4141/10059] total steps:[104731] lr:[0.00005000] time: 14.78s (7421s total) loss: 130.170\n",
      "Epoch: [11] [ 4151/10059] total steps:[104741] lr:[0.00005000] time: 14.64s (7436s total) loss: 192.109\n",
      "Epoch: [11] [ 4161/10059] total steps:[104751] lr:[0.00005000] time: 14.73s (7451s total) loss: 156.412\n",
      "Epoch: [11] [ 4171/10059] total steps:[104761] lr:[0.00005000] time: 14.74s (7466s total) loss: 175.869\n",
      "Epoch: [11] [ 4181/10059] total steps:[104771] lr:[0.00005000] time: 14.87s (7480s total) loss: 121.861\n",
      "Epoch: [11] [ 4191/10059] total steps:[104781] lr:[0.00005000] time: 14.74s (7495s total) loss: 145.827\n",
      "Epoch: [11] [ 4201/10059] total steps:[104791] lr:[0.00005000] time: 14.81s (7510s total) loss: 140.238\n",
      "Epoch: [11] [ 4211/10059] total steps:[104801] lr:[0.00005000] time: 14.82s (7525s total) loss: 116.390\n",
      "Epoch: [11] [ 4221/10059] total steps:[104811] lr:[0.00005000] time: 14.73s (7540s total) loss: 139.705\n",
      "Epoch: [11] [ 4231/10059] total steps:[104821] lr:[0.00005000] time: 14.80s (7554s total) loss: 109.036\n",
      "Epoch: [11] [ 4241/10059] total steps:[104831] lr:[0.00005000] time: 14.81s (7569s total) loss: 155.054\n",
      "Epoch: [11] [ 4251/10059] total steps:[104841] lr:[0.00005000] time: 14.78s (7584s total) loss: 165.323\n",
      "Epoch: [11] [ 4261/10059] total steps:[104851] lr:[0.00005000] time: 14.83s (7599s total) loss: 126.252\n",
      "Epoch: [11] [ 4271/10059] total steps:[104861] lr:[0.00005000] time: 14.82s (7614s total) loss: 122.823\n",
      "Epoch: [11] [ 4281/10059] total steps:[104871] lr:[0.00005000] time: 14.75s (7628s total) loss: 101.019\n",
      "Epoch: [11] [ 4291/10059] total steps:[104881] lr:[0.00005000] time: 14.85s (7643s total) loss: 133.302\n",
      "Epoch: [11] [ 4301/10059] total steps:[104891] lr:[0.00005000] time: 14.75s (7658s total) loss: 106.231\n",
      "Epoch: [11] [ 4311/10059] total steps:[104901] lr:[0.00005000] time: 14.96s (7673s total) loss: 141.874\n",
      "Epoch: [11] [ 4321/10059] total steps:[104911] lr:[0.00005000] time: 14.92s (7688s total) loss: 102.547\n",
      "Epoch: [11] [ 4331/10059] total steps:[104921] lr:[0.00005000] time: 14.67s (7703s total) loss: 158.431\n",
      "Epoch: [11] [ 4341/10059] total steps:[104931] lr:[0.00005000] time: 14.65s (7717s total) loss: 128.992\n",
      "Epoch: [11] [ 4351/10059] total steps:[104941] lr:[0.00005000] time: 14.96s (7732s total) loss: 121.372\n",
      "Epoch: [11] [ 4361/10059] total steps:[104951] lr:[0.00005000] time: 14.78s (7747s total) loss: 152.199\n",
      "Epoch: [11] [ 4371/10059] total steps:[104961] lr:[0.00005000] time: 14.86s (7762s total) loss: 172.935\n",
      "Epoch: [11] [ 4381/10059] total steps:[104971] lr:[0.00005000] time: 14.79s (7777s total) loss: 138.281\n",
      "Epoch: [11] [ 4391/10059] total steps:[104981] lr:[0.00005000] time: 14.87s (7791s total) loss: 244.708\n",
      "Epoch: [11] [ 4401/10059] total steps:[104991] lr:[0.00005000] time: 14.79s (7806s total) loss: 74.434\n",
      "Epoch: [11] [ 4411/10059] total steps:[105001] lr:[0.00005000] time: 14.83s (7821s total) loss: 120.634\n",
      "Epoch: [11] [ 4421/10059] total steps:[105011] lr:[0.00005000] time: 14.71s (7836s total) loss: 129.382\n",
      "Epoch: [11] [ 4431/10059] total steps:[105021] lr:[0.00005000] time: 14.71s (7850s total) loss: 100.333\n",
      "Epoch: [11] [ 4441/10059] total steps:[105031] lr:[0.00005000] time: 14.83s (7865s total) loss: 115.191\n",
      "Epoch: [11] [ 4451/10059] total steps:[105041] lr:[0.00005000] time: 14.77s (7880s total) loss: 159.198\n",
      "Epoch: [11] [ 4461/10059] total steps:[105051] lr:[0.00005000] time: 14.84s (7895s total) loss: 138.942\n",
      "Epoch: [11] [ 4471/10059] total steps:[105061] lr:[0.00005000] time: 14.74s (7910s total) loss: 130.401\n",
      "Epoch: [11] [ 4481/10059] total steps:[105071] lr:[0.00005000] time: 14.73s (7924s total) loss: 106.070\n",
      "Epoch: [11] [ 4491/10059] total steps:[105081] lr:[0.00005000] time: 14.72s (7939s total) loss: 191.023\n",
      "Epoch: [11] [ 4501/10059] total steps:[105091] lr:[0.00005000] time: 15.04s (7954s total) loss: 161.991\n",
      "Epoch: [11] [ 4511/10059] total steps:[105101] lr:[0.00005000] time: 14.94s (7969s total) loss: 99.132\n",
      "Epoch: [11] [ 4521/10059] total steps:[105111] lr:[0.00005000] time: 14.80s (7984s total) loss: 94.784\n",
      "Epoch: [11] [ 4531/10059] total steps:[105121] lr:[0.00005000] time: 14.80s (7999s total) loss: 112.501\n",
      "Epoch: [11] [ 4541/10059] total steps:[105131] lr:[0.00005000] time: 14.86s (8014s total) loss: 127.119\n",
      "Epoch: [11] [ 4551/10059] total steps:[105141] lr:[0.00005000] time: 14.84s (8028s total) loss: 129.532\n",
      "Epoch: [11] [ 4561/10059] total steps:[105151] lr:[0.00005000] time: 14.67s (8043s total) loss: 116.664\n",
      "Epoch: [11] [ 4571/10059] total steps:[105161] lr:[0.00005000] time: 14.77s (8058s total) loss: 124.365\n",
      "Epoch: [11] [ 4581/10059] total steps:[105171] lr:[0.00005000] time: 14.72s (8073s total) loss: 202.145\n",
      "Epoch: [11] [ 4591/10059] total steps:[105181] lr:[0.00005000] time: 14.69s (8087s total) loss: 131.596\n",
      "Epoch: [11] [ 4601/10059] total steps:[105191] lr:[0.00005000] time: 14.64s (8102s total) loss: 135.879\n",
      "Epoch: [11] [ 4611/10059] total steps:[105201] lr:[0.00005000] time: 14.80s (8117s total) loss: 195.175\n",
      "Epoch: [11] [ 4621/10059] total steps:[105211] lr:[0.00005000] time: 14.77s (8131s total) loss: 99.382\n",
      "Epoch: [11] [ 4631/10059] total steps:[105221] lr:[0.00005000] time: 14.63s (8146s total) loss: 108.684\n",
      "Epoch: [11] [ 4641/10059] total steps:[105231] lr:[0.00005000] time: 14.83s (8161s total) loss: 201.074\n",
      "Epoch: [11] [ 4651/10059] total steps:[105241] lr:[0.00005000] time: 14.78s (8176s total) loss: 115.501\n",
      "Epoch: [11] [ 4661/10059] total steps:[105251] lr:[0.00005000] time: 14.80s (8191s total) loss: 115.067\n",
      "Epoch: [11] [ 4671/10059] total steps:[105261] lr:[0.00005000] time: 14.81s (8205s total) loss: 105.611\n",
      "Epoch: [11] [ 4681/10059] total steps:[105271] lr:[0.00005000] time: 14.75s (8220s total) loss: 158.589\n",
      "Epoch: [11] [ 4691/10059] total steps:[105281] lr:[0.00005000] time: 14.73s (8235s total) loss: 110.029\n",
      "Epoch: [11] [ 4701/10059] total steps:[105291] lr:[0.00005000] time: 14.81s (8250s total) loss: 152.932\n",
      "Epoch: [11] [ 4711/10059] total steps:[105301] lr:[0.00005000] time: 14.82s (8264s total) loss: 123.722\n",
      "Epoch: [11] [ 4721/10059] total steps:[105311] lr:[0.00005000] time: 14.92s (8279s total) loss: 150.647\n",
      "Epoch: [11] [ 4731/10059] total steps:[105321] lr:[0.00005000] time: 14.77s (8294s total) loss: 116.049\n",
      "Epoch: [11] [ 4741/10059] total steps:[105331] lr:[0.00005000] time: 14.87s (8309s total) loss: 156.441\n",
      "Epoch: [11] [ 4751/10059] total steps:[105341] lr:[0.00005000] time: 14.68s (8324s total) loss: 130.944\n",
      "Epoch: [11] [ 4761/10059] total steps:[105351] lr:[0.00005000] time: 14.75s (8338s total) loss: 165.915\n",
      "Epoch: [11] [ 4771/10059] total steps:[105361] lr:[0.00005000] time: 14.78s (8353s total) loss: 116.139\n",
      "Epoch: [11] [ 4781/10059] total steps:[105371] lr:[0.00005000] time: 14.77s (8368s total) loss: 104.152\n",
      "Epoch: [11] [ 4791/10059] total steps:[105381] lr:[0.00005000] time: 14.78s (8383s total) loss: 131.363\n",
      "Epoch: [11] [ 4801/10059] total steps:[105391] lr:[0.00005000] time: 14.68s (8397s total) loss: 146.932\n",
      "Epoch: [11] [ 4811/10059] total steps:[105401] lr:[0.00005000] time: 14.81s (8412s total) loss: 172.297\n",
      "Epoch: [11] [ 4821/10059] total steps:[105411] lr:[0.00005000] time: 14.89s (8427s total) loss: 159.419\n",
      "Epoch: [11] [ 4831/10059] total steps:[105421] lr:[0.00005000] time: 14.74s (8442s total) loss: 100.675\n",
      "Epoch: [11] [ 4841/10059] total steps:[105431] lr:[0.00005000] time: 14.90s (8457s total) loss: 137.497\n",
      "Epoch: [11] [ 4851/10059] total steps:[105441] lr:[0.00005000] time: 14.85s (8472s total) loss: 115.279\n",
      "Epoch: [11] [ 4861/10059] total steps:[105451] lr:[0.00005000] time: 14.71s (8486s total) loss: 107.233\n",
      "Epoch: [11] [ 4871/10059] total steps:[105461] lr:[0.00005000] time: 14.75s (8501s total) loss: 164.204\n",
      "Epoch: [11] [ 4881/10059] total steps:[105471] lr:[0.00005000] time: 14.79s (8516s total) loss: 143.936\n",
      "Epoch: [11] [ 4891/10059] total steps:[105481] lr:[0.00005000] time: 14.84s (8531s total) loss: 79.347\n",
      "Epoch: [11] [ 4901/10059] total steps:[105491] lr:[0.00005000] time: 14.84s (8546s total) loss: 216.505\n",
      "Epoch: [11] [ 4911/10059] total steps:[105501] lr:[0.00005000] time: 14.98s (8561s total) loss: 130.247\n",
      "Epoch: [11] [ 4921/10059] total steps:[105511] lr:[0.00005000] time: 14.72s (8575s total) loss: 127.381\n",
      "Epoch: [11] [ 4931/10059] total steps:[105521] lr:[0.00005000] time: 14.73s (8590s total) loss: 107.740\n",
      "Epoch: [11] [ 4941/10059] total steps:[105531] lr:[0.00005000] time: 14.78s (8605s total) loss: 160.736\n",
      "Epoch: [11] [ 4951/10059] total steps:[105541] lr:[0.00005000] time: 14.81s (8620s total) loss: 129.111\n",
      "Epoch: [11] [ 4961/10059] total steps:[105551] lr:[0.00005000] time: 14.91s (8634s total) loss: 147.857\n",
      "Epoch: [11] [ 4971/10059] total steps:[105561] lr:[0.00005000] time: 14.70s (8649s total) loss: 156.842\n",
      "Epoch: [11] [ 4981/10059] total steps:[105571] lr:[0.00005000] time: 14.81s (8664s total) loss: 110.587\n",
      "Epoch: [11] [ 4991/10059] total steps:[105581] lr:[0.00005000] time: 14.83s (8679s total) loss: 111.569\n",
      "Epoch: [11] [ 5001/10059] total steps:[105591] lr:[0.00005000] time: 14.76s (8694s total) loss: 135.413\n",
      "Epoch: [11] [ 5011/10059] total steps:[105601] lr:[0.00005000] time: 14.69s (8708s total) loss: 155.471\n",
      "Epoch: [11] [ 5021/10059] total steps:[105611] lr:[0.00005000] time: 14.74s (8723s total) loss: 151.386\n",
      "Epoch: [11] [ 5031/10059] total steps:[105621] lr:[0.00005000] time: 14.75s (8738s total) loss: 119.581\n",
      "Epoch: [11] [ 5041/10059] total steps:[105631] lr:[0.00005000] time: 14.85s (8753s total) loss: 132.805\n",
      "Epoch: [11] [ 5051/10059] total steps:[105641] lr:[0.00005000] time: 14.83s (8767s total) loss: 150.741\n",
      "Epoch: [11] [ 5061/10059] total steps:[105651] lr:[0.00005000] time: 14.87s (8782s total) loss: 114.861\n",
      "Epoch: [11] [ 5071/10059] total steps:[105661] lr:[0.00005000] time: 14.78s (8797s total) loss: 156.059\n",
      "Epoch: [11] [ 5081/10059] total steps:[105671] lr:[0.00005000] time: 14.71s (8812s total) loss: 132.826\n",
      "Epoch: [11] [ 5091/10059] total steps:[105681] lr:[0.00005000] time: 14.78s (8827s total) loss: 97.515\n",
      "Epoch: [11] [ 5101/10059] total steps:[105691] lr:[0.00005000] time: 14.75s (8841s total) loss: 202.940\n",
      "Epoch: [11] [ 5111/10059] total steps:[105701] lr:[0.00005000] time: 14.72s (8856s total) loss: 89.359\n",
      "Epoch: [11] [ 5121/10059] total steps:[105711] lr:[0.00005000] time: 14.80s (8871s total) loss: 167.351\n",
      "Epoch: [11] [ 5131/10059] total steps:[105721] lr:[0.00005000] time: 14.70s (8886s total) loss: 90.108\n",
      "Epoch: [11] [ 5141/10059] total steps:[105731] lr:[0.00005000] time: 14.79s (8900s total) loss: 119.931\n",
      "Epoch: [11] [ 5151/10059] total steps:[105741] lr:[0.00005000] time: 14.89s (8915s total) loss: 125.176\n",
      "Epoch: [11] [ 5161/10059] total steps:[105751] lr:[0.00005000] time: 14.82s (8930s total) loss: 188.458\n",
      "Epoch: [11] [ 5171/10059] total steps:[105761] lr:[0.00005000] time: 14.82s (8945s total) loss: 136.703\n",
      "Epoch: [11] [ 5181/10059] total steps:[105771] lr:[0.00005000] time: 14.65s (8959s total) loss: 138.423\n",
      "Epoch: [11] [ 5191/10059] total steps:[105781] lr:[0.00005000] time: 14.63s (8974s total) loss: 160.784\n",
      "Epoch: [11] [ 5201/10059] total steps:[105791] lr:[0.00005000] time: 14.76s (8989s total) loss: 121.542\n",
      "Epoch: [11] [ 5211/10059] total steps:[105801] lr:[0.00005000] time: 14.86s (9004s total) loss: 108.830\n",
      "Epoch: [11] [ 5221/10059] total steps:[105811] lr:[0.00005000] time: 14.86s (9019s total) loss: 147.114\n",
      "Epoch: [11] [ 5231/10059] total steps:[105821] lr:[0.00005000] time: 14.77s (9033s total) loss: 91.320\n",
      "Epoch: [11] [ 5241/10059] total steps:[105831] lr:[0.00005000] time: 14.73s (9048s total) loss: 117.721\n",
      "Epoch: [11] [ 5251/10059] total steps:[105841] lr:[0.00005000] time: 14.71s (9063s total) loss: 156.196\n",
      "Epoch: [11] [ 5261/10059] total steps:[105851] lr:[0.00005000] time: 14.77s (9078s total) loss: 154.471\n",
      "Epoch: [11] [ 5271/10059] total steps:[105861] lr:[0.00005000] time: 14.87s (9092s total) loss: 147.086\n",
      "Epoch: [11] [ 5281/10059] total steps:[105871] lr:[0.00005000] time: 14.81s (9107s total) loss: 96.265\n",
      "Epoch: [11] [ 5291/10059] total steps:[105881] lr:[0.00005000] time: 14.70s (9122s total) loss: 131.797\n",
      "Epoch: [11] [ 5301/10059] total steps:[105891] lr:[0.00005000] time: 14.76s (9137s total) loss: 117.076\n",
      "Epoch: [11] [ 5311/10059] total steps:[105901] lr:[0.00005000] time: 14.71s (9151s total) loss: 167.030\n",
      "Epoch: [11] [ 5321/10059] total steps:[105911] lr:[0.00005000] time: 14.76s (9166s total) loss: 135.116\n",
      "Epoch: [11] [ 5331/10059] total steps:[105921] lr:[0.00005000] time: 14.74s (9181s total) loss: 110.761\n",
      "Epoch: [11] [ 5341/10059] total steps:[105931] lr:[0.00005000] time: 14.65s (9196s total) loss: 205.494\n",
      "Epoch: [11] [ 5351/10059] total steps:[105941] lr:[0.00005000] time: 14.80s (9210s total) loss: 137.666\n",
      "Epoch: [11] [ 5361/10059] total steps:[105951] lr:[0.00005000] time: 16.43s (9227s total) loss: 176.657\n",
      "Epoch: [11] [ 5371/10059] total steps:[105961] lr:[0.00005000] time: 14.81s (9242s total) loss: 96.519\n",
      "Epoch: [11] [ 5381/10059] total steps:[105971] lr:[0.00005000] time: 14.72s (9256s total) loss: 111.167\n",
      "Epoch: [11] [ 5391/10059] total steps:[105981] lr:[0.00005000] time: 14.75s (9271s total) loss: 113.988\n",
      "Epoch: [11] [ 5401/10059] total steps:[105991] lr:[0.00005000] time: 14.67s (9286s total) loss: 123.321\n",
      "Epoch: [11] [ 5411/10059] total steps:[106001] lr:[0.00005000] time: 14.83s (9301s total) loss: 190.012\n",
      "Epoch: [11] [ 5421/10059] total steps:[106011] lr:[0.00005000] time: 14.79s (9315s total) loss: 150.035\n",
      "Epoch: [11] [ 5431/10059] total steps:[106021] lr:[0.00005000] time: 14.84s (9330s total) loss: 132.806\n",
      "Epoch: [11] [ 5441/10059] total steps:[106031] lr:[0.00005000] time: 14.67s (9345s total) loss: 116.495\n",
      "Epoch: [11] [ 5451/10059] total steps:[106041] lr:[0.00005000] time: 14.98s (9360s total) loss: 164.461\n",
      "Epoch: [11] [ 5461/10059] total steps:[106051] lr:[0.00005000] time: 14.81s (9375s total) loss: 122.412\n",
      "Epoch: [11] [ 5471/10059] total steps:[106061] lr:[0.00005000] time: 14.73s (9389s total) loss: 134.777\n",
      "Epoch: [11] [ 5481/10059] total steps:[106071] lr:[0.00005000] time: 14.69s (9404s total) loss: 110.428\n",
      "Epoch: [11] [ 5491/10059] total steps:[106081] lr:[0.00005000] time: 14.72s (9419s total) loss: 134.700\n",
      "Epoch: [11] [ 5501/10059] total steps:[106091] lr:[0.00005000] time: 14.81s (9434s total) loss: 80.586\n",
      "Epoch: [11] [ 5511/10059] total steps:[106101] lr:[0.00005000] time: 14.95s (9449s total) loss: 210.441\n",
      "Epoch: [11] [ 5521/10059] total steps:[106111] lr:[0.00005000] time: 14.76s (9463s total) loss: 118.510\n",
      "Epoch: [11] [ 5531/10059] total steps:[106121] lr:[0.00005000] time: 14.81s (9478s total) loss: 138.340\n",
      "Epoch: [11] [ 5541/10059] total steps:[106131] lr:[0.00005000] time: 14.90s (9493s total) loss: 162.357\n",
      "Epoch: [11] [ 5551/10059] total steps:[106141] lr:[0.00005000] time: 14.73s (9508s total) loss: 148.106\n",
      "Epoch: [11] [ 5561/10059] total steps:[106151] lr:[0.00005000] time: 14.82s (9523s total) loss: 152.158\n",
      "Epoch: [11] [ 5571/10059] total steps:[106161] lr:[0.00005000] time: 14.81s (9537s total) loss: 156.545\n",
      "Epoch: [11] [ 5581/10059] total steps:[106171] lr:[0.00005000] time: 14.79s (9552s total) loss: 124.826\n",
      "Epoch: [11] [ 5591/10059] total steps:[106181] lr:[0.00005000] time: 14.78s (9567s total) loss: 111.146\n",
      "Epoch: [11] [ 5601/10059] total steps:[106191] lr:[0.00005000] time: 14.81s (9582s total) loss: 111.725\n",
      "Epoch: [11] [ 5611/10059] total steps:[106201] lr:[0.00005000] time: 14.80s (9597s total) loss: 140.105\n",
      "Epoch: [11] [ 5621/10059] total steps:[106211] lr:[0.00005000] time: 14.77s (9611s total) loss: 113.895\n",
      "Epoch: [11] [ 5631/10059] total steps:[106221] lr:[0.00005000] time: 14.75s (9626s total) loss: 104.721\n",
      "Epoch: [11] [ 5641/10059] total steps:[106231] lr:[0.00005000] time: 14.71s (9641s total) loss: 112.769\n",
      "Epoch: [11] [ 5651/10059] total steps:[106241] lr:[0.00005000] time: 14.98s (9656s total) loss: 153.025\n",
      "Epoch: [11] [ 5661/10059] total steps:[106251] lr:[0.00005000] time: 14.76s (9671s total) loss: 145.165\n",
      "Epoch: [11] [ 5671/10059] total steps:[106261] lr:[0.00005000] time: 14.74s (9685s total) loss: 146.412\n",
      "Epoch: [11] [ 5681/10059] total steps:[106271] lr:[0.00005000] time: 14.71s (9700s total) loss: 118.931\n",
      "Epoch: [11] [ 5691/10059] total steps:[106281] lr:[0.00005000] time: 14.91s (9715s total) loss: 184.010\n",
      "Epoch: [11] [ 5701/10059] total steps:[106291] lr:[0.00005000] time: 14.71s (9730s total) loss: 207.449\n",
      "Epoch: [11] [ 5711/10059] total steps:[106301] lr:[0.00005000] time: 14.88s (9744s total) loss: 152.210\n",
      "Epoch: [11] [ 5721/10059] total steps:[106311] lr:[0.00005000] time: 14.79s (9759s total) loss: 148.242\n",
      "Epoch: [11] [ 5731/10059] total steps:[106321] lr:[0.00005000] time: 14.71s (9774s total) loss: 145.006\n",
      "Epoch: [11] [ 5741/10059] total steps:[106331] lr:[0.00005000] time: 14.80s (9789s total) loss: 160.778\n",
      "Epoch: [11] [ 5751/10059] total steps:[106341] lr:[0.00005000] time: 14.89s (9804s total) loss: 103.196\n",
      "Epoch: [11] [ 5761/10059] total steps:[106351] lr:[0.00005000] time: 14.81s (9819s total) loss: 94.658\n",
      "Epoch: [11] [ 5771/10059] total steps:[106361] lr:[0.00005000] time: 14.64s (9833s total) loss: 117.222\n",
      "Epoch: [11] [ 5781/10059] total steps:[106371] lr:[0.00005000] time: 14.85s (9848s total) loss: 121.573\n",
      "Epoch: [11] [ 5791/10059] total steps:[106381] lr:[0.00005000] time: 14.80s (9863s total) loss: 127.999\n",
      "Epoch: [11] [ 5801/10059] total steps:[106391] lr:[0.00005000] time: 14.70s (9878s total) loss: 182.401\n",
      "Epoch: [11] [ 5811/10059] total steps:[106401] lr:[0.00005000] time: 14.70s (9892s total) loss: 112.031\n",
      "Epoch: [11] [ 5821/10059] total steps:[106411] lr:[0.00005000] time: 14.68s (9907s total) loss: 166.564\n",
      "Epoch: [11] [ 5831/10059] total steps:[106421] lr:[0.00005000] time: 14.96s (9922s total) loss: 192.520\n",
      "Epoch: [11] [ 5841/10059] total steps:[106431] lr:[0.00005000] time: 14.95s (9937s total) loss: 149.445\n",
      "Epoch: [11] [ 5851/10059] total steps:[106441] lr:[0.00005000] time: 14.83s (9952s total) loss: 122.351\n",
      "Epoch: [11] [ 5861/10059] total steps:[106451] lr:[0.00005000] time: 14.75s (9966s total) loss: 166.957\n",
      "Epoch: [11] [ 5871/10059] total steps:[106461] lr:[0.00005000] time: 14.76s (9981s total) loss: 138.329\n",
      "Epoch: [11] [ 5881/10059] total steps:[106471] lr:[0.00005000] time: 14.84s (9996s total) loss: 141.730\n",
      "Epoch: [11] [ 5891/10059] total steps:[106481] lr:[0.00005000] time: 14.82s (10011s total) loss: 181.977\n",
      "Epoch: [11] [ 5901/10059] total steps:[106491] lr:[0.00005000] time: 14.78s (10026s total) loss: 143.951\n",
      "Epoch: [11] [ 5911/10059] total steps:[106501] lr:[0.00005000] time: 14.81s (10040s total) loss: 142.372\n",
      "Epoch: [11] [ 5921/10059] total steps:[106511] lr:[0.00005000] time: 14.78s (10055s total) loss: 111.223\n",
      "Epoch: [11] [ 5931/10059] total steps:[106521] lr:[0.00005000] time: 14.72s (10070s total) loss: 154.021\n",
      "Epoch: [11] [ 5941/10059] total steps:[106531] lr:[0.00005000] time: 14.81s (10085s total) loss: 140.641\n",
      "Epoch: [11] [ 5951/10059] total steps:[106541] lr:[0.00005000] time: 14.83s (10100s total) loss: 131.150\n",
      "Epoch: [11] [ 5961/10059] total steps:[106551] lr:[0.00005000] time: 14.83s (10114s total) loss: 165.478\n",
      "Epoch: [11] [ 5971/10059] total steps:[106561] lr:[0.00005000] time: 14.70s (10129s total) loss: 151.988\n",
      "Epoch: [11] [ 5981/10059] total steps:[106571] lr:[0.00005000] time: 14.83s (10144s total) loss: 118.003\n",
      "Epoch: [11] [ 5991/10059] total steps:[106581] lr:[0.00005000] time: 14.75s (10159s total) loss: 128.532\n",
      "Epoch: [11] [ 6001/10059] total steps:[106591] lr:[0.00005000] time: 14.88s (10174s total) loss: 133.615\n",
      "Epoch: [11] [ 6011/10059] total steps:[106601] lr:[0.00005000] time: 14.84s (10188s total) loss: 160.981\n",
      "Epoch: [11] [ 6021/10059] total steps:[106611] lr:[0.00005000] time: 14.76s (10203s total) loss: 112.025\n",
      "Epoch: [11] [ 6031/10059] total steps:[106621] lr:[0.00005000] time: 14.74s (10218s total) loss: 133.800\n",
      "Epoch: [11] [ 6041/10059] total steps:[106631] lr:[0.00005000] time: 14.72s (10233s total) loss: 111.241\n",
      "Epoch: [11] [ 6051/10059] total steps:[106641] lr:[0.00005000] time: 14.92s (10247s total) loss: 186.611\n",
      "Epoch: [11] [ 6061/10059] total steps:[106651] lr:[0.00005000] time: 14.82s (10262s total) loss: 90.750\n",
      "Epoch: [11] [ 6071/10059] total steps:[106661] lr:[0.00005000] time: 14.89s (10277s total) loss: 113.192\n",
      "Epoch: [11] [ 6081/10059] total steps:[106671] lr:[0.00005000] time: 14.81s (10292s total) loss: 170.782\n",
      "Epoch: [11] [ 6091/10059] total steps:[106681] lr:[0.00005000] time: 14.77s (10307s total) loss: 177.906\n",
      "Epoch: [11] [ 6101/10059] total steps:[106691] lr:[0.00005000] time: 14.75s (10322s total) loss: 111.866\n",
      "Epoch: [11] [ 6111/10059] total steps:[106701] lr:[0.00005000] time: 14.69s (10336s total) loss: 127.343\n",
      "Epoch: [11] [ 6121/10059] total steps:[106711] lr:[0.00005000] time: 14.82s (10351s total) loss: 144.571\n",
      "Epoch: [11] [ 6131/10059] total steps:[106721] lr:[0.00005000] time: 14.75s (10366s total) loss: 96.660\n",
      "Epoch: [11] [ 6141/10059] total steps:[106731] lr:[0.00005000] time: 14.87s (10381s total) loss: 101.370\n",
      "Epoch: [11] [ 6151/10059] total steps:[106741] lr:[0.00005000] time: 14.82s (10395s total) loss: 141.752\n",
      "Epoch: [11] [ 6161/10059] total steps:[106751] lr:[0.00005000] time: 14.78s (10410s total) loss: 178.285\n",
      "Epoch: [11] [ 6171/10059] total steps:[106761] lr:[0.00005000] time: 14.76s (10425s total) loss: 143.001\n",
      "Epoch: [11] [ 6181/10059] total steps:[106771] lr:[0.00005000] time: 14.79s (10440s total) loss: 134.728\n",
      "Epoch: [11] [ 6191/10059] total steps:[106781] lr:[0.00005000] time: 14.83s (10455s total) loss: 88.417\n",
      "Epoch: [11] [ 6201/10059] total steps:[106791] lr:[0.00005000] time: 14.85s (10469s total) loss: 153.517\n",
      "Epoch: [11] [ 6211/10059] total steps:[106801] lr:[0.00005000] time: 14.85s (10484s total) loss: 132.772\n",
      "Epoch: [11] [ 6221/10059] total steps:[106811] lr:[0.00005000] time: 14.73s (10499s total) loss: 130.351\n",
      "Epoch: [11] [ 6231/10059] total steps:[106821] lr:[0.00005000] time: 14.76s (10514s total) loss: 178.938\n",
      "Epoch: [11] [ 6241/10059] total steps:[106831] lr:[0.00005000] time: 14.82s (10529s total) loss: 137.413\n",
      "Epoch: [11] [ 6251/10059] total steps:[106841] lr:[0.00005000] time: 14.81s (10543s total) loss: 114.651\n",
      "Epoch: [11] [ 6261/10059] total steps:[106851] lr:[0.00005000] time: 14.70s (10558s total) loss: 113.857\n",
      "Epoch: [11] [ 6271/10059] total steps:[106861] lr:[0.00005000] time: 14.72s (10573s total) loss: 147.241\n",
      "Epoch: [11] [ 6281/10059] total steps:[106871] lr:[0.00005000] time: 14.74s (10588s total) loss: 198.676\n",
      "Epoch: [11] [ 6291/10059] total steps:[106881] lr:[0.00005000] time: 14.81s (10602s total) loss: 105.575\n",
      "Epoch: [11] [ 6301/10059] total steps:[106891] lr:[0.00005000] time: 14.80s (10617s total) loss: 187.999\n",
      "Epoch: [11] [ 6311/10059] total steps:[106901] lr:[0.00005000] time: 14.87s (10632s total) loss: 140.509\n",
      "Epoch: [11] [ 6321/10059] total steps:[106911] lr:[0.00005000] time: 14.71s (10647s total) loss: 138.702\n",
      "Epoch: [11] [ 6331/10059] total steps:[106921] lr:[0.00005000] time: 14.82s (10662s total) loss: 180.359\n",
      "Epoch: [11] [ 6341/10059] total steps:[106931] lr:[0.00005000] time: 14.77s (10676s total) loss: 93.011\n",
      "Epoch: [11] [ 6351/10059] total steps:[106941] lr:[0.00005000] time: 14.78s (10691s total) loss: 131.305\n",
      "Epoch: [11] [ 6361/10059] total steps:[106951] lr:[0.00005000] time: 14.62s (10706s total) loss: 125.894\n",
      "Epoch: [11] [ 6371/10059] total steps:[106961] lr:[0.00005000] time: 14.88s (10721s total) loss: 121.028\n",
      "Epoch: [11] [ 6381/10059] total steps:[106971] lr:[0.00005000] time: 14.75s (10735s total) loss: 179.748\n",
      "Epoch: [11] [ 6391/10059] total steps:[106981] lr:[0.00005000] time: 14.69s (10750s total) loss: 149.234\n",
      "Epoch: [11] [ 6401/10059] total steps:[106991] lr:[0.00005000] time: 14.72s (10765s total) loss: 86.675\n",
      "Epoch: [11] [ 6411/10059] total steps:[107001] lr:[0.00005000] time: 14.83s (10780s total) loss: 142.620\n",
      "Epoch: [11] [ 6421/10059] total steps:[107011] lr:[0.00005000] time: 14.63s (10794s total) loss: 118.685\n",
      "Epoch: [11] [ 6431/10059] total steps:[107021] lr:[0.00005000] time: 14.82s (10809s total) loss: 94.877\n",
      "Epoch: [11] [ 6441/10059] total steps:[107031] lr:[0.00005000] time: 14.88s (10824s total) loss: 96.405\n",
      "Epoch: [11] [ 6451/10059] total steps:[107041] lr:[0.00005000] time: 14.73s (10839s total) loss: 131.449\n",
      "Epoch: [11] [ 6461/10059] total steps:[107051] lr:[0.00005000] time: 14.75s (10853s total) loss: 127.252\n",
      "Epoch: [11] [ 6471/10059] total steps:[107061] lr:[0.00005000] time: 14.66s (10868s total) loss: 200.358\n",
      "Epoch: [11] [ 6481/10059] total steps:[107071] lr:[0.00005000] time: 14.79s (10883s total) loss: 97.760\n",
      "Epoch: [11] [ 6491/10059] total steps:[107081] lr:[0.00005000] time: 14.74s (10898s total) loss: 147.220\n",
      "Epoch: [11] [ 6501/10059] total steps:[107091] lr:[0.00005000] time: 14.79s (10912s total) loss: 160.923\n",
      "Epoch: [11] [ 6511/10059] total steps:[107101] lr:[0.00005000] time: 14.82s (10927s total) loss: 150.256\n",
      "Epoch: [11] [ 6521/10059] total steps:[107111] lr:[0.00005000] time: 14.80s (10942s total) loss: 210.572\n",
      "Epoch: [11] [ 6531/10059] total steps:[107121] lr:[0.00005000] time: 14.72s (10957s total) loss: 127.678\n",
      "Epoch: [11] [ 6541/10059] total steps:[107131] lr:[0.00005000] time: 14.71s (10971s total) loss: 143.266\n",
      "Epoch: [11] [ 6551/10059] total steps:[107141] lr:[0.00005000] time: 14.62s (10986s total) loss: 144.026\n",
      "Epoch: [11] [ 6561/10059] total steps:[107151] lr:[0.00005000] time: 14.70s (11001s total) loss: 162.610\n",
      "Epoch: [11] [ 6571/10059] total steps:[107161] lr:[0.00005000] time: 14.95s (11016s total) loss: 135.928\n",
      "Epoch: [11] [ 6581/10059] total steps:[107171] lr:[0.00005000] time: 14.85s (11031s total) loss: 122.645\n",
      "Epoch: [11] [ 6591/10059] total steps:[107181] lr:[0.00005000] time: 14.80s (11045s total) loss: 91.289\n",
      "Epoch: [11] [ 6601/10059] total steps:[107191] lr:[0.00005000] time: 14.77s (11060s total) loss: 109.450\n",
      "Epoch: [11] [ 6611/10059] total steps:[107201] lr:[0.00005000] time: 14.82s (11075s total) loss: 118.350\n",
      "Epoch: [11] [ 6621/10059] total steps:[107211] lr:[0.00005000] time: 14.77s (11090s total) loss: 205.691\n",
      "Epoch: [11] [ 6631/10059] total steps:[107221] lr:[0.00005000] time: 14.68s (11104s total) loss: 138.597\n",
      "Epoch: [11] [ 6641/10059] total steps:[107231] lr:[0.00005000] time: 14.89s (11119s total) loss: 149.898\n",
      "Epoch: [11] [ 6651/10059] total steps:[107241] lr:[0.00005000] time: 14.70s (11134s total) loss: 132.769\n",
      "Epoch: [11] [ 6661/10059] total steps:[107251] lr:[0.00005000] time: 14.72s (11149s total) loss: 188.407\n",
      "Epoch: [11] [ 6671/10059] total steps:[107261] lr:[0.00005000] time: 14.72s (11163s total) loss: 154.883\n",
      "Epoch: [11] [ 6681/10059] total steps:[107271] lr:[0.00005000] time: 14.75s (11178s total) loss: 171.471\n",
      "Epoch: [11] [ 6691/10059] total steps:[107281] lr:[0.00005000] time: 14.89s (11193s total) loss: 139.294\n",
      "Epoch: [11] [ 6701/10059] total steps:[107291] lr:[0.00005000] time: 14.75s (11208s total) loss: 144.559\n",
      "Epoch: [11] [ 6711/10059] total steps:[107301] lr:[0.00005000] time: 14.92s (11223s total) loss: 113.564\n",
      "Epoch: [11] [ 6721/10059] total steps:[107311] lr:[0.00005000] time: 14.76s (11238s total) loss: 131.546\n",
      "Epoch: [11] [ 6731/10059] total steps:[107321] lr:[0.00005000] time: 14.72s (11252s total) loss: 151.861\n",
      "Epoch: [11] [ 6741/10059] total steps:[107331] lr:[0.00005000] time: 14.70s (11267s total) loss: 123.526\n",
      "Epoch: [11] [ 6751/10059] total steps:[107341] lr:[0.00005000] time: 14.75s (11282s total) loss: 158.202\n",
      "Epoch: [11] [ 6761/10059] total steps:[107351] lr:[0.00005000] time: 14.82s (11297s total) loss: 105.779\n",
      "Epoch: [11] [ 6771/10059] total steps:[107361] lr:[0.00005000] time: 14.83s (11311s total) loss: 144.921\n",
      "Epoch: [11] [ 6781/10059] total steps:[107371] lr:[0.00005000] time: 14.84s (11326s total) loss: 91.928\n",
      "Epoch: [11] [ 6791/10059] total steps:[107381] lr:[0.00005000] time: 14.77s (11341s total) loss: 128.325\n",
      "Epoch: [11] [ 6801/10059] total steps:[107391] lr:[0.00005000] time: 14.75s (11356s total) loss: 122.009\n",
      "Epoch: [11] [ 6811/10059] total steps:[107401] lr:[0.00005000] time: 14.87s (11371s total) loss: 112.894\n",
      "Epoch: [11] [ 6821/10059] total steps:[107411] lr:[0.00005000] time: 14.71s (11385s total) loss: 145.141\n",
      "Epoch: [11] [ 6831/10059] total steps:[107421] lr:[0.00005000] time: 14.89s (11400s total) loss: 97.268\n",
      "Epoch: [11] [ 6841/10059] total steps:[107431] lr:[0.00005000] time: 14.67s (11415s total) loss: 108.284\n",
      "Epoch: [11] [ 6851/10059] total steps:[107441] lr:[0.00005000] time: 14.69s (11430s total) loss: 140.447\n",
      "Epoch: [11] [ 6861/10059] total steps:[107451] lr:[0.00005000] time: 14.85s (11444s total) loss: 165.124\n",
      "Epoch: [11] [ 6871/10059] total steps:[107461] lr:[0.00005000] time: 14.64s (11459s total) loss: 126.318\n",
      "Epoch: [11] [ 6881/10059] total steps:[107471] lr:[0.00005000] time: 14.87s (11474s total) loss: 164.702\n",
      "Epoch: [11] [ 6891/10059] total steps:[107481] lr:[0.00005000] time: 14.68s (11489s total) loss: 122.992\n",
      "Epoch: [11] [ 6901/10059] total steps:[107491] lr:[0.00005000] time: 14.84s (11503s total) loss: 95.874\n",
      "Epoch: [11] [ 6911/10059] total steps:[107501] lr:[0.00005000] time: 14.86s (11518s total) loss: 175.064\n",
      "Epoch: [11] [ 6921/10059] total steps:[107511] lr:[0.00005000] time: 14.92s (11533s total) loss: 162.402\n",
      "Epoch: [11] [ 6931/10059] total steps:[107521] lr:[0.00005000] time: 14.96s (11548s total) loss: 181.877\n",
      "Epoch: [11] [ 6941/10059] total steps:[107531] lr:[0.00005000] time: 14.90s (11563s total) loss: 111.568\n",
      "Epoch: [11] [ 6951/10059] total steps:[107541] lr:[0.00005000] time: 14.68s (11578s total) loss: 98.000\n",
      "Epoch: [11] [ 6961/10059] total steps:[107551] lr:[0.00005000] time: 14.80s (11593s total) loss: 156.387\n",
      "Epoch: [11] [ 6971/10059] total steps:[107561] lr:[0.00005000] time: 14.75s (11607s total) loss: 141.350\n",
      "Epoch: [11] [ 6981/10059] total steps:[107571] lr:[0.00005000] time: 14.80s (11622s total) loss: 104.811\n",
      "Epoch: [11] [ 6991/10059] total steps:[107581] lr:[0.00005000] time: 14.71s (11637s total) loss: 113.985\n",
      "Epoch: [11] [ 7001/10059] total steps:[107591] lr:[0.00005000] time: 14.97s (11652s total) loss: 100.151\n",
      "Epoch: [11] [ 7011/10059] total steps:[107601] lr:[0.00005000] time: 14.73s (11667s total) loss: 144.249\n",
      "Epoch: [11] [ 7021/10059] total steps:[107611] lr:[0.00005000] time: 14.75s (11681s total) loss: 122.012\n",
      "Epoch: [11] [ 7031/10059] total steps:[107621] lr:[0.00005000] time: 14.78s (11696s total) loss: 128.722\n",
      "Epoch: [11] [ 7041/10059] total steps:[107631] lr:[0.00005000] time: 14.71s (11711s total) loss: 111.893\n",
      "Epoch: [11] [ 7051/10059] total steps:[107641] lr:[0.00005000] time: 14.65s (11725s total) loss: 149.911\n",
      "Epoch: [11] [ 7061/10059] total steps:[107651] lr:[0.00005000] time: 14.78s (11740s total) loss: 101.879\n",
      "Epoch: [11] [ 7071/10059] total steps:[107661] lr:[0.00005000] time: 14.88s (11755s total) loss: 149.989\n",
      "Epoch: [11] [ 7081/10059] total steps:[107671] lr:[0.00005000] time: 14.80s (11770s total) loss: 216.657\n",
      "Epoch: [11] [ 7091/10059] total steps:[107681] lr:[0.00005000] time: 14.79s (11785s total) loss: 123.841\n",
      "Epoch: [11] [ 7101/10059] total steps:[107691] lr:[0.00005000] time: 14.72s (11799s total) loss: 134.862\n",
      "Epoch: [11] [ 7111/10059] total steps:[107701] lr:[0.00005000] time: 14.89s (11814s total) loss: 140.100\n",
      "Epoch: [11] [ 7121/10059] total steps:[107711] lr:[0.00005000] time: 14.77s (11829s total) loss: 119.726\n",
      "Epoch: [11] [ 7131/10059] total steps:[107721] lr:[0.00005000] time: 14.67s (11844s total) loss: 151.253\n",
      "Epoch: [11] [ 7141/10059] total steps:[107731] lr:[0.00005000] time: 14.78s (11858s total) loss: 160.466\n",
      "Epoch: [11] [ 7151/10059] total steps:[107741] lr:[0.00005000] time: 14.72s (11873s total) loss: 151.983\n",
      "Epoch: [11] [ 7161/10059] total steps:[107751] lr:[0.00005000] time: 14.85s (11888s total) loss: 129.854\n",
      "Epoch: [11] [ 7171/10059] total steps:[107761] lr:[0.00005000] time: 14.84s (11903s total) loss: 179.523\n",
      "Epoch: [11] [ 7181/10059] total steps:[107771] lr:[0.00005000] time: 14.73s (11918s total) loss: 116.988\n",
      "Epoch: [11] [ 7191/10059] total steps:[107781] lr:[0.00005000] time: 14.81s (11932s total) loss: 135.079\n",
      "Epoch: [11] [ 7201/10059] total steps:[107791] lr:[0.00005000] time: 14.73s (11947s total) loss: 146.617\n",
      "Epoch: [11] [ 7211/10059] total steps:[107801] lr:[0.00005000] time: 14.86s (11962s total) loss: 116.945\n",
      "Epoch: [11] [ 7221/10059] total steps:[107811] lr:[0.00005000] time: 14.70s (11977s total) loss: 201.195\n",
      "Epoch: [11] [ 7231/10059] total steps:[107821] lr:[0.00005000] time: 14.78s (11992s total) loss: 125.141\n",
      "Epoch: [11] [ 7241/10059] total steps:[107831] lr:[0.00005000] time: 14.75s (12006s total) loss: 115.320\n",
      "Epoch: [11] [ 7251/10059] total steps:[107841] lr:[0.00005000] time: 14.77s (12021s total) loss: 132.974\n",
      "Epoch: [11] [ 7261/10059] total steps:[107851] lr:[0.00005000] time: 14.80s (12036s total) loss: 134.404\n",
      "Epoch: [11] [ 7271/10059] total steps:[107861] lr:[0.00005000] time: 14.72s (12051s total) loss: 169.426\n",
      "Epoch: [11] [ 7281/10059] total steps:[107871] lr:[0.00005000] time: 14.81s (12065s total) loss: 143.880\n",
      "Epoch: [11] [ 7291/10059] total steps:[107881] lr:[0.00005000] time: 14.79s (12080s total) loss: 150.387\n",
      "Epoch: [11] [ 7301/10059] total steps:[107891] lr:[0.00005000] time: 14.72s (12095s total) loss: 177.666\n",
      "Epoch: [11] [ 7311/10059] total steps:[107901] lr:[0.00005000] time: 14.86s (12110s total) loss: 173.810\n",
      "Epoch: [11] [ 7321/10059] total steps:[107911] lr:[0.00005000] time: 14.75s (12125s total) loss: 75.253\n",
      "Epoch: [11] [ 7331/10059] total steps:[107921] lr:[0.00005000] time: 14.72s (12139s total) loss: 101.664\n",
      "Epoch: [11] [ 7341/10059] total steps:[107931] lr:[0.00005000] time: 14.70s (12154s total) loss: 90.295\n",
      "Epoch: [11] [ 7351/10059] total steps:[107941] lr:[0.00005000] time: 14.80s (12169s total) loss: 146.230\n",
      "Epoch: [11] [ 7361/10059] total steps:[107951] lr:[0.00005000] time: 14.73s (12183s total) loss: 185.680\n",
      "Epoch: [11] [ 7371/10059] total steps:[107961] lr:[0.00005000] time: 14.85s (12198s total) loss: 187.425\n",
      "Epoch: [11] [ 7381/10059] total steps:[107971] lr:[0.00005000] time: 14.76s (12213s total) loss: 127.861\n",
      "Epoch: [11] [ 7391/10059] total steps:[107981] lr:[0.00005000] time: 14.70s (12228s total) loss: 109.776\n",
      "Epoch: [11] [ 7401/10059] total steps:[107991] lr:[0.00005000] time: 14.67s (12242s total) loss: 138.653\n",
      "Epoch: [11] [ 7411/10059] total steps:[108001] lr:[0.00005000] time: 14.90s (12257s total) loss: 180.093\n",
      "Epoch: [11] [ 7421/10059] total steps:[108011] lr:[0.00005000] time: 14.75s (12272s total) loss: 163.874\n",
      "Epoch: [11] [ 7431/10059] total steps:[108021] lr:[0.00005000] time: 14.72s (12287s total) loss: 104.681\n",
      "Epoch: [11] [ 7441/10059] total steps:[108031] lr:[0.00005000] time: 14.73s (12302s total) loss: 93.885\n",
      "Epoch: [11] [ 7451/10059] total steps:[108041] lr:[0.00005000] time: 14.71s (12316s total) loss: 147.569\n",
      "Epoch: [11] [ 7461/10059] total steps:[108051] lr:[0.00005000] time: 15.01s (12331s total) loss: 146.777\n",
      "Epoch: [11] [ 7471/10059] total steps:[108061] lr:[0.00005000] time: 14.90s (12346s total) loss: 159.280\n",
      "Epoch: [11] [ 7481/10059] total steps:[108071] lr:[0.00005000] time: 14.79s (12361s total) loss: 159.073\n",
      "Epoch: [11] [ 7491/10059] total steps:[108081] lr:[0.00005000] time: 14.88s (12376s total) loss: 105.875\n",
      "Epoch: [11] [ 7501/10059] total steps:[108091] lr:[0.00005000] time: 14.88s (12391s total) loss: 122.373\n",
      "Epoch: [11] [ 7511/10059] total steps:[108101] lr:[0.00005000] time: 14.84s (12406s total) loss: 113.933\n",
      "Epoch: [11] [ 7521/10059] total steps:[108111] lr:[0.00005000] time: 14.73s (12420s total) loss: 156.377\n",
      "Epoch: [11] [ 7531/10059] total steps:[108121] lr:[0.00005000] time: 14.73s (12435s total) loss: 216.637\n",
      "Epoch: [11] [ 7541/10059] total steps:[108131] lr:[0.00005000] time: 14.77s (12450s total) loss: 144.133\n",
      "Epoch: [11] [ 7551/10059] total steps:[108141] lr:[0.00005000] time: 14.72s (12465s total) loss: 134.640\n",
      "Epoch: [11] [ 7561/10059] total steps:[108151] lr:[0.00005000] time: 14.86s (12479s total) loss: 152.226\n",
      "Epoch: [11] [ 7571/10059] total steps:[108161] lr:[0.00005000] time: 14.65s (12494s total) loss: 145.107\n",
      "Epoch: [11] [ 7581/10059] total steps:[108171] lr:[0.00005000] time: 14.92s (12509s total) loss: 136.071\n",
      "Epoch: [11] [ 7591/10059] total steps:[108181] lr:[0.00005000] time: 14.80s (12524s total) loss: 75.743\n",
      "Epoch: [11] [ 7601/10059] total steps:[108191] lr:[0.00005000] time: 14.67s (12538s total) loss: 116.377\n",
      "Epoch: [11] [ 7611/10059] total steps:[108201] lr:[0.00005000] time: 14.79s (12553s total) loss: 118.785\n",
      "Epoch: [11] [ 7621/10059] total steps:[108211] lr:[0.00005000] time: 14.83s (12568s total) loss: 111.506\n",
      "Epoch: [11] [ 7631/10059] total steps:[108221] lr:[0.00005000] time: 14.84s (12583s total) loss: 164.527\n",
      "Epoch: [11] [ 7641/10059] total steps:[108231] lr:[0.00005000] time: 14.78s (12598s total) loss: 89.614\n",
      "Epoch: [11] [ 7651/10059] total steps:[108241] lr:[0.00005000] time: 14.81s (12612s total) loss: 139.032\n",
      "Epoch: [11] [ 7661/10059] total steps:[108251] lr:[0.00005000] time: 14.77s (12627s total) loss: 120.173\n",
      "Epoch: [11] [ 7671/10059] total steps:[108261] lr:[0.00005000] time: 14.74s (12642s total) loss: 88.803\n",
      "Epoch: [11] [ 7681/10059] total steps:[108271] lr:[0.00005000] time: 14.74s (12657s total) loss: 121.177\n",
      "Epoch: [11] [ 7691/10059] total steps:[108281] lr:[0.00005000] time: 14.71s (12671s total) loss: 103.196\n",
      "Epoch: [11] [ 7701/10059] total steps:[108291] lr:[0.00005000] time: 14.70s (12686s total) loss: 187.954\n",
      "Epoch: [11] [ 7711/10059] total steps:[108301] lr:[0.00005000] time: 14.78s (12701s total) loss: 119.653\n",
      "Epoch: [11] [ 7721/10059] total steps:[108311] lr:[0.00005000] time: 14.77s (12716s total) loss: 143.962\n",
      "Epoch: [11] [ 7731/10059] total steps:[108321] lr:[0.00005000] time: 14.76s (12730s total) loss: 93.574\n",
      "Epoch: [11] [ 7741/10059] total steps:[108331] lr:[0.00005000] time: 14.74s (12745s total) loss: 149.528\n",
      "Epoch: [11] [ 7751/10059] total steps:[108341] lr:[0.00005000] time: 14.82s (12760s total) loss: 154.146\n",
      "Epoch: [11] [ 7761/10059] total steps:[108351] lr:[0.00005000] time: 14.82s (12775s total) loss: 179.128\n",
      "Epoch: [11] [ 7771/10059] total steps:[108361] lr:[0.00005000] time: 14.90s (12790s total) loss: 138.116\n",
      "Epoch: [11] [ 7781/10059] total steps:[108371] lr:[0.00005000] time: 14.81s (12805s total) loss: 173.147\n",
      "Epoch: [11] [ 7791/10059] total steps:[108381] lr:[0.00005000] time: 14.73s (12819s total) loss: 89.828\n",
      "Epoch: [11] [ 7801/10059] total steps:[108391] lr:[0.00005000] time: 14.78s (12834s total) loss: 121.023\n",
      "Epoch: [11] [ 7811/10059] total steps:[108401] lr:[0.00005000] time: 14.84s (12849s total) loss: 119.318\n",
      "Epoch: [11] [ 7821/10059] total steps:[108411] lr:[0.00005000] time: 14.80s (12864s total) loss: 160.292\n",
      "Epoch: [11] [ 7831/10059] total steps:[108421] lr:[0.00005000] time: 14.74s (12878s total) loss: 169.356\n",
      "Epoch: [11] [ 7841/10059] total steps:[108431] lr:[0.00005000] time: 14.74s (12893s total) loss: 118.227\n",
      "Epoch: [11] [ 7851/10059] total steps:[108441] lr:[0.00005000] time: 14.77s (12908s total) loss: 147.454\n",
      "Epoch: [11] [ 7861/10059] total steps:[108451] lr:[0.00005000] time: 14.86s (12923s total) loss: 162.883\n",
      "Epoch: [11] [ 7871/10059] total steps:[108461] lr:[0.00005000] time: 14.88s (12938s total) loss: 153.365\n",
      "Epoch: [11] [ 7881/10059] total steps:[108471] lr:[0.00005000] time: 14.87s (12953s total) loss: 174.197\n",
      "Epoch: [11] [ 7891/10059] total steps:[108481] lr:[0.00005000] time: 14.72s (12967s total) loss: 133.399\n",
      "Epoch: [11] [ 7901/10059] total steps:[108491] lr:[0.00005000] time: 14.68s (12982s total) loss: 148.314\n",
      "Epoch: [11] [ 7911/10059] total steps:[108501] lr:[0.00005000] time: 14.85s (12997s total) loss: 167.256\n",
      "Epoch: [11] [ 7921/10059] total steps:[108511] lr:[0.00005000] time: 14.82s (13012s total) loss: 154.190\n",
      "Epoch: [11] [ 7931/10059] total steps:[108521] lr:[0.00005000] time: 16.67s (13028s total) loss: 158.692\n",
      "Epoch: [11] [ 7941/10059] total steps:[108531] lr:[0.00005000] time: 14.80s (13043s total) loss: 129.046\n",
      "Epoch: [11] [ 7951/10059] total steps:[108541] lr:[0.00005000] time: 14.72s (13058s total) loss: 186.799\n",
      "Epoch: [11] [ 7961/10059] total steps:[108551] lr:[0.00005000] time: 14.67s (13072s total) loss: 98.434\n",
      "Epoch: [11] [ 7971/10059] total steps:[108561] lr:[0.00005000] time: 14.89s (13087s total) loss: 127.249\n",
      "Epoch: [11] [ 7981/10059] total steps:[108571] lr:[0.00005000] time: 14.73s (13102s total) loss: 130.338\n",
      "Epoch: [11] [ 7991/10059] total steps:[108581] lr:[0.00005000] time: 14.74s (13117s total) loss: 150.355\n",
      "Epoch: [11] [ 8001/10059] total steps:[108591] lr:[0.00005000] time: 14.75s (13132s total) loss: 78.566\n",
      "Epoch: [11] [ 8011/10059] total steps:[108601] lr:[0.00005000] time: 14.89s (13146s total) loss: 142.967\n",
      "Epoch: [11] [ 8021/10059] total steps:[108611] lr:[0.00005000] time: 14.80s (13161s total) loss: 131.958\n",
      "Epoch: [11] [ 8031/10059] total steps:[108621] lr:[0.00005000] time: 14.72s (13176s total) loss: 148.656\n",
      "Epoch: [11] [ 8041/10059] total steps:[108631] lr:[0.00005000] time: 14.75s (13191s total) loss: 107.686\n",
      "Epoch: [11] [ 8051/10059] total steps:[108641] lr:[0.00005000] time: 14.82s (13206s total) loss: 158.316\n",
      "Epoch: [11] [ 8061/10059] total steps:[108651] lr:[0.00005000] time: 14.68s (13220s total) loss: 127.461\n",
      "Epoch: [11] [ 8071/10059] total steps:[108661] lr:[0.00005000] time: 14.75s (13235s total) loss: 142.568\n",
      "Epoch: [11] [ 8081/10059] total steps:[108671] lr:[0.00005000] time: 14.71s (13250s total) loss: 140.998\n",
      "Epoch: [11] [ 8091/10059] total steps:[108681] lr:[0.00005000] time: 14.79s (13265s total) loss: 100.854\n",
      "Epoch: [11] [ 8101/10059] total steps:[108691] lr:[0.00005000] time: 14.73s (13279s total) loss: 127.554\n",
      "Epoch: [11] [ 8111/10059] total steps:[108701] lr:[0.00005000] time: 14.79s (13294s total) loss: 107.085\n",
      "Epoch: [11] [ 8121/10059] total steps:[108711] lr:[0.00005000] time: 14.64s (13309s total) loss: 123.560\n",
      "Epoch: [11] [ 8131/10059] total steps:[108721] lr:[0.00005000] time: 14.85s (13324s total) loss: 143.340\n",
      "Epoch: [11] [ 8141/10059] total steps:[108731] lr:[0.00005000] time: 14.73s (13338s total) loss: 137.629\n",
      "Epoch: [11] [ 8151/10059] total steps:[108741] lr:[0.00005000] time: 14.82s (13353s total) loss: 90.424\n",
      "Epoch: [11] [ 8161/10059] total steps:[108751] lr:[0.00005000] time: 14.77s (13368s total) loss: 159.692\n",
      "Epoch: [11] [ 8171/10059] total steps:[108761] lr:[0.00005000] time: 14.90s (13383s total) loss: 136.856\n",
      "Epoch: [11] [ 8181/10059] total steps:[108771] lr:[0.00005000] time: 14.86s (13398s total) loss: 102.988\n",
      "Epoch: [11] [ 8191/10059] total steps:[108781] lr:[0.00005000] time: 14.72s (13412s total) loss: 140.313\n",
      "Epoch: [11] [ 8201/10059] total steps:[108791] lr:[0.00005000] time: 14.77s (13427s total) loss: 129.076\n",
      "Epoch: [11] [ 8211/10059] total steps:[108801] lr:[0.00005000] time: 14.76s (13442s total) loss: 107.033\n",
      "Epoch: [11] [ 8221/10059] total steps:[108811] lr:[0.00005000] time: 14.82s (13457s total) loss: 110.316\n",
      "Epoch: [11] [ 8231/10059] total steps:[108821] lr:[0.00005000] time: 14.75s (13471s total) loss: 103.839\n",
      "Epoch: [11] [ 8241/10059] total steps:[108831] lr:[0.00005000] time: 14.74s (13486s total) loss: 141.129\n",
      "Epoch: [11] [ 8251/10059] total steps:[108841] lr:[0.00005000] time: 14.83s (13501s total) loss: 150.393\n",
      "Epoch: [11] [ 8261/10059] total steps:[108851] lr:[0.00005000] time: 14.70s (13516s total) loss: 169.206\n",
      "Epoch: [11] [ 8271/10059] total steps:[108861] lr:[0.00005000] time: 14.74s (13530s total) loss: 93.407\n",
      "Epoch: [11] [ 8281/10059] total steps:[108871] lr:[0.00005000] time: 14.72s (13545s total) loss: 109.352\n",
      "Epoch: [11] [ 8291/10059] total steps:[108881] lr:[0.00005000] time: 14.87s (13560s total) loss: 121.565\n",
      "Epoch: [11] [ 8301/10059] total steps:[108891] lr:[0.00005000] time: 14.86s (13575s total) loss: 158.376\n",
      "Epoch: [11] [ 8311/10059] total steps:[108901] lr:[0.00005000] time: 14.93s (13590s total) loss: 192.036\n",
      "Epoch: [11] [ 8321/10059] total steps:[108911] lr:[0.00005000] time: 14.77s (13605s total) loss: 83.433\n",
      "Epoch: [11] [ 8331/10059] total steps:[108921] lr:[0.00005000] time: 14.80s (13619s total) loss: 112.443\n",
      "Epoch: [11] [ 8341/10059] total steps:[108931] lr:[0.00005000] time: 14.86s (13634s total) loss: 155.020\n",
      "Epoch: [11] [ 8351/10059] total steps:[108941] lr:[0.00005000] time: 14.75s (13649s total) loss: 158.343\n",
      "Epoch: [11] [ 8361/10059] total steps:[108951] lr:[0.00005000] time: 14.75s (13664s total) loss: 142.172\n",
      "Epoch: [11] [ 8371/10059] total steps:[108961] lr:[0.00005000] time: 14.85s (13679s total) loss: 128.474\n",
      "Epoch: [11] [ 8381/10059] total steps:[108971] lr:[0.00005000] time: 14.68s (13693s total) loss: 77.662\n",
      "Epoch: [11] [ 8391/10059] total steps:[108981] lr:[0.00005000] time: 14.76s (13708s total) loss: 161.720\n",
      "Epoch: [11] [ 8401/10059] total steps:[108991] lr:[0.00005000] time: 14.76s (13723s total) loss: 141.923\n",
      "Epoch: [11] [ 8411/10059] total steps:[109001] lr:[0.00005000] time: 14.91s (13738s total) loss: 112.405\n",
      "Epoch: [11] [ 8421/10059] total steps:[109011] lr:[0.00005000] time: 14.84s (13753s total) loss: 147.447\n",
      "Epoch: [11] [ 8431/10059] total steps:[109021] lr:[0.00005000] time: 14.85s (13767s total) loss: 131.028\n",
      "Epoch: [11] [ 8441/10059] total steps:[109031] lr:[0.00005000] time: 14.79s (13782s total) loss: 142.044\n",
      "Epoch: [11] [ 8451/10059] total steps:[109041] lr:[0.00005000] time: 14.87s (13797s total) loss: 168.672\n",
      "Epoch: [11] [ 8461/10059] total steps:[109051] lr:[0.00005000] time: 14.80s (13812s total) loss: 111.756\n",
      "Epoch: [11] [ 8471/10059] total steps:[109061] lr:[0.00005000] time: 14.81s (13827s total) loss: 104.815\n",
      "Epoch: [11] [ 8481/10059] total steps:[109071] lr:[0.00005000] time: 14.88s (13842s total) loss: 142.965\n",
      "Epoch: [11] [ 8491/10059] total steps:[109081] lr:[0.00005000] time: 14.72s (13856s total) loss: 124.969\n",
      "Epoch: [11] [ 8501/10059] total steps:[109091] lr:[0.00005000] time: 14.78s (13871s total) loss: 105.614\n",
      "Epoch: [11] [ 8511/10059] total steps:[109101] lr:[0.00005000] time: 14.70s (13886s total) loss: 129.585\n",
      "Epoch: [11] [ 8521/10059] total steps:[109111] lr:[0.00005000] time: 14.73s (13900s total) loss: 125.926\n",
      "Epoch: [11] [ 8531/10059] total steps:[109121] lr:[0.00005000] time: 14.81s (13915s total) loss: 178.476\n",
      "Epoch: [11] [ 8541/10059] total steps:[109131] lr:[0.00005000] time: 14.84s (13930s total) loss: 163.194\n",
      "Epoch: [11] [ 8551/10059] total steps:[109141] lr:[0.00005000] time: 14.67s (13945s total) loss: 107.808\n",
      "Epoch: [11] [ 8561/10059] total steps:[109151] lr:[0.00005000] time: 14.79s (13960s total) loss: 116.208\n",
      "Epoch: [11] [ 8571/10059] total steps:[109161] lr:[0.00005000] time: 14.81s (13974s total) loss: 71.859\n",
      "Epoch: [11] [ 8581/10059] total steps:[109171] lr:[0.00005000] time: 14.92s (13989s total) loss: 151.560\n",
      "Epoch: [11] [ 8591/10059] total steps:[109181] lr:[0.00005000] time: 14.84s (14004s total) loss: 96.929\n",
      "Epoch: [11] [ 8601/10059] total steps:[109191] lr:[0.00005000] time: 14.90s (14019s total) loss: 129.626\n",
      "Epoch: [11] [ 8611/10059] total steps:[109201] lr:[0.00005000] time: 14.79s (14034s total) loss: 144.405\n",
      "Epoch: [11] [ 8621/10059] total steps:[109211] lr:[0.00005000] time: 14.70s (14049s total) loss: 93.747\n",
      "Epoch: [11] [ 8631/10059] total steps:[109221] lr:[0.00005000] time: 14.75s (14063s total) loss: 103.889\n",
      "Epoch: [11] [ 8641/10059] total steps:[109231] lr:[0.00005000] time: 14.80s (14078s total) loss: 164.825\n",
      "Epoch: [11] [ 8651/10059] total steps:[109241] lr:[0.00005000] time: 14.93s (14093s total) loss: 193.787\n",
      "Epoch: [11] [ 8661/10059] total steps:[109251] lr:[0.00005000] time: 14.69s (14108s total) loss: 201.877\n",
      "Epoch: [11] [ 8671/10059] total steps:[109261] lr:[0.00005000] time: 14.65s (14122s total) loss: 155.662\n",
      "Epoch: [11] [ 8681/10059] total steps:[109271] lr:[0.00005000] time: 14.85s (14137s total) loss: 198.052\n",
      "Epoch: [11] [ 8691/10059] total steps:[109281] lr:[0.00005000] time: 14.70s (14152s total) loss: 135.684\n",
      "Epoch: [11] [ 8701/10059] total steps:[109291] lr:[0.00005000] time: 14.74s (14167s total) loss: 124.492\n",
      "Epoch: [11] [ 8711/10059] total steps:[109301] lr:[0.00005000] time: 14.79s (14181s total) loss: 103.583\n",
      "Epoch: [11] [ 8721/10059] total steps:[109311] lr:[0.00005000] time: 14.81s (14196s total) loss: 150.113\n",
      "Epoch: [11] [ 8731/10059] total steps:[109321] lr:[0.00005000] time: 14.75s (14211s total) loss: 126.855\n",
      "Epoch: [11] [ 8741/10059] total steps:[109331] lr:[0.00005000] time: 14.86s (14226s total) loss: 139.501\n",
      "Epoch: [11] [ 8751/10059] total steps:[109341] lr:[0.00005000] time: 14.78s (14241s total) loss: 111.704\n",
      "Epoch: [11] [ 8761/10059] total steps:[109351] lr:[0.00005000] time: 14.73s (14255s total) loss: 128.582\n",
      "Epoch: [11] [ 8771/10059] total steps:[109361] lr:[0.00005000] time: 14.69s (14270s total) loss: 184.498\n",
      "Epoch: [11] [ 8781/10059] total steps:[109371] lr:[0.00005000] time: 14.64s (14285s total) loss: 151.318\n",
      "Epoch: [11] [ 8791/10059] total steps:[109381] lr:[0.00005000] time: 14.82s (14300s total) loss: 90.323\n",
      "Epoch: [11] [ 8801/10059] total steps:[109391] lr:[0.00005000] time: 14.98s (14315s total) loss: 121.171\n",
      "Epoch: [11] [ 8811/10059] total steps:[109401] lr:[0.00005000] time: 14.80s (14329s total) loss: 169.873\n",
      "Epoch: [11] [ 8821/10059] total steps:[109411] lr:[0.00005000] time: 14.80s (14344s total) loss: 165.079\n",
      "Epoch: [11] [ 8831/10059] total steps:[109421] lr:[0.00005000] time: 14.82s (14359s total) loss: 101.723\n",
      "Epoch: [11] [ 8841/10059] total steps:[109431] lr:[0.00005000] time: 14.75s (14374s total) loss: 114.035\n",
      "Epoch: [11] [ 8851/10059] total steps:[109441] lr:[0.00005000] time: 14.74s (14388s total) loss: 86.241\n",
      "Epoch: [11] [ 8861/10059] total steps:[109451] lr:[0.00005000] time: 14.89s (14403s total) loss: 146.213\n",
      "Epoch: [11] [ 8871/10059] total steps:[109461] lr:[0.00005000] time: 14.73s (14418s total) loss: 81.462\n",
      "Epoch: [11] [ 8881/10059] total steps:[109471] lr:[0.00005000] time: 14.74s (14433s total) loss: 85.289\n",
      "Epoch: [11] [ 8891/10059] total steps:[109481] lr:[0.00005000] time: 14.74s (14448s total) loss: 150.636\n",
      "Epoch: [11] [ 8901/10059] total steps:[109491] lr:[0.00005000] time: 14.69s (14462s total) loss: 121.544\n",
      "Epoch: [11] [ 8911/10059] total steps:[109501] lr:[0.00005000] time: 14.78s (14477s total) loss: 161.404\n",
      "Epoch: [11] [ 8921/10059] total steps:[109511] lr:[0.00005000] time: 14.79s (14492s total) loss: 126.592\n",
      "Epoch: [11] [ 8931/10059] total steps:[109521] lr:[0.00005000] time: 14.80s (14507s total) loss: 123.839\n",
      "Epoch: [11] [ 8941/10059] total steps:[109531] lr:[0.00005000] time: 14.81s (14521s total) loss: 195.915\n",
      "Epoch: [11] [ 8951/10059] total steps:[109541] lr:[0.00005000] time: 14.70s (14536s total) loss: 269.559\n",
      "Epoch: [11] [ 8961/10059] total steps:[109551] lr:[0.00005000] time: 15.00s (14551s total) loss: 171.896\n",
      "Epoch: [11] [ 8971/10059] total steps:[109561] lr:[0.00005000] time: 14.81s (14566s total) loss: 105.155\n",
      "Epoch: [11] [ 8981/10059] total steps:[109571] lr:[0.00005000] time: 14.74s (14581s total) loss: 132.905\n",
      "Epoch: [11] [ 8991/10059] total steps:[109581] lr:[0.00005000] time: 14.80s (14595s total) loss: 179.001\n",
      "Epoch: [11] [ 9001/10059] total steps:[109591] lr:[0.00005000] time: 14.85s (14610s total) loss: 77.584\n",
      "Epoch: [11] [ 9011/10059] total steps:[109601] lr:[0.00005000] time: 14.88s (14625s total) loss: 140.650\n",
      "Epoch: [11] [ 9021/10059] total steps:[109611] lr:[0.00005000] time: 14.81s (14640s total) loss: 165.013\n",
      "Epoch: [11] [ 9031/10059] total steps:[109621] lr:[0.00005000] time: 14.70s (14655s total) loss: 135.876\n",
      "Epoch: [11] [ 9041/10059] total steps:[109631] lr:[0.00005000] time: 14.79s (14669s total) loss: 117.287\n",
      "Epoch: [11] [ 9051/10059] total steps:[109641] lr:[0.00005000] time: 14.80s (14684s total) loss: 122.199\n",
      "Epoch: [11] [ 9061/10059] total steps:[109651] lr:[0.00005000] time: 14.90s (14699s total) loss: 142.308\n",
      "Epoch: [11] [ 9071/10059] total steps:[109661] lr:[0.00005000] time: 14.82s (14714s total) loss: 130.554\n",
      "Epoch: [11] [ 9081/10059] total steps:[109671] lr:[0.00005000] time: 14.85s (14729s total) loss: 135.905\n",
      "Epoch: [11] [ 9091/10059] total steps:[109681] lr:[0.00005000] time: 14.73s (14744s total) loss: 174.231\n",
      "Epoch: [11] [ 9101/10059] total steps:[109691] lr:[0.00005000] time: 14.82s (14758s total) loss: 109.284\n",
      "Epoch: [11] [ 9111/10059] total steps:[109701] lr:[0.00005000] time: 14.84s (14773s total) loss: 105.746\n",
      "Epoch: [11] [ 9121/10059] total steps:[109711] lr:[0.00005000] time: 14.84s (14788s total) loss: 150.084\n",
      "Epoch: [11] [ 9131/10059] total steps:[109721] lr:[0.00005000] time: 14.82s (14803s total) loss: 84.694\n",
      "Epoch: [11] [ 9141/10059] total steps:[109731] lr:[0.00005000] time: 14.79s (14818s total) loss: 146.344\n",
      "Epoch: [11] [ 9151/10059] total steps:[109741] lr:[0.00005000] time: 14.60s (14832s total) loss: 114.283\n",
      "Epoch: [11] [ 9161/10059] total steps:[109751] lr:[0.00005000] time: 14.85s (14847s total) loss: 153.379\n",
      "Epoch: [11] [ 9171/10059] total steps:[109761] lr:[0.00005000] time: 14.79s (14862s total) loss: 181.844\n",
      "Epoch: [11] [ 9181/10059] total steps:[109771] lr:[0.00005000] time: 14.76s (14877s total) loss: 185.485\n",
      "Epoch: [11] [ 9191/10059] total steps:[109781] lr:[0.00005000] time: 14.59s (14891s total) loss: 130.719\n",
      "Epoch: [11] [ 9201/10059] total steps:[109791] lr:[0.00005000] time: 14.68s (14906s total) loss: 114.538\n",
      "Epoch: [11] [ 9211/10059] total steps:[109801] lr:[0.00005000] time: 14.83s (14921s total) loss: 113.593\n",
      "Epoch: [11] [ 9221/10059] total steps:[109811] lr:[0.00005000] time: 14.89s (14936s total) loss: 112.303\n",
      "Epoch: [11] [ 9231/10059] total steps:[109821] lr:[0.00005000] time: 14.82s (14950s total) loss: 130.599\n",
      "Epoch: [11] [ 9241/10059] total steps:[109831] lr:[0.00005000] time: 14.80s (14965s total) loss: 148.092\n",
      "Epoch: [11] [ 9251/10059] total steps:[109841] lr:[0.00005000] time: 14.73s (14980s total) loss: 168.005\n",
      "Epoch: [11] [ 9261/10059] total steps:[109851] lr:[0.00005000] time: 14.81s (14995s total) loss: 104.263\n",
      "Epoch: [11] [ 9271/10059] total steps:[109861] lr:[0.00005000] time: 14.87s (15010s total) loss: 143.077\n",
      "Epoch: [11] [ 9281/10059] total steps:[109871] lr:[0.00005000] time: 14.88s (15025s total) loss: 132.471\n",
      "Epoch: [11] [ 9291/10059] total steps:[109881] lr:[0.00005000] time: 14.76s (15039s total) loss: 171.728\n",
      "Epoch: [11] [ 9301/10059] total steps:[109891] lr:[0.00005000] time: 14.67s (15054s total) loss: 135.976\n",
      "Epoch: [11] [ 9311/10059] total steps:[109901] lr:[0.00005000] time: 14.70s (15069s total) loss: 162.202\n",
      "Epoch: [11] [ 9321/10059] total steps:[109911] lr:[0.00005000] time: 14.70s (15083s total) loss: 91.713\n",
      "Epoch: [11] [ 9331/10059] total steps:[109921] lr:[0.00005000] time: 14.79s (15098s total) loss: 155.378\n",
      "Epoch: [11] [ 9341/10059] total steps:[109931] lr:[0.00005000] time: 14.81s (15113s total) loss: 170.967\n",
      "Epoch: [11] [ 9351/10059] total steps:[109941] lr:[0.00005000] time: 14.79s (15128s total) loss: 167.460\n",
      "Epoch: [11] [ 9361/10059] total steps:[109951] lr:[0.00005000] time: 14.84s (15143s total) loss: 211.538\n",
      "Epoch: [11] [ 9371/10059] total steps:[109961] lr:[0.00005000] time: 14.69s (15157s total) loss: 181.850\n",
      "Epoch: [11] [ 9381/10059] total steps:[109971] lr:[0.00005000] time: 14.81s (15172s total) loss: 111.438\n",
      "Epoch: [11] [ 9391/10059] total steps:[109981] lr:[0.00005000] time: 14.76s (15187s total) loss: 190.948\n",
      "Epoch: [11] [ 9401/10059] total steps:[109991] lr:[0.00005000] time: 14.75s (15202s total) loss: 139.401\n",
      "Epoch: [11] [ 9411/10059] total steps:[110001] lr:[0.00005000] time: 14.80s (15216s total) loss: 120.569\n",
      "Epoch: [11] [ 9421/10059] total steps:[110011] lr:[0.00005000] time: 14.77s (15231s total) loss: 185.695\n",
      "Epoch: [11] [ 9431/10059] total steps:[110021] lr:[0.00005000] time: 14.71s (15246s total) loss: 158.499\n",
      "Epoch: [11] [ 9441/10059] total steps:[110031] lr:[0.00005000] time: 14.89s (15261s total) loss: 166.256\n",
      "Epoch: [11] [ 9451/10059] total steps:[110041] lr:[0.00005000] time: 14.80s (15276s total) loss: 157.894\n",
      "Epoch: [11] [ 9461/10059] total steps:[110051] lr:[0.00005000] time: 14.70s (15290s total) loss: 183.132\n",
      "Epoch: [11] [ 9471/10059] total steps:[110061] lr:[0.00005000] time: 14.72s (15305s total) loss: 104.702\n",
      "Epoch: [11] [ 9481/10059] total steps:[110071] lr:[0.00005000] time: 14.68s (15320s total) loss: 125.656\n",
      "Epoch: [11] [ 9491/10059] total steps:[110081] lr:[0.00005000] time: 14.65s (15334s total) loss: 164.477\n",
      "Epoch: [11] [ 9501/10059] total steps:[110091] lr:[0.00005000] time: 14.77s (15349s total) loss: 89.873\n",
      "Epoch: [11] [ 9511/10059] total steps:[110101] lr:[0.00005000] time: 14.83s (15364s total) loss: 90.279\n",
      "Epoch: [11] [ 9521/10059] total steps:[110111] lr:[0.00005000] time: 14.71s (15379s total) loss: 143.635\n",
      "Epoch: [11] [ 9531/10059] total steps:[110121] lr:[0.00005000] time: 14.75s (15393s total) loss: 81.430\n",
      "Epoch: [11] [ 9541/10059] total steps:[110131] lr:[0.00005000] time: 14.77s (15408s total) loss: 127.137\n",
      "Epoch: [11] [ 9551/10059] total steps:[110141] lr:[0.00005000] time: 14.75s (15423s total) loss: 144.429\n",
      "Epoch: [11] [ 9561/10059] total steps:[110151] lr:[0.00005000] time: 14.79s (15438s total) loss: 186.799\n",
      "Epoch: [11] [ 9571/10059] total steps:[110161] lr:[0.00005000] time: 14.79s (15452s total) loss: 161.332\n",
      "Epoch: [11] [ 9581/10059] total steps:[110171] lr:[0.00005000] time: 14.87s (15467s total) loss: 97.178\n",
      "Epoch: [11] [ 9591/10059] total steps:[110181] lr:[0.00005000] time: 14.72s (15482s total) loss: 165.706\n",
      "Epoch: [11] [ 9601/10059] total steps:[110191] lr:[0.00005000] time: 14.72s (15497s total) loss: 134.901\n",
      "Epoch: [11] [ 9611/10059] total steps:[110201] lr:[0.00005000] time: 14.85s (15512s total) loss: 171.319\n",
      "Epoch: [11] [ 9621/10059] total steps:[110211] lr:[0.00005000] time: 14.77s (15526s total) loss: 131.983\n",
      "Epoch: [11] [ 9631/10059] total steps:[110221] lr:[0.00005000] time: 14.82s (15541s total) loss: 126.350\n",
      "Epoch: [11] [ 9641/10059] total steps:[110231] lr:[0.00005000] time: 14.69s (15556s total) loss: 66.349\n",
      "Epoch: [11] [ 9651/10059] total steps:[110241] lr:[0.00005000] time: 14.84s (15571s total) loss: 95.798\n",
      "Epoch: [11] [ 9661/10059] total steps:[110251] lr:[0.00005000] time: 14.79s (15586s total) loss: 131.692\n",
      "Epoch: [11] [ 9671/10059] total steps:[110261] lr:[0.00005000] time: 14.90s (15600s total) loss: 137.624\n",
      "Epoch: [11] [ 9681/10059] total steps:[110271] lr:[0.00005000] time: 14.67s (15615s total) loss: 147.875\n",
      "Epoch: [11] [ 9691/10059] total steps:[110281] lr:[0.00005000] time: 14.75s (15630s total) loss: 120.594\n",
      "Epoch: [11] [ 9701/10059] total steps:[110291] lr:[0.00005000] time: 14.89s (15645s total) loss: 124.623\n",
      "Epoch: [11] [ 9711/10059] total steps:[110301] lr:[0.00005000] time: 14.77s (15660s total) loss: 195.089\n",
      "Epoch: [11] [ 9721/10059] total steps:[110311] lr:[0.00005000] time: 14.88s (15674s total) loss: 153.760\n",
      "Epoch: [11] [ 9731/10059] total steps:[110321] lr:[0.00005000] time: 14.70s (15689s total) loss: 93.160\n",
      "Epoch: [11] [ 9741/10059] total steps:[110331] lr:[0.00005000] time: 14.70s (15704s total) loss: 129.003\n",
      "Epoch: [11] [ 9751/10059] total steps:[110341] lr:[0.00005000] time: 14.73s (15719s total) loss: 120.845\n",
      "Epoch: [11] [ 9761/10059] total steps:[110351] lr:[0.00005000] time: 14.69s (15733s total) loss: 152.988\n",
      "Epoch: [11] [ 9771/10059] total steps:[110361] lr:[0.00005000] time: 14.71s (15748s total) loss: 145.219\n",
      "Epoch: [11] [ 9781/10059] total steps:[110371] lr:[0.00005000] time: 14.72s (15763s total) loss: 147.460\n",
      "Epoch: [11] [ 9791/10059] total steps:[110381] lr:[0.00005000] time: 14.72s (15777s total) loss: 122.554\n",
      "Epoch: [11] [ 9801/10059] total steps:[110391] lr:[0.00005000] time: 14.81s (15792s total) loss: 123.374\n",
      "Epoch: [11] [ 9811/10059] total steps:[110401] lr:[0.00005000] time: 14.96s (15807s total) loss: 139.626\n",
      "Epoch: [11] [ 9821/10059] total steps:[110411] lr:[0.00005000] time: 14.72s (15822s total) loss: 88.350\n",
      "Epoch: [11] [ 9831/10059] total steps:[110421] lr:[0.00005000] time: 14.72s (15837s total) loss: 122.140\n",
      "Epoch: [11] [ 9841/10059] total steps:[110431] lr:[0.00005000] time: 14.65s (15851s total) loss: 155.056\n",
      "Epoch: [11] [ 9851/10059] total steps:[110441] lr:[0.00005000] time: 14.81s (15866s total) loss: 160.016\n",
      "Epoch: [11] [ 9861/10059] total steps:[110451] lr:[0.00005000] time: 14.83s (15881s total) loss: 124.970\n",
      "Epoch: [11] [ 9871/10059] total steps:[110461] lr:[0.00005000] time: 14.85s (15896s total) loss: 130.839\n",
      "Epoch: [11] [ 9881/10059] total steps:[110471] lr:[0.00005000] time: 14.75s (15910s total) loss: 77.095\n",
      "Epoch: [11] [ 9891/10059] total steps:[110481] lr:[0.00005000] time: 14.80s (15925s total) loss: 148.663\n",
      "Epoch: [11] [ 9901/10059] total steps:[110491] lr:[0.00005000] time: 14.75s (15940s total) loss: 187.909\n",
      "Epoch: [11] [ 9911/10059] total steps:[110501] lr:[0.00005000] time: 14.76s (15955s total) loss: 175.235\n",
      "Epoch: [11] [ 9921/10059] total steps:[110511] lr:[0.00005000] time: 14.86s (15970s total) loss: 165.509\n",
      "Epoch: [11] [ 9931/10059] total steps:[110521] lr:[0.00005000] time: 14.76s (15984s total) loss: 146.848\n",
      "Epoch: [11] [ 9941/10059] total steps:[110531] lr:[0.00005000] time: 14.84s (15999s total) loss: 201.339\n",
      "Epoch: [11] [ 9951/10059] total steps:[110541] lr:[0.00005000] time: 14.76s (16014s total) loss: 176.122\n",
      "Epoch: [11] [ 9961/10059] total steps:[110551] lr:[0.00005000] time: 14.87s (16029s total) loss: 121.851\n",
      "Epoch: [11] [ 9971/10059] total steps:[110561] lr:[0.00005000] time: 14.80s (16044s total) loss: 196.916\n",
      "Epoch: [11] [ 9981/10059] total steps:[110571] lr:[0.00005000] time: 14.71s (16058s total) loss: 144.708\n",
      "Epoch: [11] [ 9991/10059] total steps:[110581] lr:[0.00005000] time: 14.71s (16073s total) loss: 136.531\n",
      "Epoch: [11] [10001/10059] total steps:[110591] lr:[0.00005000] time: 14.76s (16088s total) loss: 164.238\n",
      "Epoch: [11] [10011/10059] total steps:[110601] lr:[0.00005000] time: 14.88s (16103s total) loss: 171.859\n",
      "Epoch: [11] [10021/10059] total steps:[110611] lr:[0.00005000] time: 14.84s (16118s total) loss: 96.195\n",
      "Epoch: [11] [10031/10059] total steps:[110621] lr:[0.00005000] time: 14.90s (16132s total) loss: 140.600\n",
      "Epoch: [11] [10041/10059] total steps:[110631] lr:[0.00005000] time: 14.77s (16147s total) loss: 149.270\n",
      "Epoch: [11] [10051/10059] total steps:[110641] lr:[0.00005000] time: 14.75s (16162s total) loss: 113.311\n",
      "[Info] Saving checkpoint to ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints ...\n",
      "Epoch: [12] [    2/10059] total steps:[110651] lr:[0.00005000] time: 342.83s (16505s total) loss: 126.471\n",
      "Epoch: [12] [   12/10059] total steps:[110661] lr:[0.00005000] time: 14.49s (16519s total) loss: 122.336\n",
      "Epoch: [12] [   22/10059] total steps:[110671] lr:[0.00005000] time: 14.78s (16534s total) loss: 91.412\n",
      "Epoch: [12] [   32/10059] total steps:[110681] lr:[0.00005000] time: 14.53s (16549s total) loss: 155.987\n",
      "Epoch: [12] [   42/10059] total steps:[110691] lr:[0.00005000] time: 14.59s (16563s total) loss: 131.057\n",
      "Epoch: [12] [   52/10059] total steps:[110701] lr:[0.00005000] time: 14.83s (16578s total) loss: 98.288\n",
      "Epoch: [12] [   62/10059] total steps:[110711] lr:[0.00005000] time: 14.84s (16593s total) loss: 134.044\n",
      "Epoch: [12] [   72/10059] total steps:[110721] lr:[0.00005000] time: 14.65s (16608s total) loss: 124.074\n",
      "Epoch: [12] [   82/10059] total steps:[110731] lr:[0.00005000] time: 14.82s (16622s total) loss: 124.202\n",
      "Epoch: [12] [   92/10059] total steps:[110741] lr:[0.00005000] time: 14.85s (16637s total) loss: 117.665\n",
      "Epoch: [12] [  102/10059] total steps:[110751] lr:[0.00005000] time: 14.64s (16652s total) loss: 128.738\n",
      "Epoch: [12] [  112/10059] total steps:[110761] lr:[0.00005000] time: 14.83s (16667s total) loss: 158.722\n",
      "Epoch: [12] [  122/10059] total steps:[110771] lr:[0.00005000] time: 14.93s (16682s total) loss: 174.679\n",
      "Epoch: [12] [  132/10059] total steps:[110781] lr:[0.00005000] time: 14.89s (16696s total) loss: 165.361\n",
      "Epoch: [12] [  142/10059] total steps:[110791] lr:[0.00005000] time: 14.73s (16711s total) loss: 189.024\n",
      "Epoch: [12] [  152/10059] total steps:[110801] lr:[0.00005000] time: 14.82s (16726s total) loss: 158.009\n",
      "Epoch: [12] [  162/10059] total steps:[110811] lr:[0.00005000] time: 14.77s (16741s total) loss: 153.271\n",
      "Epoch: [12] [  172/10059] total steps:[110821] lr:[0.00005000] time: 14.68s (16755s total) loss: 148.317\n",
      "Epoch: [12] [  182/10059] total steps:[110831] lr:[0.00005000] time: 14.75s (16770s total) loss: 95.535\n",
      "Epoch: [12] [  192/10059] total steps:[110841] lr:[0.00005000] time: 14.81s (16785s total) loss: 166.344\n",
      "Epoch: [12] [  202/10059] total steps:[110851] lr:[0.00005000] time: 14.66s (16800s total) loss: 157.057\n",
      "Epoch: [12] [  212/10059] total steps:[110861] lr:[0.00005000] time: 14.72s (16814s total) loss: 158.183\n",
      "Epoch: [12] [  222/10059] total steps:[110871] lr:[0.00005000] time: 14.84s (16829s total) loss: 112.291\n",
      "Epoch: [12] [  232/10059] total steps:[110881] lr:[0.00005000] time: 14.77s (16844s total) loss: 120.362\n",
      "Epoch: [12] [  242/10059] total steps:[110891] lr:[0.00005000] time: 14.83s (16859s total) loss: 115.719\n",
      "Epoch: [12] [  252/10059] total steps:[110901] lr:[0.00005000] time: 14.87s (16874s total) loss: 146.854\n",
      "Epoch: [12] [  262/10059] total steps:[110911] lr:[0.00005000] time: 14.71s (16888s total) loss: 170.542\n",
      "Epoch: [12] [  272/10059] total steps:[110921] lr:[0.00005000] time: 14.80s (16903s total) loss: 160.616\n",
      "Epoch: [12] [  282/10059] total steps:[110931] lr:[0.00005000] time: 14.67s (16918s total) loss: 132.195\n",
      "Epoch: [12] [  292/10059] total steps:[110941] lr:[0.00005000] time: 14.79s (16933s total) loss: 129.565\n",
      "Epoch: [12] [  302/10059] total steps:[110951] lr:[0.00005000] time: 14.83s (16948s total) loss: 145.702\n",
      "Epoch: [12] [  312/10059] total steps:[110961] lr:[0.00005000] time: 14.84s (16962s total) loss: 174.591\n",
      "Epoch: [12] [  322/10059] total steps:[110971] lr:[0.00005000] time: 14.79s (16977s total) loss: 86.363\n",
      "Epoch: [12] [  332/10059] total steps:[110981] lr:[0.00005000] time: 14.85s (16992s total) loss: 153.928\n",
      "Epoch: [12] [  342/10059] total steps:[110991] lr:[0.00005000] time: 14.90s (17007s total) loss: 134.950\n",
      "Epoch: [12] [  352/10059] total steps:[111001] lr:[0.00005000] time: 14.77s (17022s total) loss: 149.968\n",
      "Epoch: [12] [  362/10059] total steps:[111011] lr:[0.00005000] time: 14.74s (17036s total) loss: 202.106\n",
      "Epoch: [12] [  372/10059] total steps:[111021] lr:[0.00005000] time: 14.75s (17051s total) loss: 201.596\n",
      "Epoch: [12] [  382/10059] total steps:[111031] lr:[0.00005000] time: 14.76s (17066s total) loss: 153.582\n",
      "Epoch: [12] [  392/10059] total steps:[111041] lr:[0.00005000] time: 14.77s (17081s total) loss: 123.872\n",
      "Epoch: [12] [  402/10059] total steps:[111051] lr:[0.00005000] time: 14.74s (17095s total) loss: 131.405\n",
      "Epoch: [12] [  412/10059] total steps:[111061] lr:[0.00005000] time: 14.90s (17110s total) loss: 116.297\n",
      "Epoch: [12] [  422/10059] total steps:[111071] lr:[0.00005000] time: 14.79s (17125s total) loss: 112.780\n",
      "Epoch: [12] [  432/10059] total steps:[111081] lr:[0.00005000] time: 14.79s (17140s total) loss: 165.605\n",
      "Epoch: [12] [  442/10059] total steps:[111091] lr:[0.00005000] time: 17.58s (17157s total) loss: 158.683\n",
      "Epoch: [12] [  452/10059] total steps:[111101] lr:[0.00005000] time: 14.80s (17172s total) loss: 93.254\n",
      "Epoch: [12] [  462/10059] total steps:[111111] lr:[0.00005000] time: 14.77s (17187s total) loss: 116.780\n",
      "Epoch: [12] [  472/10059] total steps:[111121] lr:[0.00005000] time: 14.68s (17202s total) loss: 145.371\n",
      "Epoch: [12] [  482/10059] total steps:[111131] lr:[0.00005000] time: 14.83s (17217s total) loss: 159.777\n",
      "Epoch: [12] [  492/10059] total steps:[111141] lr:[0.00005000] time: 14.91s (17231s total) loss: 174.130\n",
      "Epoch: [12] [  502/10059] total steps:[111151] lr:[0.00005000] time: 15.10s (17247s total) loss: 131.285\n",
      "Epoch: [12] [  512/10059] total steps:[111161] lr:[0.00005000] time: 14.72s (17261s total) loss: 183.536\n",
      "Epoch: [12] [  522/10059] total steps:[111171] lr:[0.00005000] time: 14.72s (17276s total) loss: 176.196\n",
      "Epoch: [12] [  532/10059] total steps:[111181] lr:[0.00005000] time: 14.79s (17291s total) loss: 153.559\n",
      "Epoch: [12] [  542/10059] total steps:[111191] lr:[0.00005000] time: 14.87s (17306s total) loss: 133.769\n",
      "Epoch: [12] [  552/10059] total steps:[111201] lr:[0.00005000] time: 14.79s (17320s total) loss: 129.345\n",
      "Epoch: [12] [  562/10059] total steps:[111211] lr:[0.00005000] time: 14.69s (17335s total) loss: 145.725\n",
      "Epoch: [12] [  572/10059] total steps:[111221] lr:[0.00005000] time: 14.80s (17350s total) loss: 130.243\n",
      "Epoch: [12] [  582/10059] total steps:[111231] lr:[0.00005000] time: 14.90s (17365s total) loss: 158.513\n",
      "Epoch: [12] [  592/10059] total steps:[111241] lr:[0.00005000] time: 14.90s (17380s total) loss: 124.507\n",
      "Epoch: [12] [  602/10059] total steps:[111251] lr:[0.00005000] time: 14.76s (17395s total) loss: 123.491\n",
      "Epoch: [12] [  612/10059] total steps:[111261] lr:[0.00005000] time: 14.78s (17409s total) loss: 134.261\n",
      "Epoch: [12] [  622/10059] total steps:[111271] lr:[0.00005000] time: 14.78s (17424s total) loss: 106.920\n",
      "Epoch: [12] [  632/10059] total steps:[111281] lr:[0.00005000] time: 14.80s (17439s total) loss: 104.336\n",
      "Epoch: [12] [  642/10059] total steps:[111291] lr:[0.00005000] time: 14.82s (17454s total) loss: 125.997\n",
      "Epoch: [12] [  652/10059] total steps:[111301] lr:[0.00005000] time: 14.77s (17468s total) loss: 119.227\n",
      "Epoch: [12] [  662/10059] total steps:[111311] lr:[0.00005000] time: 14.74s (17483s total) loss: 165.057\n",
      "Epoch: [12] [  672/10059] total steps:[111321] lr:[0.00005000] time: 14.83s (17498s total) loss: 174.403\n",
      "Epoch: [12] [  682/10059] total steps:[111331] lr:[0.00005000] time: 14.77s (17513s total) loss: 136.833\n",
      "Epoch: [12] [  692/10059] total steps:[111341] lr:[0.00005000] time: 14.82s (17528s total) loss: 89.695\n",
      "Epoch: [12] [  702/10059] total steps:[111351] lr:[0.00005000] time: 14.80s (17542s total) loss: 86.647\n",
      "Epoch: [12] [  712/10059] total steps:[111361] lr:[0.00005000] time: 14.75s (17557s total) loss: 79.455\n",
      "Epoch: [12] [  722/10059] total steps:[111371] lr:[0.00005000] time: 14.62s (17572s total) loss: 177.951\n",
      "Epoch: [12] [  732/10059] total steps:[111381] lr:[0.00005000] time: 14.77s (17587s total) loss: 147.580\n",
      "Epoch: [12] [  742/10059] total steps:[111391] lr:[0.00005000] time: 14.85s (17601s total) loss: 131.705\n",
      "Epoch: [12] [  752/10059] total steps:[111401] lr:[0.00005000] time: 14.83s (17616s total) loss: 115.427\n",
      "Epoch: [12] [  762/10059] total steps:[111411] lr:[0.00005000] time: 14.88s (17631s total) loss: 142.180\n",
      "Epoch: [12] [  772/10059] total steps:[111421] lr:[0.00005000] time: 14.81s (17646s total) loss: 142.292\n",
      "Epoch: [12] [  782/10059] total steps:[111431] lr:[0.00005000] time: 14.59s (17661s total) loss: 144.480\n",
      "Epoch: [12] [  792/10059] total steps:[111441] lr:[0.00005000] time: 14.76s (17675s total) loss: 107.758\n",
      "Epoch: [12] [  802/10059] total steps:[111451] lr:[0.00005000] time: 14.74s (17690s total) loss: 155.144\n",
      "Epoch: [12] [  812/10059] total steps:[111461] lr:[0.00005000] time: 14.70s (17705s total) loss: 87.837\n",
      "Epoch: [12] [  822/10059] total steps:[111471] lr:[0.00005000] time: 14.71s (17719s total) loss: 120.350\n",
      "Epoch: [12] [  832/10059] total steps:[111481] lr:[0.00005000] time: 14.72s (17734s total) loss: 141.259\n",
      "Epoch: [12] [  842/10059] total steps:[111491] lr:[0.00005000] time: 14.84s (17749s total) loss: 111.586\n",
      "Epoch: [12] [  852/10059] total steps:[111501] lr:[0.00005000] time: 14.81s (17764s total) loss: 106.389\n",
      "Epoch: [12] [  862/10059] total steps:[111511] lr:[0.00005000] time: 14.73s (17779s total) loss: 164.077\n",
      "Epoch: [12] [  872/10059] total steps:[111521] lr:[0.00005000] time: 14.73s (17793s total) loss: 157.978\n",
      "Epoch: [12] [  882/10059] total steps:[111531] lr:[0.00005000] time: 14.76s (17808s total) loss: 148.010\n",
      "Epoch: [12] [  892/10059] total steps:[111541] lr:[0.00005000] time: 14.86s (17823s total) loss: 132.416\n",
      "Epoch: [12] [  902/10059] total steps:[111551] lr:[0.00005000] time: 14.81s (17838s total) loss: 102.352\n",
      "Epoch: [12] [  912/10059] total steps:[111561] lr:[0.00005000] time: 14.71s (17852s total) loss: 144.912\n",
      "Epoch: [12] [  922/10059] total steps:[111571] lr:[0.00005000] time: 14.79s (17867s total) loss: 179.438\n",
      "Epoch: [12] [  932/10059] total steps:[111581] lr:[0.00005000] time: 14.78s (17882s total) loss: 142.887\n",
      "Epoch: [12] [  942/10059] total steps:[111591] lr:[0.00005000] time: 15.00s (17897s total) loss: 125.205\n",
      "Epoch: [12] [  952/10059] total steps:[111601] lr:[0.00005000] time: 14.87s (17912s total) loss: 136.724\n",
      "Epoch: [12] [  962/10059] total steps:[111611] lr:[0.00005000] time: 14.80s (17927s total) loss: 85.021\n",
      "Epoch: [12] [  972/10059] total steps:[111621] lr:[0.00005000] time: 14.80s (17941s total) loss: 121.868\n",
      "Epoch: [12] [  982/10059] total steps:[111631] lr:[0.00005000] time: 14.72s (17956s total) loss: 111.234\n",
      "Epoch: [12] [  992/10059] total steps:[111641] lr:[0.00005000] time: 14.68s (17971s total) loss: 181.707\n",
      "Epoch: [12] [ 1002/10059] total steps:[111651] lr:[0.00005000] time: 14.72s (17986s total) loss: 172.095\n",
      "Epoch: [12] [ 1012/10059] total steps:[111661] lr:[0.00005000] time: 14.72s (18000s total) loss: 128.191\n",
      "Epoch: [12] [ 1022/10059] total steps:[111671] lr:[0.00005000] time: 14.75s (18015s total) loss: 118.962\n",
      "Epoch: [12] [ 1032/10059] total steps:[111681] lr:[0.00005000] time: 14.72s (18030s total) loss: 148.457\n",
      "Epoch: [12] [ 1042/10059] total steps:[111691] lr:[0.00005000] time: 14.78s (18045s total) loss: 150.352\n",
      "Epoch: [12] [ 1052/10059] total steps:[111701] lr:[0.00005000] time: 14.84s (18059s total) loss: 154.402\n",
      "Epoch: [12] [ 1062/10059] total steps:[111711] lr:[0.00005000] time: 14.84s (18074s total) loss: 115.435\n",
      "Epoch: [12] [ 1072/10059] total steps:[111721] lr:[0.00005000] time: 14.73s (18089s total) loss: 120.281\n",
      "Epoch: [12] [ 1082/10059] total steps:[111731] lr:[0.00005000] time: 14.89s (18104s total) loss: 154.267\n",
      "Epoch: [12] [ 1092/10059] total steps:[111741] lr:[0.00005000] time: 14.92s (18119s total) loss: 118.536\n",
      "Epoch: [12] [ 1102/10059] total steps:[111751] lr:[0.00005000] time: 14.85s (18134s total) loss: 139.329\n",
      "Epoch: [12] [ 1112/10059] total steps:[111761] lr:[0.00005000] time: 14.79s (18148s total) loss: 149.633\n",
      "Epoch: [12] [ 1122/10059] total steps:[111771] lr:[0.00005000] time: 14.79s (18163s total) loss: 126.435\n",
      "Epoch: [12] [ 1132/10059] total steps:[111781] lr:[0.00005000] time: 14.63s (18178s total) loss: 95.697\n",
      "Epoch: [12] [ 1142/10059] total steps:[111791] lr:[0.00005000] time: 14.86s (18193s total) loss: 142.927\n",
      "Epoch: [12] [ 1152/10059] total steps:[111801] lr:[0.00005000] time: 14.88s (18208s total) loss: 99.594\n",
      "Epoch: [12] [ 1162/10059] total steps:[111811] lr:[0.00005000] time: 14.92s (18222s total) loss: 112.972\n",
      "Epoch: [12] [ 1172/10059] total steps:[111821] lr:[0.00005000] time: 14.82s (18237s total) loss: 186.352\n",
      "Epoch: [12] [ 1182/10059] total steps:[111831] lr:[0.00005000] time: 14.86s (18252s total) loss: 136.906\n",
      "Epoch: [12] [ 1192/10059] total steps:[111841] lr:[0.00005000] time: 14.73s (18267s total) loss: 144.472\n",
      "Epoch: [12] [ 1202/10059] total steps:[111851] lr:[0.00005000] time: 14.75s (18282s total) loss: 154.951\n",
      "Epoch: [12] [ 1212/10059] total steps:[111861] lr:[0.00005000] time: 14.81s (18296s total) loss: 134.829\n",
      "Epoch: [12] [ 1222/10059] total steps:[111871] lr:[0.00005000] time: 14.80s (18311s total) loss: 139.088\n",
      "Epoch: [12] [ 1232/10059] total steps:[111881] lr:[0.00005000] time: 14.94s (18326s total) loss: 189.040\n",
      "Epoch: [12] [ 1242/10059] total steps:[111891] lr:[0.00005000] time: 14.79s (18341s total) loss: 103.950\n",
      "Epoch: [12] [ 1252/10059] total steps:[111901] lr:[0.00005000] time: 14.84s (18356s total) loss: 115.487\n",
      "Epoch: [12] [ 1262/10059] total steps:[111911] lr:[0.00005000] time: 14.80s (18371s total) loss: 154.388\n",
      "Epoch: [12] [ 1272/10059] total steps:[111921] lr:[0.00005000] time: 14.85s (18385s total) loss: 141.052\n",
      "Epoch: [12] [ 1282/10059] total steps:[111931] lr:[0.00005000] time: 14.81s (18400s total) loss: 134.196\n",
      "Epoch: [12] [ 1292/10059] total steps:[111941] lr:[0.00005000] time: 14.78s (18415s total) loss: 140.870\n",
      "Epoch: [12] [ 1302/10059] total steps:[111951] lr:[0.00005000] time: 14.74s (18430s total) loss: 152.037\n",
      "Epoch: [12] [ 1312/10059] total steps:[111961] lr:[0.00005000] time: 14.76s (18445s total) loss: 179.580\n",
      "Epoch: [12] [ 1322/10059] total steps:[111971] lr:[0.00005000] time: 14.89s (18459s total) loss: 175.259\n",
      "Epoch: [12] [ 1332/10059] total steps:[111981] lr:[0.00005000] time: 14.72s (18474s total) loss: 154.444\n",
      "Epoch: [12] [ 1342/10059] total steps:[111991] lr:[0.00005000] time: 15.02s (18489s total) loss: 136.260\n",
      "Epoch: [12] [ 1352/10059] total steps:[112001] lr:[0.00005000] time: 14.81s (18504s total) loss: 90.224\n",
      "Epoch: [12] [ 1362/10059] total steps:[112011] lr:[0.00005000] time: 14.89s (18519s total) loss: 147.508\n",
      "Epoch: [12] [ 1372/10059] total steps:[112021] lr:[0.00005000] time: 14.87s (18534s total) loss: 148.102\n",
      "Epoch: [12] [ 1382/10059] total steps:[112031] lr:[0.00005000] time: 14.81s (18549s total) loss: 121.834\n",
      "Epoch: [12] [ 1392/10059] total steps:[112041] lr:[0.00005000] time: 14.68s (18563s total) loss: 154.818\n",
      "Epoch: [12] [ 1402/10059] total steps:[112051] lr:[0.00005000] time: 14.75s (18578s total) loss: 136.396\n",
      "Epoch: [12] [ 1412/10059] total steps:[112061] lr:[0.00005000] time: 14.81s (18593s total) loss: 116.722\n",
      "Epoch: [12] [ 1422/10059] total steps:[112071] lr:[0.00005000] time: 14.82s (18608s total) loss: 136.636\n",
      "Epoch: [12] [ 1432/10059] total steps:[112081] lr:[0.00005000] time: 14.79s (18622s total) loss: 124.312\n",
      "Epoch: [12] [ 1442/10059] total steps:[112091] lr:[0.00005000] time: 14.71s (18637s total) loss: 145.469\n",
      "Epoch: [12] [ 1452/10059] total steps:[112101] lr:[0.00005000] time: 14.85s (18652s total) loss: 136.164\n",
      "Epoch: [12] [ 1462/10059] total steps:[112111] lr:[0.00005000] time: 14.80s (18667s total) loss: 94.847\n",
      "Epoch: [12] [ 1472/10059] total steps:[112121] lr:[0.00005000] time: 14.87s (18682s total) loss: 157.885\n",
      "Epoch: [12] [ 1482/10059] total steps:[112131] lr:[0.00005000] time: 14.87s (18697s total) loss: 104.626\n",
      "Epoch: [12] [ 1492/10059] total steps:[112141] lr:[0.00005000] time: 14.72s (18711s total) loss: 162.259\n",
      "Epoch: [12] [ 1502/10059] total steps:[112151] lr:[0.00005000] time: 14.71s (18726s total) loss: 134.421\n",
      "Epoch: [12] [ 1512/10059] total steps:[112161] lr:[0.00005000] time: 14.77s (18741s total) loss: 60.873\n",
      "Epoch: [12] [ 1522/10059] total steps:[112171] lr:[0.00005000] time: 14.67s (18755s total) loss: 138.924\n",
      "Epoch: [12] [ 1532/10059] total steps:[112181] lr:[0.00005000] time: 14.70s (18770s total) loss: 165.190\n",
      "Epoch: [12] [ 1542/10059] total steps:[112191] lr:[0.00005000] time: 14.78s (18785s total) loss: 122.661\n",
      "Epoch: [12] [ 1552/10059] total steps:[112201] lr:[0.00005000] time: 14.87s (18800s total) loss: 126.940\n",
      "Epoch: [12] [ 1562/10059] total steps:[112211] lr:[0.00005000] time: 14.75s (18815s total) loss: 166.781\n",
      "Epoch: [12] [ 1572/10059] total steps:[112221] lr:[0.00005000] time: 14.68s (18829s total) loss: 141.363\n",
      "Epoch: [12] [ 1582/10059] total steps:[112231] lr:[0.00005000] time: 14.71s (18844s total) loss: 149.967\n",
      "Epoch: [12] [ 1592/10059] total steps:[112241] lr:[0.00005000] time: 14.81s (18859s total) loss: 111.759\n",
      "Epoch: [12] [ 1602/10059] total steps:[112251] lr:[0.00005000] time: 14.78s (18874s total) loss: 147.005\n",
      "Epoch: [12] [ 1612/10059] total steps:[112261] lr:[0.00005000] time: 14.67s (18888s total) loss: 161.212\n",
      "Epoch: [12] [ 1622/10059] total steps:[112271] lr:[0.00005000] time: 14.96s (18903s total) loss: 131.762\n",
      "Epoch: [12] [ 1632/10059] total steps:[112281] lr:[0.00005000] time: 14.91s (18918s total) loss: 96.021\n",
      "Epoch: [12] [ 1642/10059] total steps:[112291] lr:[0.00005000] time: 14.82s (18933s total) loss: 108.948\n",
      "Epoch: [12] [ 1652/10059] total steps:[112301] lr:[0.00005000] time: 14.82s (18948s total) loss: 161.234\n",
      "Epoch: [12] [ 1662/10059] total steps:[112311] lr:[0.00005000] time: 14.77s (18962s total) loss: 142.420\n",
      "Epoch: [12] [ 1672/10059] total steps:[112321] lr:[0.00005000] time: 14.74s (18977s total) loss: 134.022\n",
      "Epoch: [12] [ 1682/10059] total steps:[112331] lr:[0.00005000] time: 14.80s (18992s total) loss: 144.917\n",
      "Epoch: [12] [ 1692/10059] total steps:[112341] lr:[0.00005000] time: 14.84s (19007s total) loss: 143.982\n",
      "Epoch: [12] [ 1702/10059] total steps:[112351] lr:[0.00005000] time: 14.79s (19022s total) loss: 166.446\n",
      "Epoch: [12] [ 1712/10059] total steps:[112361] lr:[0.00005000] time: 14.80s (19036s total) loss: 180.071\n",
      "Epoch: [12] [ 1722/10059] total steps:[112371] lr:[0.00005000] time: 14.72s (19051s total) loss: 169.913\n",
      "Epoch: [12] [ 1732/10059] total steps:[112381] lr:[0.00005000] time: 14.90s (19066s total) loss: 160.869\n",
      "Epoch: [12] [ 1742/10059] total steps:[112391] lr:[0.00005000] time: 14.96s (19081s total) loss: 132.980\n",
      "Epoch: [12] [ 1752/10059] total steps:[112401] lr:[0.00005000] time: 14.81s (19096s total) loss: 122.431\n",
      "Epoch: [12] [ 1762/10059] total steps:[112411] lr:[0.00005000] time: 14.74s (19111s total) loss: 123.030\n",
      "Epoch: [12] [ 1772/10059] total steps:[112421] lr:[0.00005000] time: 14.71s (19125s total) loss: 181.881\n",
      "Epoch: [12] [ 1782/10059] total steps:[112431] lr:[0.00005000] time: 14.76s (19140s total) loss: 124.107\n",
      "Epoch: [12] [ 1792/10059] total steps:[112441] lr:[0.00005000] time: 14.77s (19155s total) loss: 129.146\n",
      "Epoch: [12] [ 1802/10059] total steps:[112451] lr:[0.00005000] time: 14.71s (19169s total) loss: 171.199\n",
      "Epoch: [12] [ 1812/10059] total steps:[112461] lr:[0.00005000] time: 14.69s (19184s total) loss: 111.704\n",
      "Epoch: [12] [ 1822/10059] total steps:[112471] lr:[0.00005000] time: 14.76s (19199s total) loss: 149.326\n",
      "Epoch: [12] [ 1832/10059] total steps:[112481] lr:[0.00005000] time: 14.71s (19214s total) loss: 140.281\n",
      "Epoch: [12] [ 1842/10059] total steps:[112491] lr:[0.00005000] time: 14.77s (19228s total) loss: 136.093\n",
      "Epoch: [12] [ 1852/10059] total steps:[112501] lr:[0.00005000] time: 14.97s (19243s total) loss: 94.128\n",
      "Epoch: [12] [ 1862/10059] total steps:[112511] lr:[0.00005000] time: 14.63s (19258s total) loss: 161.972\n",
      "Epoch: [12] [ 1872/10059] total steps:[112521] lr:[0.00005000] time: 14.78s (19273s total) loss: 112.162\n",
      "Epoch: [12] [ 1882/10059] total steps:[112531] lr:[0.00005000] time: 14.79s (19288s total) loss: 139.222\n",
      "Epoch: [12] [ 1892/10059] total steps:[112541] lr:[0.00005000] time: 14.75s (19302s total) loss: 158.841\n",
      "Epoch: [12] [ 1902/10059] total steps:[112551] lr:[0.00005000] time: 14.77s (19317s total) loss: 93.409\n",
      "Epoch: [12] [ 1912/10059] total steps:[112561] lr:[0.00005000] time: 14.68s (19332s total) loss: 123.708\n",
      "Epoch: [12] [ 1922/10059] total steps:[112571] lr:[0.00005000] time: 14.78s (19347s total) loss: 194.767\n",
      "Epoch: [12] [ 1932/10059] total steps:[112581] lr:[0.00005000] time: 14.77s (19361s total) loss: 139.206\n",
      "Epoch: [12] [ 1942/10059] total steps:[112591] lr:[0.00005000] time: 14.77s (19376s total) loss: 161.313\n",
      "Epoch: [12] [ 1952/10059] total steps:[112601] lr:[0.00005000] time: 14.76s (19391s total) loss: 120.107\n",
      "Epoch: [12] [ 1962/10059] total steps:[112611] lr:[0.00005000] time: 14.89s (19406s total) loss: 133.183\n",
      "Epoch: [12] [ 1972/10059] total steps:[112621] lr:[0.00005000] time: 14.91s (19421s total) loss: 144.727\n",
      "Epoch: [12] [ 1982/10059] total steps:[112631] lr:[0.00005000] time: 14.75s (19435s total) loss: 159.387\n",
      "Epoch: [12] [ 1992/10059] total steps:[112641] lr:[0.00005000] time: 14.71s (19450s total) loss: 110.785\n",
      "Epoch: [12] [ 2002/10059] total steps:[112651] lr:[0.00005000] time: 14.79s (19465s total) loss: 126.174\n",
      "Epoch: [12] [ 2012/10059] total steps:[112661] lr:[0.00005000] time: 14.73s (19480s total) loss: 169.373\n",
      "Epoch: [12] [ 2022/10059] total steps:[112671] lr:[0.00005000] time: 14.88s (19495s total) loss: 119.425\n",
      "Epoch: [12] [ 2032/10059] total steps:[112681] lr:[0.00005000] time: 14.81s (19509s total) loss: 134.127\n",
      "Epoch: [12] [ 2042/10059] total steps:[112691] lr:[0.00005000] time: 14.72s (19524s total) loss: 98.926\n",
      "Epoch: [12] [ 2052/10059] total steps:[112701] lr:[0.00005000] time: 14.78s (19539s total) loss: 163.176\n",
      "Epoch: [12] [ 2062/10059] total steps:[112711] lr:[0.00005000] time: 14.90s (19554s total) loss: 147.623\n",
      "Epoch: [12] [ 2072/10059] total steps:[112721] lr:[0.00005000] time: 14.69s (19568s total) loss: 155.148\n",
      "Epoch: [12] [ 2082/10059] total steps:[112731] lr:[0.00005000] time: 14.72s (19583s total) loss: 130.259\n",
      "Epoch: [12] [ 2092/10059] total steps:[112741] lr:[0.00005000] time: 14.75s (19598s total) loss: 151.898\n",
      "Epoch: [12] [ 2102/10059] total steps:[112751] lr:[0.00005000] time: 14.74s (19613s total) loss: 147.547\n",
      "Epoch: [12] [ 2112/10059] total steps:[112761] lr:[0.00005000] time: 14.85s (19627s total) loss: 127.558\n",
      "Epoch: [12] [ 2122/10059] total steps:[112771] lr:[0.00005000] time: 14.74s (19642s total) loss: 133.288\n",
      "Epoch: [12] [ 2132/10059] total steps:[112781] lr:[0.00005000] time: 14.80s (19657s total) loss: 130.576\n",
      "Epoch: [12] [ 2142/10059] total steps:[112791] lr:[0.00005000] time: 14.75s (19672s total) loss: 102.874\n",
      "Epoch: [12] [ 2152/10059] total steps:[112801] lr:[0.00005000] time: 14.74s (19687s total) loss: 163.410\n",
      "Epoch: [12] [ 2162/10059] total steps:[112811] lr:[0.00005000] time: 14.75s (19701s total) loss: 133.521\n",
      "Epoch: [12] [ 2172/10059] total steps:[112821] lr:[0.00005000] time: 14.74s (19716s total) loss: 139.560\n",
      "Epoch: [12] [ 2182/10059] total steps:[112831] lr:[0.00005000] time: 14.83s (19731s total) loss: 145.746\n",
      "Epoch: [12] [ 2192/10059] total steps:[112841] lr:[0.00005000] time: 14.96s (19746s total) loss: 103.286\n",
      "Epoch: [12] [ 2202/10059] total steps:[112851] lr:[0.00005000] time: 14.83s (19761s total) loss: 128.827\n",
      "Epoch: [12] [ 2212/10059] total steps:[112861] lr:[0.00005000] time: 14.86s (19775s total) loss: 171.261\n",
      "Epoch: [12] [ 2222/10059] total steps:[112871] lr:[0.00005000] time: 14.89s (19790s total) loss: 127.920\n",
      "Epoch: [12] [ 2232/10059] total steps:[112881] lr:[0.00005000] time: 14.78s (19805s total) loss: 110.232\n",
      "Epoch: [12] [ 2242/10059] total steps:[112891] lr:[0.00005000] time: 14.75s (19820s total) loss: 79.396\n",
      "Epoch: [12] [ 2252/10059] total steps:[112901] lr:[0.00005000] time: 14.99s (19835s total) loss: 150.711\n",
      "Epoch: [12] [ 2262/10059] total steps:[112911] lr:[0.00005000] time: 14.90s (19850s total) loss: 175.739\n",
      "Epoch: [12] [ 2272/10059] total steps:[112921] lr:[0.00005000] time: 14.83s (19865s total) loss: 138.422\n",
      "Epoch: [12] [ 2282/10059] total steps:[112931] lr:[0.00005000] time: 14.96s (19880s total) loss: 106.323\n",
      "Epoch: [12] [ 2292/10059] total steps:[112941] lr:[0.00005000] time: 14.84s (19894s total) loss: 166.843\n",
      "Epoch: [12] [ 2302/10059] total steps:[112951] lr:[0.00005000] time: 14.81s (19909s total) loss: 106.640\n",
      "Epoch: [12] [ 2312/10059] total steps:[112961] lr:[0.00005000] time: 14.76s (19924s total) loss: 153.315\n",
      "Epoch: [12] [ 2322/10059] total steps:[112971] lr:[0.00005000] time: 14.79s (19939s total) loss: 121.787\n",
      "Epoch: [12] [ 2332/10059] total steps:[112981] lr:[0.00005000] time: 14.74s (19954s total) loss: 105.201\n",
      "Epoch: [12] [ 2342/10059] total steps:[112991] lr:[0.00005000] time: 14.83s (19968s total) loss: 119.164\n",
      "Epoch: [12] [ 2352/10059] total steps:[113001] lr:[0.00005000] time: 14.77s (19983s total) loss: 179.621\n",
      "Epoch: [12] [ 2362/10059] total steps:[113011] lr:[0.00005000] time: 14.80s (19998s total) loss: 157.028\n",
      "Epoch: [12] [ 2372/10059] total steps:[113021] lr:[0.00005000] time: 14.80s (20013s total) loss: 147.084\n",
      "Epoch: [12] [ 2382/10059] total steps:[113031] lr:[0.00005000] time: 14.81s (20028s total) loss: 183.911\n",
      "Epoch: [12] [ 2392/10059] total steps:[113041] lr:[0.00005000] time: 14.93s (20042s total) loss: 134.404\n",
      "Epoch: [12] [ 2402/10059] total steps:[113051] lr:[0.00005000] time: 14.90s (20057s total) loss: 151.238\n",
      "Epoch: [12] [ 2412/10059] total steps:[113061] lr:[0.00005000] time: 15.02s (20072s total) loss: 102.577\n",
      "Epoch: [12] [ 2422/10059] total steps:[113071] lr:[0.00005000] time: 14.91s (20087s total) loss: 138.210\n",
      "Epoch: [12] [ 2432/10059] total steps:[113081] lr:[0.00005000] time: 14.81s (20102s total) loss: 141.764\n",
      "Epoch: [12] [ 2442/10059] total steps:[113091] lr:[0.00005000] time: 14.82s (20117s total) loss: 147.022\n",
      "Epoch: [12] [ 2452/10059] total steps:[113101] lr:[0.00005000] time: 14.83s (20132s total) loss: 123.063\n",
      "Epoch: [12] [ 2462/10059] total steps:[113111] lr:[0.00005000] time: 14.86s (20147s total) loss: 164.223\n",
      "Epoch: [12] [ 2472/10059] total steps:[113121] lr:[0.00005000] time: 14.89s (20162s total) loss: 128.689\n",
      "Epoch: [12] [ 2482/10059] total steps:[113131] lr:[0.00005000] time: 14.85s (20176s total) loss: 98.528\n",
      "Epoch: [12] [ 2492/10059] total steps:[113141] lr:[0.00005000] time: 14.95s (20191s total) loss: 138.608\n",
      "Epoch: [12] [ 2502/10059] total steps:[113151] lr:[0.00005000] time: 14.85s (20206s total) loss: 150.094\n",
      "Epoch: [12] [ 2512/10059] total steps:[113161] lr:[0.00005000] time: 14.84s (20221s total) loss: 142.528\n",
      "Epoch: [12] [ 2522/10059] total steps:[113171] lr:[0.00005000] time: 14.88s (20236s total) loss: 112.467\n",
      "Epoch: [12] [ 2532/10059] total steps:[113181] lr:[0.00005000] time: 14.72s (20251s total) loss: 94.729\n",
      "Epoch: [12] [ 2542/10059] total steps:[113191] lr:[0.00005000] time: 14.91s (20266s total) loss: 104.816\n",
      "Epoch: [12] [ 2552/10059] total steps:[113201] lr:[0.00005000] time: 14.87s (20280s total) loss: 148.714\n",
      "Epoch: [12] [ 2562/10059] total steps:[113211] lr:[0.00005000] time: 14.77s (20295s total) loss: 99.057\n",
      "Epoch: [12] [ 2572/10059] total steps:[113221] lr:[0.00005000] time: 14.80s (20310s total) loss: 153.128\n",
      "Epoch: [12] [ 2582/10059] total steps:[113231] lr:[0.00005000] time: 14.75s (20325s total) loss: 137.066\n",
      "Epoch: [12] [ 2592/10059] total steps:[113241] lr:[0.00005000] time: 14.76s (20339s total) loss: 180.596\n",
      "Epoch: [12] [ 2602/10059] total steps:[113251] lr:[0.00005000] time: 14.83s (20354s total) loss: 78.074\n",
      "Epoch: [12] [ 2612/10059] total steps:[113261] lr:[0.00005000] time: 14.75s (20369s total) loss: 175.616\n",
      "Epoch: [12] [ 2622/10059] total steps:[113271] lr:[0.00005000] time: 14.82s (20384s total) loss: 132.977\n",
      "Epoch: [12] [ 2632/10059] total steps:[113281] lr:[0.00005000] time: 14.69s (20399s total) loss: 161.883\n",
      "Epoch: [12] [ 2642/10059] total steps:[113291] lr:[0.00005000] time: 14.81s (20413s total) loss: 192.802\n",
      "Epoch: [12] [ 2652/10059] total steps:[113301] lr:[0.00005000] time: 14.79s (20428s total) loss: 123.127\n",
      "Epoch: [12] [ 2662/10059] total steps:[113311] lr:[0.00005000] time: 14.80s (20443s total) loss: 105.693\n",
      "Epoch: [12] [ 2672/10059] total steps:[113321] lr:[0.00005000] time: 14.71s (20458s total) loss: 122.264\n",
      "Epoch: [12] [ 2682/10059] total steps:[113331] lr:[0.00005000] time: 14.71s (20472s total) loss: 163.437\n",
      "Epoch: [12] [ 2692/10059] total steps:[113341] lr:[0.00005000] time: 14.71s (20487s total) loss: 126.532\n",
      "Epoch: [12] [ 2702/10059] total steps:[113351] lr:[0.00005000] time: 14.75s (20502s total) loss: 127.902\n",
      "Epoch: [12] [ 2712/10059] total steps:[113361] lr:[0.00005000] time: 14.77s (20517s total) loss: 148.867\n",
      "Epoch: [12] [ 2722/10059] total steps:[113371] lr:[0.00005000] time: 14.78s (20531s total) loss: 110.765\n",
      "Epoch: [12] [ 2732/10059] total steps:[113381] lr:[0.00005000] time: 14.72s (20546s total) loss: 150.285\n",
      "Epoch: [12] [ 2742/10059] total steps:[113391] lr:[0.00005000] time: 14.85s (20561s total) loss: 125.123\n",
      "Epoch: [12] [ 2752/10059] total steps:[113401] lr:[0.00005000] time: 14.90s (20576s total) loss: 127.666\n",
      "Epoch: [12] [ 2762/10059] total steps:[113411] lr:[0.00005000] time: 14.77s (20591s total) loss: 120.597\n",
      "Epoch: [12] [ 2772/10059] total steps:[113421] lr:[0.00005000] time: 14.79s (20605s total) loss: 128.283\n",
      "Epoch: [12] [ 2782/10059] total steps:[113431] lr:[0.00005000] time: 14.75s (20620s total) loss: 133.568\n",
      "Epoch: [12] [ 2792/10059] total steps:[113441] lr:[0.00005000] time: 14.85s (20635s total) loss: 181.907\n",
      "Epoch: [12] [ 2802/10059] total steps:[113451] lr:[0.00005000] time: 14.75s (20650s total) loss: 117.313\n",
      "Epoch: [12] [ 2812/10059] total steps:[113461] lr:[0.00005000] time: 14.88s (20665s total) loss: 78.831\n",
      "Epoch: [12] [ 2822/10059] total steps:[113471] lr:[0.00005000] time: 14.90s (20680s total) loss: 125.519\n",
      "Epoch: [12] [ 2832/10059] total steps:[113481] lr:[0.00005000] time: 14.79s (20694s total) loss: 162.453\n",
      "Epoch: [12] [ 2842/10059] total steps:[113491] lr:[0.00005000] time: 14.78s (20709s total) loss: 148.102\n",
      "Epoch: [12] [ 2852/10059] total steps:[113501] lr:[0.00005000] time: 14.81s (20724s total) loss: 121.339\n",
      "Epoch: [12] [ 2862/10059] total steps:[113511] lr:[0.00005000] time: 14.76s (20739s total) loss: 223.770\n",
      "Epoch: [12] [ 2872/10059] total steps:[113521] lr:[0.00005000] time: 14.75s (20753s total) loss: 123.781\n",
      "Epoch: [12] [ 2882/10059] total steps:[113531] lr:[0.00005000] time: 14.88s (20768s total) loss: 132.155\n",
      "Epoch: [12] [ 2892/10059] total steps:[113541] lr:[0.00005000] time: 14.72s (20783s total) loss: 138.345\n",
      "Epoch: [12] [ 2902/10059] total steps:[113551] lr:[0.00005000] time: 14.71s (20798s total) loss: 154.901\n",
      "Epoch: [12] [ 2912/10059] total steps:[113561] lr:[0.00005000] time: 14.94s (20813s total) loss: 120.443\n",
      "Epoch: [12] [ 2922/10059] total steps:[113571] lr:[0.00005000] time: 14.76s (20827s total) loss: 78.994\n",
      "Epoch: [12] [ 2932/10059] total steps:[113581] lr:[0.00005000] time: 14.82s (20842s total) loss: 111.174\n",
      "Epoch: [12] [ 2942/10059] total steps:[113591] lr:[0.00005000] time: 14.81s (20857s total) loss: 152.323\n",
      "Epoch: [12] [ 2952/10059] total steps:[113601] lr:[0.00005000] time: 14.88s (20872s total) loss: 132.194\n",
      "Epoch: [12] [ 2962/10059] total steps:[113611] lr:[0.00005000] time: 14.70s (20887s total) loss: 109.188\n",
      "Epoch: [12] [ 2972/10059] total steps:[113621] lr:[0.00005000] time: 14.78s (20901s total) loss: 219.785\n",
      "Epoch: [12] [ 2982/10059] total steps:[113631] lr:[0.00005000] time: 14.80s (20916s total) loss: 96.821\n",
      "Epoch: [12] [ 2992/10059] total steps:[113641] lr:[0.00005000] time: 14.68s (20931s total) loss: 92.664\n",
      "Epoch: [12] [ 3002/10059] total steps:[113651] lr:[0.00005000] time: 14.77s (20946s total) loss: 131.945\n",
      "Epoch: [12] [ 3012/10059] total steps:[113661] lr:[0.00005000] time: 16.36s (20962s total) loss: 168.927\n",
      "Epoch: [12] [ 3022/10059] total steps:[113671] lr:[0.00005000] time: 14.82s (20977s total) loss: 101.970\n",
      "Epoch: [12] [ 3032/10059] total steps:[113681] lr:[0.00005000] time: 14.91s (20992s total) loss: 140.822\n",
      "Epoch: [12] [ 3042/10059] total steps:[113691] lr:[0.00005000] time: 15.10s (21007s total) loss: 140.224\n",
      "Epoch: [12] [ 3052/10059] total steps:[113701] lr:[0.00005000] time: 14.87s (21022s total) loss: 158.736\n",
      "Epoch: [12] [ 3062/10059] total steps:[113711] lr:[0.00005000] time: 14.78s (21037s total) loss: 125.269\n",
      "Epoch: [12] [ 3072/10059] total steps:[113721] lr:[0.00005000] time: 14.90s (21051s total) loss: 111.993\n",
      "Epoch: [12] [ 3082/10059] total steps:[113731] lr:[0.00005000] time: 14.84s (21066s total) loss: 119.482\n",
      "Epoch: [12] [ 3092/10059] total steps:[113741] lr:[0.00005000] time: 14.72s (21081s total) loss: 151.527\n",
      "Epoch: [12] [ 3102/10059] total steps:[113751] lr:[0.00005000] time: 14.84s (21096s total) loss: 92.132\n",
      "Epoch: [12] [ 3112/10059] total steps:[113761] lr:[0.00005000] time: 14.79s (21111s total) loss: 139.619\n",
      "Epoch: [12] [ 3122/10059] total steps:[113771] lr:[0.00005000] time: 14.84s (21125s total) loss: 113.951\n",
      "Epoch: [12] [ 3132/10059] total steps:[113781] lr:[0.00005000] time: 14.77s (21140s total) loss: 167.518\n",
      "Epoch: [12] [ 3142/10059] total steps:[113791] lr:[0.00005000] time: 14.73s (21155s total) loss: 150.484\n",
      "Epoch: [12] [ 3152/10059] total steps:[113801] lr:[0.00005000] time: 14.80s (21170s total) loss: 125.182\n",
      "Epoch: [12] [ 3162/10059] total steps:[113811] lr:[0.00005000] time: 14.72s (21184s total) loss: 128.669\n",
      "Epoch: [12] [ 3172/10059] total steps:[113821] lr:[0.00005000] time: 14.87s (21199s total) loss: 156.491\n",
      "Epoch: [12] [ 3182/10059] total steps:[113831] lr:[0.00005000] time: 14.77s (21214s total) loss: 94.984\n",
      "Epoch: [12] [ 3192/10059] total steps:[113841] lr:[0.00005000] time: 14.77s (21229s total) loss: 115.932\n",
      "Epoch: [12] [ 3202/10059] total steps:[113851] lr:[0.00005000] time: 14.80s (21244s total) loss: 95.249\n",
      "Epoch: [12] [ 3212/10059] total steps:[113861] lr:[0.00005000] time: 14.83s (21259s total) loss: 117.980\n",
      "Epoch: [12] [ 3222/10059] total steps:[113871] lr:[0.00005000] time: 14.77s (21273s total) loss: 98.542\n",
      "Epoch: [12] [ 3232/10059] total steps:[113881] lr:[0.00005000] time: 14.92s (21288s total) loss: 177.387\n",
      "Epoch: [12] [ 3242/10059] total steps:[113891] lr:[0.00005000] time: 14.78s (21303s total) loss: 92.018\n",
      "Epoch: [12] [ 3252/10059] total steps:[113901] lr:[0.00005000] time: 14.91s (21318s total) loss: 132.675\n",
      "Epoch: [12] [ 3262/10059] total steps:[113911] lr:[0.00005000] time: 14.99s (21333s total) loss: 147.234\n",
      "Epoch: [12] [ 3272/10059] total steps:[113921] lr:[0.00005000] time: 14.76s (21348s total) loss: 184.822\n",
      "Epoch: [12] [ 3282/10059] total steps:[113931] lr:[0.00005000] time: 14.86s (21363s total) loss: 101.603\n",
      "Epoch: [12] [ 3292/10059] total steps:[113941] lr:[0.00005000] time: 14.74s (21377s total) loss: 164.491\n",
      "Epoch: [12] [ 3302/10059] total steps:[113951] lr:[0.00005000] time: 14.72s (21392s total) loss: 100.397\n",
      "Epoch: [12] [ 3312/10059] total steps:[113961] lr:[0.00005000] time: 14.85s (21407s total) loss: 99.963\n",
      "Epoch: [12] [ 3322/10059] total steps:[113971] lr:[0.00005000] time: 14.91s (21422s total) loss: 104.928\n",
      "Epoch: [12] [ 3332/10059] total steps:[113981] lr:[0.00005000] time: 14.87s (21437s total) loss: 124.609\n",
      "Epoch: [12] [ 3342/10059] total steps:[113991] lr:[0.00005000] time: 14.76s (21451s total) loss: 121.824\n",
      "Epoch: [12] [ 3352/10059] total steps:[114001] lr:[0.00005000] time: 14.80s (21466s total) loss: 142.234\n",
      "Epoch: [12] [ 3362/10059] total steps:[114011] lr:[0.00005000] time: 14.74s (21481s total) loss: 187.432\n",
      "Epoch: [12] [ 3372/10059] total steps:[114021] lr:[0.00005000] time: 14.83s (21496s total) loss: 150.586\n",
      "Epoch: [12] [ 3382/10059] total steps:[114031] lr:[0.00005000] time: 14.78s (21511s total) loss: 113.439\n",
      "Epoch: [12] [ 3392/10059] total steps:[114041] lr:[0.00005000] time: 14.82s (21525s total) loss: 125.810\n",
      "Epoch: [12] [ 3402/10059] total steps:[114051] lr:[0.00005000] time: 14.75s (21540s total) loss: 76.379\n",
      "Epoch: [12] [ 3412/10059] total steps:[114061] lr:[0.00005000] time: 14.77s (21555s total) loss: 169.170\n",
      "Epoch: [12] [ 3422/10059] total steps:[114071] lr:[0.00005000] time: 14.83s (21570s total) loss: 151.524\n",
      "Epoch: [12] [ 3432/10059] total steps:[114081] lr:[0.00005000] time: 14.75s (21584s total) loss: 129.216\n",
      "Epoch: [12] [ 3442/10059] total steps:[114091] lr:[0.00005000] time: 14.81s (21599s total) loss: 155.412\n",
      "Epoch: [12] [ 3452/10059] total steps:[114101] lr:[0.00005000] time: 14.86s (21614s total) loss: 128.196\n",
      "Epoch: [12] [ 3462/10059] total steps:[114111] lr:[0.00005000] time: 14.75s (21629s total) loss: 167.874\n",
      "Epoch: [12] [ 3472/10059] total steps:[114121] lr:[0.00005000] time: 14.84s (21644s total) loss: 120.055\n",
      "Epoch: [12] [ 3482/10059] total steps:[114131] lr:[0.00005000] time: 14.81s (21659s total) loss: 162.281\n",
      "Epoch: [12] [ 3492/10059] total steps:[114141] lr:[0.00005000] time: 14.65s (21673s total) loss: 103.287\n",
      "Epoch: [12] [ 3502/10059] total steps:[114151] lr:[0.00005000] time: 14.83s (21688s total) loss: 105.944\n",
      "Epoch: [12] [ 3512/10059] total steps:[114161] lr:[0.00005000] time: 14.70s (21703s total) loss: 130.327\n",
      "Epoch: [12] [ 3522/10059] total steps:[114171] lr:[0.00005000] time: 14.75s (21717s total) loss: 139.298\n",
      "Epoch: [12] [ 3532/10059] total steps:[114181] lr:[0.00005000] time: 14.91s (21732s total) loss: 153.729\n",
      "Epoch: [12] [ 3542/10059] total steps:[114191] lr:[0.00005000] time: 14.63s (21747s total) loss: 85.605\n",
      "Epoch: [12] [ 3552/10059] total steps:[114201] lr:[0.00005000] time: 14.81s (21762s total) loss: 164.468\n",
      "Epoch: [12] [ 3562/10059] total steps:[114211] lr:[0.00005000] time: 14.85s (21777s total) loss: 87.387\n",
      "Epoch: [12] [ 3572/10059] total steps:[114221] lr:[0.00005000] time: 14.79s (21791s total) loss: 155.958\n",
      "Epoch: [12] [ 3582/10059] total steps:[114231] lr:[0.00005000] time: 14.86s (21806s total) loss: 120.914\n",
      "Epoch: [12] [ 3592/10059] total steps:[114241] lr:[0.00005000] time: 14.87s (21821s total) loss: 123.981\n",
      "Epoch: [12] [ 3602/10059] total steps:[114251] lr:[0.00005000] time: 14.72s (21836s total) loss: 125.346\n",
      "Epoch: [12] [ 3612/10059] total steps:[114261] lr:[0.00005000] time: 14.85s (21851s total) loss: 113.379\n",
      "Epoch: [12] [ 3622/10059] total steps:[114271] lr:[0.00005000] time: 14.77s (21866s total) loss: 108.669\n",
      "Epoch: [12] [ 3632/10059] total steps:[114281] lr:[0.00005000] time: 14.87s (21880s total) loss: 117.763\n",
      "Epoch: [12] [ 3642/10059] total steps:[114291] lr:[0.00005000] time: 14.73s (21895s total) loss: 178.841\n",
      "Epoch: [12] [ 3652/10059] total steps:[114301] lr:[0.00005000] time: 14.97s (21910s total) loss: 108.966\n",
      "Epoch: [12] [ 3662/10059] total steps:[114311] lr:[0.00005000] time: 14.93s (21925s total) loss: 124.906\n",
      "Epoch: [12] [ 3672/10059] total steps:[114321] lr:[0.00005000] time: 14.81s (21940s total) loss: 156.219\n",
      "Epoch: [12] [ 3682/10059] total steps:[114331] lr:[0.00005000] time: 14.78s (21955s total) loss: 126.356\n",
      "Epoch: [12] [ 3692/10059] total steps:[114341] lr:[0.00005000] time: 14.79s (21969s total) loss: 126.848\n",
      "Epoch: [12] [ 3702/10059] total steps:[114351] lr:[0.00005000] time: 14.72s (21984s total) loss: 125.449\n",
      "Epoch: [12] [ 3712/10059] total steps:[114361] lr:[0.00005000] time: 14.78s (21999s total) loss: 122.689\n",
      "Epoch: [12] [ 3722/10059] total steps:[114371] lr:[0.00005000] time: 15.02s (22014s total) loss: 119.262\n",
      "Epoch: [12] [ 3732/10059] total steps:[114381] lr:[0.00005000] time: 14.83s (22029s total) loss: 169.970\n",
      "Epoch: [12] [ 3742/10059] total steps:[114391] lr:[0.00005000] time: 14.68s (22043s total) loss: 137.489\n",
      "Epoch: [12] [ 3752/10059] total steps:[114401] lr:[0.00005000] time: 14.80s (22058s total) loss: 122.559\n",
      "Epoch: [12] [ 3762/10059] total steps:[114411] lr:[0.00005000] time: 14.76s (22073s total) loss: 152.820\n",
      "Epoch: [12] [ 3772/10059] total steps:[114421] lr:[0.00005000] time: 14.67s (22088s total) loss: 120.527\n",
      "Epoch: [12] [ 3782/10059] total steps:[114431] lr:[0.00005000] time: 14.73s (22102s total) loss: 197.280\n",
      "Epoch: [12] [ 3792/10059] total steps:[114441] lr:[0.00005000] time: 14.75s (22117s total) loss: 149.307\n",
      "Epoch: [12] [ 3802/10059] total steps:[114451] lr:[0.00005000] time: 14.90s (22132s total) loss: 150.363\n",
      "Epoch: [12] [ 3812/10059] total steps:[114461] lr:[0.00005000] time: 14.88s (22147s total) loss: 102.887\n",
      "Epoch: [12] [ 3822/10059] total steps:[114471] lr:[0.00005000] time: 14.86s (22162s total) loss: 108.818\n",
      "Epoch: [12] [ 3832/10059] total steps:[114481] lr:[0.00005000] time: 14.80s (22177s total) loss: 143.235\n",
      "Epoch: [12] [ 3842/10059] total steps:[114491] lr:[0.00005000] time: 14.83s (22191s total) loss: 119.097\n",
      "Epoch: [12] [ 3852/10059] total steps:[114501] lr:[0.00005000] time: 14.83s (22206s total) loss: 148.708\n",
      "Epoch: [12] [ 3862/10059] total steps:[114511] lr:[0.00005000] time: 14.82s (22221s total) loss: 128.349\n",
      "Epoch: [12] [ 3872/10059] total steps:[114521] lr:[0.00005000] time: 14.73s (22236s total) loss: 180.915\n",
      "Epoch: [12] [ 3882/10059] total steps:[114531] lr:[0.00005000] time: 14.80s (22251s total) loss: 101.101\n",
      "Epoch: [12] [ 3892/10059] total steps:[114541] lr:[0.00005000] time: 15.02s (22266s total) loss: 138.784\n",
      "Epoch: [12] [ 3902/10059] total steps:[114551] lr:[0.00005000] time: 14.74s (22280s total) loss: 115.176\n",
      "Epoch: [12] [ 3912/10059] total steps:[114561] lr:[0.00005000] time: 14.75s (22295s total) loss: 132.274\n",
      "Epoch: [12] [ 3922/10059] total steps:[114571] lr:[0.00005000] time: 14.79s (22310s total) loss: 158.410\n",
      "Epoch: [12] [ 3932/10059] total steps:[114581] lr:[0.00005000] time: 14.69s (22325s total) loss: 129.330\n",
      "Epoch: [12] [ 3942/10059] total steps:[114591] lr:[0.00005000] time: 14.84s (22339s total) loss: 151.750\n",
      "Epoch: [12] [ 3952/10059] total steps:[114601] lr:[0.00005000] time: 14.81s (22354s total) loss: 135.819\n",
      "Epoch: [12] [ 3962/10059] total steps:[114611] lr:[0.00005000] time: 14.90s (22369s total) loss: 127.891\n",
      "Epoch: [12] [ 3972/10059] total steps:[114621] lr:[0.00005000] time: 14.92s (22384s total) loss: 161.241\n",
      "Epoch: [12] [ 3982/10059] total steps:[114631] lr:[0.00005000] time: 14.78s (22399s total) loss: 106.771\n",
      "Epoch: [12] [ 3992/10059] total steps:[114641] lr:[0.00005000] time: 14.83s (22414s total) loss: 116.597\n",
      "Epoch: [12] [ 4002/10059] total steps:[114651] lr:[0.00005000] time: 14.84s (22428s total) loss: 190.819\n",
      "Epoch: [12] [ 4012/10059] total steps:[114661] lr:[0.00005000] time: 14.75s (22443s total) loss: 163.842\n",
      "Epoch: [12] [ 4022/10059] total steps:[114671] lr:[0.00005000] time: 14.74s (22458s total) loss: 108.176\n",
      "Epoch: [12] [ 4032/10059] total steps:[114681] lr:[0.00005000] time: 14.72s (22473s total) loss: 88.447\n",
      "Epoch: [12] [ 4042/10059] total steps:[114691] lr:[0.00005000] time: 14.82s (22487s total) loss: 93.064\n",
      "Epoch: [12] [ 4052/10059] total steps:[114701] lr:[0.00005000] time: 14.84s (22502s total) loss: 159.065\n",
      "Epoch: [12] [ 4062/10059] total steps:[114711] lr:[0.00005000] time: 14.90s (22517s total) loss: 126.719\n",
      "Epoch: [12] [ 4072/10059] total steps:[114721] lr:[0.00005000] time: 14.74s (22532s total) loss: 128.719\n",
      "Epoch: [12] [ 4082/10059] total steps:[114731] lr:[0.00005000] time: 14.83s (22547s total) loss: 191.582\n",
      "Epoch: [12] [ 4092/10059] total steps:[114741] lr:[0.00005000] time: 14.75s (22562s total) loss: 103.468\n",
      "Epoch: [12] [ 4102/10059] total steps:[114751] lr:[0.00005000] time: 14.78s (22576s total) loss: 107.714\n",
      "Epoch: [12] [ 4112/10059] total steps:[114761] lr:[0.00005000] time: 14.74s (22591s total) loss: 104.005\n",
      "Epoch: [12] [ 4122/10059] total steps:[114771] lr:[0.00005000] time: 14.86s (22606s total) loss: 138.269\n",
      "Epoch: [12] [ 4132/10059] total steps:[114781] lr:[0.00005000] time: 14.81s (22621s total) loss: 112.649\n",
      "Epoch: [12] [ 4142/10059] total steps:[114791] lr:[0.00005000] time: 14.74s (22635s total) loss: 160.139\n",
      "Epoch: [12] [ 4152/10059] total steps:[114801] lr:[0.00005000] time: 14.79s (22650s total) loss: 164.712\n",
      "Epoch: [12] [ 4162/10059] total steps:[114811] lr:[0.00005000] time: 14.76s (22665s total) loss: 110.775\n",
      "Epoch: [12] [ 4172/10059] total steps:[114821] lr:[0.00005000] time: 14.87s (22680s total) loss: 127.449\n",
      "Epoch: [12] [ 4182/10059] total steps:[114831] lr:[0.00005000] time: 14.76s (22695s total) loss: 132.655\n",
      "Epoch: [12] [ 4192/10059] total steps:[114841] lr:[0.00005000] time: 14.81s (22709s total) loss: 119.930\n",
      "Epoch: [12] [ 4202/10059] total steps:[114851] lr:[0.00005000] time: 14.79s (22724s total) loss: 142.866\n",
      "Epoch: [12] [ 4212/10059] total steps:[114861] lr:[0.00005000] time: 14.72s (22739s total) loss: 139.398\n",
      "Epoch: [12] [ 4222/10059] total steps:[114871] lr:[0.00005000] time: 14.81s (22754s total) loss: 142.276\n",
      "Epoch: [12] [ 4232/10059] total steps:[114881] lr:[0.00005000] time: 14.79s (22769s total) loss: 180.929\n",
      "Epoch: [12] [ 4242/10059] total steps:[114891] lr:[0.00005000] time: 14.78s (22783s total) loss: 133.272\n",
      "Epoch: [12] [ 4252/10059] total steps:[114901] lr:[0.00005000] time: 14.89s (22798s total) loss: 150.455\n",
      "Epoch: [12] [ 4262/10059] total steps:[114911] lr:[0.00005000] time: 14.82s (22813s total) loss: 152.194\n",
      "Epoch: [12] [ 4272/10059] total steps:[114921] lr:[0.00005000] time: 14.72s (22828s total) loss: 133.909\n",
      "Epoch: [12] [ 4282/10059] total steps:[114931] lr:[0.00005000] time: 14.71s (22843s total) loss: 104.796\n",
      "Epoch: [12] [ 4292/10059] total steps:[114941] lr:[0.00005000] time: 14.78s (22857s total) loss: 109.835\n",
      "Epoch: [12] [ 4302/10059] total steps:[114951] lr:[0.00005000] time: 14.85s (22872s total) loss: 134.975\n",
      "Epoch: [12] [ 4312/10059] total steps:[114961] lr:[0.00005000] time: 14.73s (22887s total) loss: 178.764\n",
      "Epoch: [12] [ 4322/10059] total steps:[114971] lr:[0.00005000] time: 14.75s (22902s total) loss: 147.163\n",
      "Epoch: [12] [ 4332/10059] total steps:[114981] lr:[0.00005000] time: 14.80s (22916s total) loss: 133.759\n",
      "Epoch: [12] [ 4342/10059] total steps:[114991] lr:[0.00005000] time: 14.90s (22931s total) loss: 142.297\n",
      "Epoch: [12] [ 4352/10059] total steps:[115001] lr:[0.00005000] time: 14.92s (22946s total) loss: 143.085\n",
      "Epoch: [12] [ 4362/10059] total steps:[115011] lr:[0.00005000] time: 14.84s (22961s total) loss: 102.108\n",
      "Epoch: [12] [ 4372/10059] total steps:[115021] lr:[0.00005000] time: 14.76s (22976s total) loss: 144.309\n",
      "Epoch: [12] [ 4382/10059] total steps:[115031] lr:[0.00005000] time: 14.74s (22991s total) loss: 93.387\n",
      "Epoch: [12] [ 4392/10059] total steps:[115041] lr:[0.00005000] time: 14.80s (23005s total) loss: 206.013\n",
      "Epoch: [12] [ 4402/10059] total steps:[115051] lr:[0.00005000] time: 14.85s (23020s total) loss: 132.328\n",
      "Epoch: [12] [ 4412/10059] total steps:[115061] lr:[0.00005000] time: 14.87s (23035s total) loss: 153.882\n",
      "Epoch: [12] [ 4422/10059] total steps:[115071] lr:[0.00005000] time: 14.71s (23050s total) loss: 152.224\n",
      "Epoch: [12] [ 4432/10059] total steps:[115081] lr:[0.00005000] time: 14.77s (23065s total) loss: 166.770\n",
      "Epoch: [12] [ 4442/10059] total steps:[115091] lr:[0.00005000] time: 14.75s (23079s total) loss: 143.107\n",
      "Epoch: [12] [ 4452/10059] total steps:[115101] lr:[0.00005000] time: 14.88s (23094s total) loss: 148.195\n",
      "Epoch: [12] [ 4462/10059] total steps:[115111] lr:[0.00005000] time: 14.71s (23109s total) loss: 127.909\n",
      "Epoch: [12] [ 4472/10059] total steps:[115121] lr:[0.00005000] time: 14.73s (23124s total) loss: 128.706\n",
      "Epoch: [12] [ 4482/10059] total steps:[115131] lr:[0.00005000] time: 14.69s (23138s total) loss: 140.815\n",
      "Epoch: [12] [ 4492/10059] total steps:[115141] lr:[0.00005000] time: 14.77s (23153s total) loss: 163.090\n",
      "Epoch: [12] [ 4502/10059] total steps:[115151] lr:[0.00005000] time: 14.80s (23168s total) loss: 106.237\n",
      "Epoch: [12] [ 4512/10059] total steps:[115161] lr:[0.00005000] time: 14.70s (23183s total) loss: 103.342\n",
      "Epoch: [12] [ 4522/10059] total steps:[115171] lr:[0.00005000] time: 14.76s (23197s total) loss: 162.552\n",
      "Epoch: [12] [ 4532/10059] total steps:[115181] lr:[0.00005000] time: 14.91s (23212s total) loss: 143.463\n",
      "Epoch: [12] [ 4542/10059] total steps:[115191] lr:[0.00005000] time: 14.71s (23227s total) loss: 141.570\n",
      "Epoch: [12] [ 4552/10059] total steps:[115201] lr:[0.00005000] time: 14.81s (23242s total) loss: 138.716\n",
      "Epoch: [12] [ 4562/10059] total steps:[115211] lr:[0.00005000] time: 14.81s (23257s total) loss: 135.858\n",
      "Epoch: [12] [ 4572/10059] total steps:[115221] lr:[0.00005000] time: 14.75s (23271s total) loss: 154.339\n",
      "Epoch: [12] [ 4582/10059] total steps:[115231] lr:[0.00005000] time: 14.92s (23286s total) loss: 123.936\n",
      "Epoch: [12] [ 4592/10059] total steps:[115241] lr:[0.00005000] time: 14.89s (23301s total) loss: 171.356\n",
      "Epoch: [12] [ 4602/10059] total steps:[115251] lr:[0.00005000] time: 14.74s (23316s total) loss: 172.626\n",
      "Epoch: [12] [ 4612/10059] total steps:[115261] lr:[0.00005000] time: 14.79s (23331s total) loss: 107.055\n",
      "Epoch: [12] [ 4622/10059] total steps:[115271] lr:[0.00005000] time: 14.76s (23345s total) loss: 124.667\n",
      "Epoch: [12] [ 4632/10059] total steps:[115281] lr:[0.00005000] time: 14.83s (23360s total) loss: 132.338\n",
      "Epoch: [12] [ 4642/10059] total steps:[115291] lr:[0.00005000] time: 14.77s (23375s total) loss: 97.946\n",
      "Epoch: [12] [ 4652/10059] total steps:[115301] lr:[0.00005000] time: 14.92s (23390s total) loss: 143.735\n",
      "Epoch: [12] [ 4662/10059] total steps:[115311] lr:[0.00005000] time: 14.78s (23405s total) loss: 129.630\n",
      "Epoch: [12] [ 4672/10059] total steps:[115321] lr:[0.00005000] time: 14.86s (23420s total) loss: 94.383\n",
      "Epoch: [12] [ 4682/10059] total steps:[115331] lr:[0.00005000] time: 14.78s (23434s total) loss: 129.474\n",
      "Epoch: [12] [ 4692/10059] total steps:[115341] lr:[0.00005000] time: 14.81s (23449s total) loss: 146.899\n",
      "Epoch: [12] [ 4702/10059] total steps:[115351] lr:[0.00005000] time: 14.95s (23464s total) loss: 172.412\n",
      "Epoch: [12] [ 4712/10059] total steps:[115361] lr:[0.00005000] time: 14.75s (23479s total) loss: 141.150\n",
      "Epoch: [12] [ 4722/10059] total steps:[115371] lr:[0.00005000] time: 14.77s (23494s total) loss: 166.527\n",
      "Epoch: [12] [ 4732/10059] total steps:[115381] lr:[0.00005000] time: 14.79s (23508s total) loss: 135.982\n",
      "Epoch: [12] [ 4742/10059] total steps:[115391] lr:[0.00005000] time: 14.68s (23523s total) loss: 129.164\n",
      "Epoch: [12] [ 4752/10059] total steps:[115401] lr:[0.00005000] time: 14.80s (23538s total) loss: 124.775\n",
      "Epoch: [12] [ 4762/10059] total steps:[115411] lr:[0.00005000] time: 14.75s (23553s total) loss: 148.338\n",
      "Epoch: [12] [ 4772/10059] total steps:[115421] lr:[0.00005000] time: 14.77s (23567s total) loss: 154.965\n",
      "Epoch: [12] [ 4782/10059] total steps:[115431] lr:[0.00005000] time: 14.84s (23582s total) loss: 176.395\n",
      "Epoch: [12] [ 4792/10059] total steps:[115441] lr:[0.00005000] time: 14.68s (23597s total) loss: 119.115\n",
      "Epoch: [12] [ 4802/10059] total steps:[115451] lr:[0.00005000] time: 14.69s (23612s total) loss: 169.243\n",
      "Epoch: [12] [ 4812/10059] total steps:[115461] lr:[0.00005000] time: 14.69s (23626s total) loss: 162.659\n",
      "Epoch: [12] [ 4822/10059] total steps:[115471] lr:[0.00005000] time: 14.77s (23641s total) loss: 114.630\n",
      "Epoch: [12] [ 4832/10059] total steps:[115481] lr:[0.00005000] time: 14.99s (23656s total) loss: 170.721\n",
      "Epoch: [12] [ 4842/10059] total steps:[115491] lr:[0.00005000] time: 14.84s (23671s total) loss: 141.719\n",
      "Epoch: [12] [ 4852/10059] total steps:[115501] lr:[0.00005000] time: 14.84s (23686s total) loss: 196.422\n",
      "Epoch: [12] [ 4862/10059] total steps:[115511] lr:[0.00005000] time: 14.92s (23701s total) loss: 161.248\n",
      "Epoch: [12] [ 4872/10059] total steps:[115521] lr:[0.00005000] time: 14.95s (23716s total) loss: 139.557\n",
      "Epoch: [12] [ 4882/10059] total steps:[115531] lr:[0.00005000] time: 14.69s (23730s total) loss: 168.076\n",
      "Epoch: [12] [ 4892/10059] total steps:[115541] lr:[0.00005000] time: 14.91s (23745s total) loss: 136.369\n",
      "Epoch: [12] [ 4902/10059] total steps:[115551] lr:[0.00005000] time: 14.83s (23760s total) loss: 138.787\n",
      "Epoch: [12] [ 4912/10059] total steps:[115561] lr:[0.00005000] time: 14.77s (23775s total) loss: 154.095\n",
      "Epoch: [12] [ 4922/10059] total steps:[115571] lr:[0.00005000] time: 14.88s (23790s total) loss: 107.519\n",
      "Epoch: [12] [ 4932/10059] total steps:[115581] lr:[0.00005000] time: 14.80s (23805s total) loss: 129.643\n",
      "Epoch: [12] [ 4942/10059] total steps:[115591] lr:[0.00005000] time: 14.83s (23819s total) loss: 127.706\n",
      "Epoch: [12] [ 4952/10059] total steps:[115601] lr:[0.00005000] time: 14.80s (23834s total) loss: 117.612\n",
      "Epoch: [12] [ 4962/10059] total steps:[115611] lr:[0.00005000] time: 14.82s (23849s total) loss: 132.892\n",
      "Epoch: [12] [ 4972/10059] total steps:[115621] lr:[0.00005000] time: 14.80s (23864s total) loss: 103.622\n",
      "Epoch: [12] [ 4982/10059] total steps:[115631] lr:[0.00005000] time: 14.76s (23879s total) loss: 143.761\n",
      "Epoch: [12] [ 4992/10059] total steps:[115641] lr:[0.00005000] time: 14.80s (23893s total) loss: 143.306\n",
      "Epoch: [12] [ 5002/10059] total steps:[115651] lr:[0.00005000] time: 14.72s (23908s total) loss: 103.816\n",
      "Epoch: [12] [ 5012/10059] total steps:[115661] lr:[0.00005000] time: 14.85s (23923s total) loss: 128.949\n",
      "Epoch: [12] [ 5022/10059] total steps:[115671] lr:[0.00005000] time: 14.75s (23938s total) loss: 126.496\n",
      "Epoch: [12] [ 5032/10059] total steps:[115681] lr:[0.00005000] time: 14.90s (23953s total) loss: 162.898\n",
      "Epoch: [12] [ 5042/10059] total steps:[115691] lr:[0.00005000] time: 14.77s (23967s total) loss: 117.100\n",
      "Epoch: [12] [ 5052/10059] total steps:[115701] lr:[0.00005000] time: 14.93s (23982s total) loss: 114.608\n",
      "Epoch: [12] [ 5062/10059] total steps:[115711] lr:[0.00005000] time: 14.86s (23997s total) loss: 153.242\n",
      "Epoch: [12] [ 5072/10059] total steps:[115721] lr:[0.00005000] time: 14.82s (24012s total) loss: 147.764\n",
      "Epoch: [12] [ 5082/10059] total steps:[115731] lr:[0.00005000] time: 14.78s (24027s total) loss: 174.591\n",
      "Epoch: [12] [ 5092/10059] total steps:[115741] lr:[0.00005000] time: 14.72s (24041s total) loss: 80.716\n",
      "Epoch: [12] [ 5102/10059] total steps:[115751] lr:[0.00005000] time: 14.77s (24056s total) loss: 164.517\n",
      "Epoch: [12] [ 5112/10059] total steps:[115761] lr:[0.00005000] time: 14.86s (24071s total) loss: 137.671\n",
      "Epoch: [12] [ 5122/10059] total steps:[115771] lr:[0.00005000] time: 14.85s (24086s total) loss: 110.836\n",
      "Epoch: [12] [ 5132/10059] total steps:[115781] lr:[0.00005000] time: 14.73s (24101s total) loss: 148.895\n",
      "Epoch: [12] [ 5142/10059] total steps:[115791] lr:[0.00005000] time: 14.89s (24116s total) loss: 153.525\n",
      "Epoch: [12] [ 5152/10059] total steps:[115801] lr:[0.00005000] time: 14.82s (24130s total) loss: 107.401\n",
      "Epoch: [12] [ 5162/10059] total steps:[115811] lr:[0.00005000] time: 14.73s (24145s total) loss: 173.078\n",
      "Epoch: [12] [ 5172/10059] total steps:[115821] lr:[0.00005000] time: 14.82s (24160s total) loss: 149.653\n",
      "Epoch: [12] [ 5182/10059] total steps:[115831] lr:[0.00005000] time: 14.70s (24175s total) loss: 91.706\n",
      "Epoch: [12] [ 5192/10059] total steps:[115841] lr:[0.00005000] time: 14.68s (24189s total) loss: 108.550\n",
      "Epoch: [12] [ 5202/10059] total steps:[115851] lr:[0.00005000] time: 14.80s (24204s total) loss: 185.562\n",
      "Epoch: [12] [ 5212/10059] total steps:[115861] lr:[0.00005000] time: 14.76s (24219s total) loss: 127.867\n",
      "Epoch: [12] [ 5222/10059] total steps:[115871] lr:[0.00005000] time: 14.84s (24234s total) loss: 142.676\n",
      "Epoch: [12] [ 5232/10059] total steps:[115881] lr:[0.00005000] time: 14.77s (24248s total) loss: 184.669\n",
      "Epoch: [12] [ 5242/10059] total steps:[115891] lr:[0.00005000] time: 14.84s (24263s total) loss: 198.610\n",
      "Epoch: [12] [ 5252/10059] total steps:[115901] lr:[0.00005000] time: 14.86s (24278s total) loss: 164.855\n",
      "Epoch: [12] [ 5262/10059] total steps:[115911] lr:[0.00005000] time: 14.77s (24293s total) loss: 122.590\n",
      "Epoch: [12] [ 5272/10059] total steps:[115921] lr:[0.00005000] time: 14.84s (24308s total) loss: 127.352\n",
      "Epoch: [12] [ 5282/10059] total steps:[115931] lr:[0.00005000] time: 14.76s (24323s total) loss: 102.155\n",
      "Epoch: [12] [ 5292/10059] total steps:[115941] lr:[0.00005000] time: 14.73s (24337s total) loss: 164.124\n",
      "Epoch: [12] [ 5302/10059] total steps:[115951] lr:[0.00005000] time: 14.83s (24352s total) loss: 118.660\n",
      "Epoch: [12] [ 5312/10059] total steps:[115961] lr:[0.00005000] time: 14.96s (24367s total) loss: 117.862\n",
      "Epoch: [12] [ 5322/10059] total steps:[115971] lr:[0.00005000] time: 14.88s (24382s total) loss: 131.554\n",
      "Epoch: [12] [ 5332/10059] total steps:[115981] lr:[0.00005000] time: 14.91s (24397s total) loss: 153.335\n",
      "Epoch: [12] [ 5342/10059] total steps:[115991] lr:[0.00005000] time: 14.77s (24412s total) loss: 116.501\n",
      "Epoch: [12] [ 5352/10059] total steps:[116001] lr:[0.00005000] time: 14.90s (24427s total) loss: 118.151\n",
      "Epoch: [12] [ 5362/10059] total steps:[116011] lr:[0.00005000] time: 14.92s (24441s total) loss: 97.976\n",
      "Epoch: [12] [ 5372/10059] total steps:[116021] lr:[0.00005000] time: 14.74s (24456s total) loss: 161.732\n",
      "Epoch: [12] [ 5382/10059] total steps:[116031] lr:[0.00005000] time: 14.81s (24471s total) loss: 112.088\n",
      "Epoch: [12] [ 5392/10059] total steps:[116041] lr:[0.00005000] time: 14.89s (24486s total) loss: 105.282\n",
      "Epoch: [12] [ 5402/10059] total steps:[116051] lr:[0.00005000] time: 14.82s (24501s total) loss: 129.880\n",
      "Epoch: [12] [ 5412/10059] total steps:[116061] lr:[0.00005000] time: 14.68s (24515s total) loss: 105.105\n",
      "Epoch: [12] [ 5422/10059] total steps:[116071] lr:[0.00005000] time: 14.79s (24530s total) loss: 165.264\n",
      "Epoch: [12] [ 5432/10059] total steps:[116081] lr:[0.00005000] time: 14.73s (24545s total) loss: 100.894\n",
      "Epoch: [12] [ 5442/10059] total steps:[116091] lr:[0.00005000] time: 14.83s (24560s total) loss: 90.693\n",
      "Epoch: [12] [ 5452/10059] total steps:[116101] lr:[0.00005000] time: 14.87s (24575s total) loss: 186.491\n",
      "Epoch: [12] [ 5462/10059] total steps:[116111] lr:[0.00005000] time: 14.77s (24589s total) loss: 157.648\n",
      "Epoch: [12] [ 5472/10059] total steps:[116121] lr:[0.00005000] time: 14.76s (24604s total) loss: 112.461\n",
      "Epoch: [12] [ 5482/10059] total steps:[116131] lr:[0.00005000] time: 14.87s (24619s total) loss: 106.859\n",
      "Epoch: [12] [ 5492/10059] total steps:[116141] lr:[0.00005000] time: 14.80s (24634s total) loss: 143.421\n",
      "Epoch: [12] [ 5502/10059] total steps:[116151] lr:[0.00005000] time: 14.85s (24649s total) loss: 118.714\n",
      "Epoch: [12] [ 5512/10059] total steps:[116161] lr:[0.00005000] time: 14.70s (24663s total) loss: 133.371\n",
      "Epoch: [12] [ 5522/10059] total steps:[116171] lr:[0.00005000] time: 14.70s (24678s total) loss: 159.594\n",
      "Epoch: [12] [ 5532/10059] total steps:[116181] lr:[0.00005000] time: 14.80s (24693s total) loss: 170.916\n",
      "Epoch: [12] [ 5542/10059] total steps:[116191] lr:[0.00005000] time: 14.73s (24708s total) loss: 125.631\n",
      "Epoch: [12] [ 5552/10059] total steps:[116201] lr:[0.00005000] time: 14.92s (24723s total) loss: 156.278\n",
      "Epoch: [12] [ 5562/10059] total steps:[116211] lr:[0.00005000] time: 14.82s (24737s total) loss: 85.951\n",
      "Epoch: [12] [ 5572/10059] total steps:[116221] lr:[0.00005000] time: 14.75s (24752s total) loss: 123.273\n",
      "Epoch: [12] [ 5582/10059] total steps:[116231] lr:[0.00005000] time: 16.12s (24768s total) loss: 99.322\n",
      "Epoch: [12] [ 5592/10059] total steps:[116241] lr:[0.00005000] time: 14.78s (24783s total) loss: 167.413\n",
      "Epoch: [12] [ 5602/10059] total steps:[116251] lr:[0.00005000] time: 14.77s (24798s total) loss: 156.049\n",
      "Epoch: [12] [ 5612/10059] total steps:[116261] lr:[0.00005000] time: 14.84s (24813s total) loss: 159.821\n",
      "Epoch: [12] [ 5622/10059] total steps:[116271] lr:[0.00005000] time: 14.79s (24827s total) loss: 142.068\n",
      "Epoch: [12] [ 5632/10059] total steps:[116281] lr:[0.00005000] time: 14.86s (24842s total) loss: 111.551\n",
      "Epoch: [12] [ 5642/10059] total steps:[116291] lr:[0.00005000] time: 14.85s (24857s total) loss: 147.661\n",
      "Epoch: [12] [ 5652/10059] total steps:[116301] lr:[0.00005000] time: 14.69s (24872s total) loss: 123.477\n",
      "Epoch: [12] [ 5662/10059] total steps:[116311] lr:[0.00005000] time: 14.75s (24887s total) loss: 112.754\n",
      "Epoch: [12] [ 5672/10059] total steps:[116321] lr:[0.00005000] time: 14.79s (24901s total) loss: 152.354\n",
      "Epoch: [12] [ 5682/10059] total steps:[116331] lr:[0.00005000] time: 14.81s (24916s total) loss: 111.364\n",
      "Epoch: [12] [ 5692/10059] total steps:[116341] lr:[0.00005000] time: 14.83s (24931s total) loss: 158.773\n",
      "Epoch: [12] [ 5702/10059] total steps:[116351] lr:[0.00005000] time: 14.84s (24946s total) loss: 139.983\n",
      "Epoch: [12] [ 5712/10059] total steps:[116361] lr:[0.00005000] time: 14.92s (24961s total) loss: 106.821\n",
      "Epoch: [12] [ 5722/10059] total steps:[116371] lr:[0.00005000] time: 14.81s (24976s total) loss: 133.215\n",
      "Epoch: [12] [ 5732/10059] total steps:[116381] lr:[0.00005000] time: 14.74s (24990s total) loss: 140.858\n",
      "Epoch: [12] [ 5742/10059] total steps:[116391] lr:[0.00005000] time: 14.77s (25005s total) loss: 174.739\n",
      "Epoch: [12] [ 5752/10059] total steps:[116401] lr:[0.00005000] time: 15.12s (25020s total) loss: 138.956\n",
      "Epoch: [12] [ 5762/10059] total steps:[116411] lr:[0.00005000] time: 14.74s (25035s total) loss: 98.215\n",
      "Epoch: [12] [ 5772/10059] total steps:[116421] lr:[0.00005000] time: 14.70s (25050s total) loss: 145.070\n",
      "Epoch: [12] [ 5782/10059] total steps:[116431] lr:[0.00005000] time: 14.90s (25065s total) loss: 98.965\n",
      "Epoch: [12] [ 5792/10059] total steps:[116441] lr:[0.00005000] time: 14.84s (25079s total) loss: 128.236\n",
      "Epoch: [12] [ 5802/10059] total steps:[116451] lr:[0.00005000] time: 14.80s (25094s total) loss: 123.761\n",
      "Epoch: [12] [ 5812/10059] total steps:[116461] lr:[0.00005000] time: 14.75s (25109s total) loss: 123.939\n",
      "Epoch: [12] [ 5822/10059] total steps:[116471] lr:[0.00005000] time: 14.75s (25124s total) loss: 131.612\n",
      "Epoch: [12] [ 5832/10059] total steps:[116481] lr:[0.00005000] time: 14.72s (25138s total) loss: 121.684\n",
      "Epoch: [12] [ 5842/10059] total steps:[116491] lr:[0.00005000] time: 14.80s (25153s total) loss: 125.959\n",
      "Epoch: [12] [ 5852/10059] total steps:[116501] lr:[0.00005000] time: 14.83s (25168s total) loss: 128.344\n",
      "Epoch: [12] [ 5862/10059] total steps:[116511] lr:[0.00005000] time: 14.78s (25183s total) loss: 132.325\n",
      "Epoch: [12] [ 5872/10059] total steps:[116521] lr:[0.00005000] time: 14.81s (25198s total) loss: 151.171\n",
      "Epoch: [12] [ 5882/10059] total steps:[116531] lr:[0.00005000] time: 14.80s (25212s total) loss: 141.491\n",
      "Epoch: [12] [ 5892/10059] total steps:[116541] lr:[0.00005000] time: 14.71s (25227s total) loss: 119.536\n",
      "Epoch: [12] [ 5902/10059] total steps:[116551] lr:[0.00005000] time: 14.73s (25242s total) loss: 135.648\n",
      "Epoch: [12] [ 5912/10059] total steps:[116561] lr:[0.00005000] time: 14.84s (25257s total) loss: 140.910\n",
      "Epoch: [12] [ 5922/10059] total steps:[116571] lr:[0.00005000] time: 14.74s (25271s total) loss: 164.208\n",
      "Epoch: [12] [ 5932/10059] total steps:[116581] lr:[0.00005000] time: 14.71s (25286s total) loss: 152.923\n",
      "Epoch: [12] [ 5942/10059] total steps:[116591] lr:[0.00005000] time: 14.80s (25301s total) loss: 156.661\n",
      "Epoch: [12] [ 5952/10059] total steps:[116601] lr:[0.00005000] time: 14.93s (25316s total) loss: 122.983\n",
      "Epoch: [12] [ 5962/10059] total steps:[116611] lr:[0.00005000] time: 14.78s (25331s total) loss: 146.556\n",
      "Epoch: [12] [ 5972/10059] total steps:[116621] lr:[0.00005000] time: 14.78s (25345s total) loss: 138.748\n",
      "Epoch: [12] [ 5982/10059] total steps:[116631] lr:[0.00005000] time: 14.85s (25360s total) loss: 163.846\n",
      "Epoch: [12] [ 5992/10059] total steps:[116641] lr:[0.00005000] time: 14.86s (25375s total) loss: 115.162\n",
      "Epoch: [12] [ 6002/10059] total steps:[116651] lr:[0.00005000] time: 14.79s (25390s total) loss: 131.302\n",
      "Epoch: [12] [ 6012/10059] total steps:[116661] lr:[0.00005000] time: 14.80s (25405s total) loss: 126.072\n",
      "Epoch: [12] [ 6022/10059] total steps:[116671] lr:[0.00005000] time: 14.84s (25420s total) loss: 119.838\n",
      "Epoch: [12] [ 6032/10059] total steps:[116681] lr:[0.00005000] time: 14.73s (25434s total) loss: 121.410\n",
      "Epoch: [12] [ 6042/10059] total steps:[116691] lr:[0.00005000] time: 14.87s (25449s total) loss: 105.076\n",
      "Epoch: [12] [ 6052/10059] total steps:[116701] lr:[0.00005000] time: 14.87s (25464s total) loss: 184.932\n",
      "Epoch: [12] [ 6062/10059] total steps:[116711] lr:[0.00005000] time: 14.82s (25479s total) loss: 159.849\n",
      "Epoch: [12] [ 6072/10059] total steps:[116721] lr:[0.00005000] time: 14.90s (25494s total) loss: 140.152\n",
      "Epoch: [12] [ 6082/10059] total steps:[116731] lr:[0.00005000] time: 14.83s (25509s total) loss: 146.845\n",
      "Epoch: [12] [ 6092/10059] total steps:[116741] lr:[0.00005000] time: 14.85s (25523s total) loss: 126.517\n",
      "Epoch: [12] [ 6102/10059] total steps:[116751] lr:[0.00005000] time: 14.75s (25538s total) loss: 134.204\n",
      "Epoch: [12] [ 6112/10059] total steps:[116761] lr:[0.00005000] time: 14.84s (25553s total) loss: 166.590\n",
      "Epoch: [12] [ 6122/10059] total steps:[116771] lr:[0.00005000] time: 14.72s (25568s total) loss: 136.714\n",
      "Epoch: [12] [ 6132/10059] total steps:[116781] lr:[0.00005000] time: 14.89s (25583s total) loss: 108.860\n",
      "Epoch: [12] [ 6142/10059] total steps:[116791] lr:[0.00005000] time: 14.73s (25597s total) loss: 122.442\n",
      "Epoch: [12] [ 6152/10059] total steps:[116801] lr:[0.00005000] time: 14.96s (25612s total) loss: 138.195\n",
      "Epoch: [12] [ 6162/10059] total steps:[116811] lr:[0.00005000] time: 14.75s (25627s total) loss: 105.125\n",
      "Epoch: [12] [ 6172/10059] total steps:[116821] lr:[0.00005000] time: 14.77s (25642s total) loss: 140.873\n",
      "Epoch: [12] [ 6182/10059] total steps:[116831] lr:[0.00005000] time: 14.80s (25657s total) loss: 120.391\n",
      "Epoch: [12] [ 6192/10059] total steps:[116841] lr:[0.00005000] time: 14.78s (25671s total) loss: 69.858\n",
      "Epoch: [12] [ 6202/10059] total steps:[116851] lr:[0.00005000] time: 14.87s (25686s total) loss: 117.765\n",
      "Epoch: [12] [ 6212/10059] total steps:[116861] lr:[0.00005000] time: 14.78s (25701s total) loss: 131.543\n",
      "Epoch: [12] [ 6222/10059] total steps:[116871] lr:[0.00005000] time: 14.82s (25716s total) loss: 146.311\n",
      "Epoch: [12] [ 6232/10059] total steps:[116881] lr:[0.00005000] time: 14.89s (25731s total) loss: 156.964\n",
      "Epoch: [12] [ 6242/10059] total steps:[116891] lr:[0.00005000] time: 14.77s (25746s total) loss: 156.066\n",
      "Epoch: [12] [ 6252/10059] total steps:[116901] lr:[0.00005000] time: 14.76s (25760s total) loss: 112.015\n",
      "Epoch: [12] [ 6262/10059] total steps:[116911] lr:[0.00005000] time: 14.85s (25775s total) loss: 116.996\n",
      "Epoch: [12] [ 6272/10059] total steps:[116921] lr:[0.00005000] time: 14.83s (25790s total) loss: 110.770\n",
      "Epoch: [12] [ 6282/10059] total steps:[116931] lr:[0.00005000] time: 14.78s (25805s total) loss: 170.314\n",
      "Epoch: [12] [ 6292/10059] total steps:[116941] lr:[0.00005000] time: 14.81s (25820s total) loss: 153.468\n",
      "Epoch: [12] [ 6302/10059] total steps:[116951] lr:[0.00005000] time: 14.74s (25834s total) loss: 92.855\n",
      "Epoch: [12] [ 6312/10059] total steps:[116961] lr:[0.00005000] time: 14.99s (25849s total) loss: 138.990\n",
      "Epoch: [12] [ 6322/10059] total steps:[116971] lr:[0.00005000] time: 14.75s (25864s total) loss: 95.378\n",
      "Epoch: [12] [ 6332/10059] total steps:[116981] lr:[0.00005000] time: 14.75s (25879s total) loss: 105.503\n",
      "Epoch: [12] [ 6342/10059] total steps:[116991] lr:[0.00005000] time: 14.73s (25894s total) loss: 180.036\n",
      "Epoch: [12] [ 6352/10059] total steps:[117001] lr:[0.00005000] time: 14.94s (25909s total) loss: 113.631\n",
      "Epoch: [12] [ 6362/10059] total steps:[117011] lr:[0.00005000] time: 14.72s (25923s total) loss: 94.786\n",
      "Epoch: [12] [ 6372/10059] total steps:[117021] lr:[0.00005000] time: 14.71s (25938s total) loss: 83.358\n",
      "Epoch: [12] [ 6382/10059] total steps:[117031] lr:[0.00005000] time: 14.76s (25953s total) loss: 166.687\n",
      "Epoch: [12] [ 6392/10059] total steps:[117041] lr:[0.00005000] time: 14.73s (25967s total) loss: 148.181\n",
      "Epoch: [12] [ 6402/10059] total steps:[117051] lr:[0.00005000] time: 14.89s (25982s total) loss: 127.394\n",
      "Epoch: [12] [ 6412/10059] total steps:[117061] lr:[0.00005000] time: 14.81s (25997s total) loss: 130.705\n",
      "Epoch: [12] [ 6422/10059] total steps:[117071] lr:[0.00005000] time: 14.81s (26012s total) loss: 135.114\n",
      "Epoch: [12] [ 6432/10059] total steps:[117081] lr:[0.00005000] time: 14.81s (26027s total) loss: 107.922\n",
      "Epoch: [12] [ 6442/10059] total steps:[117091] lr:[0.00005000] time: 14.77s (26042s total) loss: 139.397\n",
      "Epoch: [12] [ 6452/10059] total steps:[117101] lr:[0.00005000] time: 14.85s (26056s total) loss: 180.403\n",
      "Epoch: [12] [ 6462/10059] total steps:[117111] lr:[0.00005000] time: 14.79s (26071s total) loss: 110.789\n",
      "Epoch: [12] [ 6472/10059] total steps:[117121] lr:[0.00005000] time: 14.76s (26086s total) loss: 182.811\n",
      "Epoch: [12] [ 6482/10059] total steps:[117131] lr:[0.00005000] time: 14.74s (26101s total) loss: 142.803\n",
      "Epoch: [12] [ 6492/10059] total steps:[117141] lr:[0.00005000] time: 14.79s (26116s total) loss: 158.127\n",
      "Epoch: [12] [ 6502/10059] total steps:[117151] lr:[0.00005000] time: 14.84s (26130s total) loss: 104.947\n",
      "Epoch: [12] [ 6512/10059] total steps:[117161] lr:[0.00005000] time: 14.99s (26145s total) loss: 144.610\n",
      "Epoch: [12] [ 6522/10059] total steps:[117171] lr:[0.00005000] time: 14.84s (26160s total) loss: 148.298\n",
      "Epoch: [12] [ 6532/10059] total steps:[117181] lr:[0.00005000] time: 14.75s (26175s total) loss: 100.190\n",
      "Epoch: [12] [ 6542/10059] total steps:[117191] lr:[0.00005000] time: 14.86s (26190s total) loss: 172.852\n",
      "Epoch: [12] [ 6552/10059] total steps:[117201] lr:[0.00005000] time: 14.93s (26205s total) loss: 199.249\n",
      "Epoch: [12] [ 6562/10059] total steps:[117211] lr:[0.00005000] time: 14.83s (26220s total) loss: 112.125\n",
      "Epoch: [12] [ 6572/10059] total steps:[117221] lr:[0.00005000] time: 14.78s (26234s total) loss: 159.600\n",
      "Epoch: [12] [ 6582/10059] total steps:[117231] lr:[0.00005000] time: 14.76s (26249s total) loss: 88.492\n",
      "Epoch: [12] [ 6592/10059] total steps:[117241] lr:[0.00005000] time: 14.77s (26264s total) loss: 159.974\n",
      "Epoch: [12] [ 6602/10059] total steps:[117251] lr:[0.00005000] time: 14.69s (26279s total) loss: 110.522\n",
      "Epoch: [12] [ 6612/10059] total steps:[117261] lr:[0.00005000] time: 14.73s (26293s total) loss: 125.149\n",
      "Epoch: [12] [ 6622/10059] total steps:[117271] lr:[0.00005000] time: 14.84s (26308s total) loss: 115.657\n",
      "Epoch: [12] [ 6632/10059] total steps:[117281] lr:[0.00005000] time: 14.74s (26323s total) loss: 126.248\n",
      "Epoch: [12] [ 6642/10059] total steps:[117291] lr:[0.00005000] time: 14.77s (26338s total) loss: 101.775\n",
      "Epoch: [12] [ 6652/10059] total steps:[117301] lr:[0.00005000] time: 14.85s (26353s total) loss: 136.626\n",
      "Epoch: [12] [ 6662/10059] total steps:[117311] lr:[0.00005000] time: 14.82s (26367s total) loss: 156.090\n",
      "Epoch: [12] [ 6672/10059] total steps:[117321] lr:[0.00005000] time: 14.89s (26382s total) loss: 155.307\n",
      "Epoch: [12] [ 6682/10059] total steps:[117331] lr:[0.00005000] time: 14.87s (26397s total) loss: 174.058\n",
      "Epoch: [12] [ 6692/10059] total steps:[117341] lr:[0.00005000] time: 14.80s (26412s total) loss: 107.421\n",
      "Epoch: [12] [ 6702/10059] total steps:[117351] lr:[0.00005000] time: 14.96s (26427s total) loss: 113.162\n",
      "Epoch: [12] [ 6712/10059] total steps:[117361] lr:[0.00005000] time: 14.81s (26442s total) loss: 110.942\n",
      "Epoch: [12] [ 6722/10059] total steps:[117371] lr:[0.00005000] time: 14.77s (26456s total) loss: 152.098\n",
      "Epoch: [12] [ 6732/10059] total steps:[117381] lr:[0.00005000] time: 14.75s (26471s total) loss: 123.450\n",
      "Epoch: [12] [ 6742/10059] total steps:[117391] lr:[0.00005000] time: 14.85s (26486s total) loss: 194.682\n",
      "Epoch: [12] [ 6752/10059] total steps:[117401] lr:[0.00005000] time: 14.81s (26501s total) loss: 138.423\n",
      "Epoch: [12] [ 6762/10059] total steps:[117411] lr:[0.00005000] time: 14.87s (26516s total) loss: 143.031\n",
      "Epoch: [12] [ 6772/10059] total steps:[117421] lr:[0.00005000] time: 14.86s (26531s total) loss: 132.231\n",
      "Epoch: [12] [ 6782/10059] total steps:[117431] lr:[0.00005000] time: 14.67s (26545s total) loss: 107.523\n",
      "Epoch: [12] [ 6792/10059] total steps:[117441] lr:[0.00005000] time: 14.75s (26560s total) loss: 152.593\n",
      "Epoch: [12] [ 6802/10059] total steps:[117451] lr:[0.00005000] time: 14.85s (26575s total) loss: 156.035\n",
      "Epoch: [12] [ 6812/10059] total steps:[117461] lr:[0.00005000] time: 14.70s (26590s total) loss: 97.377\n",
      "Epoch: [12] [ 6822/10059] total steps:[117471] lr:[0.00005000] time: 14.78s (26604s total) loss: 109.830\n",
      "Epoch: [12] [ 6832/10059] total steps:[117481] lr:[0.00005000] time: 14.80s (26619s total) loss: 183.082\n",
      "Epoch: [12] [ 6842/10059] total steps:[117491] lr:[0.00005000] time: 14.72s (26634s total) loss: 109.601\n",
      "Epoch: [12] [ 6852/10059] total steps:[117501] lr:[0.00005000] time: 14.82s (26649s total) loss: 102.611\n",
      "Epoch: [12] [ 6862/10059] total steps:[117511] lr:[0.00005000] time: 14.92s (26664s total) loss: 157.086\n",
      "Epoch: [12] [ 6872/10059] total steps:[117521] lr:[0.00005000] time: 14.75s (26678s total) loss: 100.200\n",
      "Epoch: [12] [ 6882/10059] total steps:[117531] lr:[0.00005000] time: 14.70s (26693s total) loss: 146.017\n",
      "Epoch: [12] [ 6892/10059] total steps:[117541] lr:[0.00005000] time: 14.84s (26708s total) loss: 128.140\n",
      "Epoch: [12] [ 6902/10059] total steps:[117551] lr:[0.00005000] time: 14.87s (26723s total) loss: 188.009\n",
      "Epoch: [12] [ 6912/10059] total steps:[117561] lr:[0.00005000] time: 14.83s (26738s total) loss: 146.534\n",
      "Epoch: [12] [ 6922/10059] total steps:[117571] lr:[0.00005000] time: 14.96s (26753s total) loss: 127.795\n",
      "Epoch: [12] [ 6932/10059] total steps:[117581] lr:[0.00005000] time: 14.78s (26767s total) loss: 176.715\n",
      "Epoch: [12] [ 6942/10059] total steps:[117591] lr:[0.00005000] time: 14.82s (26782s total) loss: 146.305\n",
      "Epoch: [12] [ 6952/10059] total steps:[117601] lr:[0.00005000] time: 14.68s (26797s total) loss: 126.906\n",
      "Epoch: [12] [ 6962/10059] total steps:[117611] lr:[0.00005000] time: 14.79s (26812s total) loss: 118.321\n",
      "Epoch: [12] [ 6972/10059] total steps:[117621] lr:[0.00005000] time: 14.91s (26827s total) loss: 144.511\n",
      "Epoch: [12] [ 6982/10059] total steps:[117631] lr:[0.00005000] time: 14.77s (26841s total) loss: 155.524\n",
      "Epoch: [12] [ 6992/10059] total steps:[117641] lr:[0.00005000] time: 14.82s (26856s total) loss: 150.534\n",
      "Epoch: [12] [ 7002/10059] total steps:[117651] lr:[0.00005000] time: 14.79s (26871s total) loss: 142.845\n",
      "Epoch: [12] [ 7012/10059] total steps:[117661] lr:[0.00005000] time: 14.87s (26886s total) loss: 133.285\n",
      "Epoch: [12] [ 7022/10059] total steps:[117671] lr:[0.00005000] time: 14.81s (26901s total) loss: 153.692\n",
      "Epoch: [12] [ 7032/10059] total steps:[117681] lr:[0.00005000] time: 14.65s (26915s total) loss: 111.659\n",
      "Epoch: [12] [ 7042/10059] total steps:[117691] lr:[0.00005000] time: 14.79s (26930s total) loss: 148.490\n",
      "Epoch: [12] [ 7052/10059] total steps:[117701] lr:[0.00005000] time: 14.76s (26945s total) loss: 166.369\n",
      "Epoch: [12] [ 7062/10059] total steps:[117711] lr:[0.00005000] time: 14.82s (26960s total) loss: 129.795\n",
      "Epoch: [12] [ 7072/10059] total steps:[117721] lr:[0.00005000] time: 14.82s (26974s total) loss: 116.242\n",
      "Epoch: [12] [ 7082/10059] total steps:[117731] lr:[0.00005000] time: 14.79s (26989s total) loss: 155.799\n",
      "Epoch: [12] [ 7092/10059] total steps:[117741] lr:[0.00005000] time: 14.82s (27004s total) loss: 155.210\n",
      "Epoch: [12] [ 7102/10059] total steps:[117751] lr:[0.00005000] time: 14.69s (27019s total) loss: 116.988\n",
      "Epoch: [12] [ 7112/10059] total steps:[117761] lr:[0.00005000] time: 14.75s (27033s total) loss: 112.686\n",
      "Epoch: [12] [ 7122/10059] total steps:[117771] lr:[0.00005000] time: 14.82s (27048s total) loss: 131.923\n",
      "Epoch: [12] [ 7132/10059] total steps:[117781] lr:[0.00005000] time: 14.83s (27063s total) loss: 134.516\n",
      "Epoch: [12] [ 7142/10059] total steps:[117791] lr:[0.00005000] time: 14.79s (27078s total) loss: 153.251\n",
      "Epoch: [12] [ 7152/10059] total steps:[117801] lr:[0.00005000] time: 14.88s (27093s total) loss: 111.431\n",
      "Epoch: [12] [ 7162/10059] total steps:[117811] lr:[0.00005000] time: 14.78s (27108s total) loss: 137.604\n",
      "Epoch: [12] [ 7172/10059] total steps:[117821] lr:[0.00005000] time: 14.88s (27122s total) loss: 127.202\n",
      "Epoch: [12] [ 7182/10059] total steps:[117831] lr:[0.00005000] time: 14.79s (27137s total) loss: 132.197\n",
      "Epoch: [12] [ 7192/10059] total steps:[117841] lr:[0.00005000] time: 14.74s (27152s total) loss: 113.632\n",
      "Epoch: [12] [ 7202/10059] total steps:[117851] lr:[0.00005000] time: 14.80s (27167s total) loss: 134.125\n",
      "Epoch: [12] [ 7212/10059] total steps:[117861] lr:[0.00005000] time: 14.68s (27181s total) loss: 153.287\n",
      "Epoch: [12] [ 7222/10059] total steps:[117871] lr:[0.00005000] time: 14.80s (27196s total) loss: 181.329\n",
      "Epoch: [12] [ 7232/10059] total steps:[117881] lr:[0.00005000] time: 14.74s (27211s total) loss: 113.897\n",
      "Epoch: [12] [ 7242/10059] total steps:[117891] lr:[0.00005000] time: 15.05s (27226s total) loss: 120.766\n",
      "Epoch: [12] [ 7252/10059] total steps:[117901] lr:[0.00005000] time: 14.83s (27241s total) loss: 133.494\n",
      "Epoch: [12] [ 7262/10059] total steps:[117911] lr:[0.00005000] time: 14.74s (27256s total) loss: 114.072\n",
      "Epoch: [12] [ 7272/10059] total steps:[117921] lr:[0.00005000] time: 14.77s (27270s total) loss: 146.863\n",
      "Epoch: [12] [ 7282/10059] total steps:[117931] lr:[0.00005000] time: 14.98s (27285s total) loss: 112.647\n",
      "Epoch: [12] [ 7292/10059] total steps:[117941] lr:[0.00005000] time: 14.82s (27300s total) loss: 126.335\n",
      "Epoch: [12] [ 7302/10059] total steps:[117951] lr:[0.00005000] time: 14.79s (27315s total) loss: 168.262\n",
      "Epoch: [12] [ 7312/10059] total steps:[117961] lr:[0.00005000] time: 14.82s (27330s total) loss: 150.505\n",
      "Epoch: [12] [ 7322/10059] total steps:[117971] lr:[0.00005000] time: 14.71s (27345s total) loss: 156.129\n",
      "Epoch: [12] [ 7332/10059] total steps:[117981] lr:[0.00005000] time: 14.81s (27359s total) loss: 116.332\n",
      "Epoch: [12] [ 7342/10059] total steps:[117991] lr:[0.00005000] time: 14.88s (27374s total) loss: 116.067\n",
      "Epoch: [12] [ 7352/10059] total steps:[118001] lr:[0.00005000] time: 14.88s (27389s total) loss: 114.639\n",
      "Epoch: [12] [ 7362/10059] total steps:[118011] lr:[0.00005000] time: 14.81s (27404s total) loss: 153.210\n",
      "Epoch: [12] [ 7372/10059] total steps:[118021] lr:[0.00005000] time: 14.79s (27419s total) loss: 129.342\n",
      "Epoch: [12] [ 7382/10059] total steps:[118031] lr:[0.00005000] time: 14.81s (27433s total) loss: 178.494\n",
      "Epoch: [12] [ 7392/10059] total steps:[118041] lr:[0.00005000] time: 14.68s (27448s total) loss: 149.693\n",
      "Epoch: [12] [ 7402/10059] total steps:[118051] lr:[0.00005000] time: 14.77s (27463s total) loss: 156.219\n",
      "Epoch: [12] [ 7412/10059] total steps:[118061] lr:[0.00005000] time: 14.75s (27478s total) loss: 131.444\n",
      "Epoch: [12] [ 7422/10059] total steps:[118071] lr:[0.00005000] time: 14.72s (27492s total) loss: 112.601\n",
      "Epoch: [12] [ 7432/10059] total steps:[118081] lr:[0.00005000] time: 14.84s (27507s total) loss: 171.912\n",
      "Epoch: [12] [ 7442/10059] total steps:[118091] lr:[0.00005000] time: 14.78s (27522s total) loss: 134.194\n",
      "Epoch: [12] [ 7452/10059] total steps:[118101] lr:[0.00005000] time: 14.87s (27537s total) loss: 140.552\n",
      "Epoch: [12] [ 7462/10059] total steps:[118111] lr:[0.00005000] time: 14.82s (27552s total) loss: 134.527\n",
      "Epoch: [12] [ 7472/10059] total steps:[118121] lr:[0.00005000] time: 14.87s (27567s total) loss: 132.002\n",
      "Epoch: [12] [ 7482/10059] total steps:[118131] lr:[0.00005000] time: 14.84s (27581s total) loss: 131.157\n",
      "Epoch: [12] [ 7492/10059] total steps:[118141] lr:[0.00005000] time: 14.81s (27596s total) loss: 124.800\n",
      "Epoch: [12] [ 7502/10059] total steps:[118151] lr:[0.00005000] time: 14.78s (27611s total) loss: 145.530\n",
      "Epoch: [12] [ 7512/10059] total steps:[118161] lr:[0.00005000] time: 14.77s (27626s total) loss: 149.128\n",
      "Epoch: [12] [ 7522/10059] total steps:[118171] lr:[0.00005000] time: 14.71s (27641s total) loss: 150.507\n",
      "Epoch: [12] [ 7532/10059] total steps:[118181] lr:[0.00005000] time: 14.83s (27655s total) loss: 113.895\n",
      "Epoch: [12] [ 7542/10059] total steps:[118191] lr:[0.00005000] time: 14.99s (27670s total) loss: 159.309\n",
      "Epoch: [12] [ 7552/10059] total steps:[118201] lr:[0.00005000] time: 14.88s (27685s total) loss: 136.923\n",
      "Epoch: [12] [ 7562/10059] total steps:[118211] lr:[0.00005000] time: 14.78s (27700s total) loss: 112.379\n",
      "Epoch: [12] [ 7572/10059] total steps:[118221] lr:[0.00005000] time: 14.89s (27715s total) loss: 161.986\n",
      "Epoch: [12] [ 7582/10059] total steps:[118231] lr:[0.00005000] time: 14.69s (27730s total) loss: 115.093\n",
      "Epoch: [12] [ 7592/10059] total steps:[118241] lr:[0.00005000] time: 14.74s (27744s total) loss: 99.062\n",
      "Epoch: [12] [ 7602/10059] total steps:[118251] lr:[0.00005000] time: 14.74s (27759s total) loss: 132.451\n",
      "Epoch: [12] [ 7612/10059] total steps:[118261] lr:[0.00005000] time: 14.88s (27774s total) loss: 110.244\n",
      "Epoch: [12] [ 7622/10059] total steps:[118271] lr:[0.00005000] time: 14.79s (27789s total) loss: 127.726\n",
      "Epoch: [12] [ 7632/10059] total steps:[118281] lr:[0.00005000] time: 14.69s (27803s total) loss: 95.776\n",
      "Epoch: [12] [ 7642/10059] total steps:[118291] lr:[0.00005000] time: 14.84s (27818s total) loss: 155.299\n",
      "Epoch: [12] [ 7652/10059] total steps:[118301] lr:[0.00005000] time: 14.84s (27833s total) loss: 128.115\n",
      "Epoch: [12] [ 7662/10059] total steps:[118311] lr:[0.00005000] time: 14.80s (27848s total) loss: 178.867\n",
      "Epoch: [12] [ 7672/10059] total steps:[118321] lr:[0.00005000] time: 14.84s (27863s total) loss: 151.644\n",
      "Epoch: [12] [ 7682/10059] total steps:[118331] lr:[0.00005000] time: 14.91s (27878s total) loss: 147.193\n",
      "Epoch: [12] [ 7692/10059] total steps:[118341] lr:[0.00005000] time: 14.75s (27892s total) loss: 131.546\n",
      "Epoch: [12] [ 7702/10059] total steps:[118351] lr:[0.00005000] time: 14.74s (27907s total) loss: 141.083\n",
      "Epoch: [12] [ 7712/10059] total steps:[118361] lr:[0.00005000] time: 14.79s (27922s total) loss: 120.062\n",
      "Epoch: [12] [ 7722/10059] total steps:[118371] lr:[0.00005000] time: 14.78s (27937s total) loss: 125.209\n",
      "Epoch: [12] [ 7732/10059] total steps:[118381] lr:[0.00005000] time: 14.88s (27952s total) loss: 164.275\n",
      "Epoch: [12] [ 7742/10059] total steps:[118391] lr:[0.00005000] time: 14.78s (27966s total) loss: 87.361\n",
      "Epoch: [12] [ 7752/10059] total steps:[118401] lr:[0.00005000] time: 14.80s (27981s total) loss: 182.650\n",
      "Epoch: [12] [ 7762/10059] total steps:[118411] lr:[0.00005000] time: 14.74s (27996s total) loss: 178.740\n",
      "Epoch: [12] [ 7772/10059] total steps:[118421] lr:[0.00005000] time: 14.82s (28011s total) loss: 116.210\n",
      "Epoch: [12] [ 7782/10059] total steps:[118431] lr:[0.00005000] time: 14.91s (28026s total) loss: 115.855\n",
      "Epoch: [12] [ 7792/10059] total steps:[118441] lr:[0.00005000] time: 14.77s (28040s total) loss: 185.459\n",
      "Epoch: [12] [ 7802/10059] total steps:[118451] lr:[0.00005000] time: 14.76s (28055s total) loss: 168.561\n",
      "Epoch: [12] [ 7812/10059] total steps:[118461] lr:[0.00005000] time: 14.74s (28070s total) loss: 127.435\n",
      "Epoch: [12] [ 7822/10059] total steps:[118471] lr:[0.00005000] time: 14.74s (28085s total) loss: 171.241\n",
      "Epoch: [12] [ 7832/10059] total steps:[118481] lr:[0.00005000] time: 14.75s (28099s total) loss: 147.202\n",
      "Epoch: [12] [ 7842/10059] total steps:[118491] lr:[0.00005000] time: 14.92s (28114s total) loss: 150.898\n",
      "Epoch: [12] [ 7852/10059] total steps:[118501] lr:[0.00005000] time: 14.85s (28129s total) loss: 108.186\n",
      "Epoch: [12] [ 7862/10059] total steps:[118511] lr:[0.00005000] time: 14.71s (28144s total) loss: 121.619\n",
      "Epoch: [12] [ 7872/10059] total steps:[118521] lr:[0.00005000] time: 14.86s (28159s total) loss: 142.025\n",
      "Epoch: [12] [ 7882/10059] total steps:[118531] lr:[0.00005000] time: 14.70s (28173s total) loss: 176.876\n",
      "Epoch: [12] [ 7892/10059] total steps:[118541] lr:[0.00005000] time: 14.64s (28188s total) loss: 153.294\n",
      "Epoch: [12] [ 7902/10059] total steps:[118551] lr:[0.00005000] time: 14.76s (28203s total) loss: 131.153\n",
      "Epoch: [12] [ 7912/10059] total steps:[118561] lr:[0.00005000] time: 14.76s (28218s total) loss: 134.923\n",
      "Epoch: [12] [ 7922/10059] total steps:[118571] lr:[0.00005000] time: 14.83s (28232s total) loss: 139.192\n",
      "Epoch: [12] [ 7932/10059] total steps:[118581] lr:[0.00005000] time: 14.72s (28247s total) loss: 159.225\n",
      "Epoch: [12] [ 7942/10059] total steps:[118591] lr:[0.00005000] time: 14.82s (28262s total) loss: 140.236\n",
      "Epoch: [12] [ 7952/10059] total steps:[118601] lr:[0.00005000] time: 14.96s (28277s total) loss: 99.454\n",
      "Epoch: [12] [ 7962/10059] total steps:[118611] lr:[0.00005000] time: 14.80s (28292s total) loss: 115.493\n",
      "Epoch: [12] [ 7972/10059] total steps:[118621] lr:[0.00005000] time: 14.74s (28306s total) loss: 129.146\n",
      "Epoch: [12] [ 7982/10059] total steps:[118631] lr:[0.00005000] time: 14.80s (28321s total) loss: 212.163\n",
      "Epoch: [12] [ 7992/10059] total steps:[118641] lr:[0.00005000] time: 14.91s (28336s total) loss: 115.274\n",
      "Epoch: [12] [ 8002/10059] total steps:[118651] lr:[0.00005000] time: 14.86s (28351s total) loss: 164.331\n",
      "Epoch: [12] [ 8012/10059] total steps:[118661] lr:[0.00005000] time: 14.77s (28366s total) loss: 186.947\n",
      "Epoch: [12] [ 8022/10059] total steps:[118671] lr:[0.00005000] time: 14.92s (28381s total) loss: 122.685\n",
      "Epoch: [12] [ 8032/10059] total steps:[118681] lr:[0.00005000] time: 14.84s (28396s total) loss: 77.809\n",
      "Epoch: [12] [ 8042/10059] total steps:[118691] lr:[0.00005000] time: 14.91s (28410s total) loss: 130.632\n",
      "Epoch: [12] [ 8052/10059] total steps:[118701] lr:[0.00005000] time: 14.76s (28425s total) loss: 141.146\n",
      "Epoch: [12] [ 8062/10059] total steps:[118711] lr:[0.00005000] time: 14.82s (28440s total) loss: 130.089\n",
      "Epoch: [12] [ 8072/10059] total steps:[118721] lr:[0.00005000] time: 14.76s (28455s total) loss: 159.736\n",
      "Epoch: [12] [ 8082/10059] total steps:[118731] lr:[0.00005000] time: 14.73s (28470s total) loss: 134.725\n",
      "Epoch: [12] [ 8092/10059] total steps:[118741] lr:[0.00005000] time: 14.85s (28484s total) loss: 93.419\n",
      "Epoch: [12] [ 8102/10059] total steps:[118751] lr:[0.00005000] time: 14.79s (28499s total) loss: 106.734\n",
      "Epoch: [12] [ 8112/10059] total steps:[118761] lr:[0.00005000] time: 14.83s (28514s total) loss: 149.733\n",
      "Epoch: [12] [ 8122/10059] total steps:[118771] lr:[0.00005000] time: 14.86s (28529s total) loss: 122.400\n",
      "Epoch: [12] [ 8132/10059] total steps:[118781] lr:[0.00005000] time: 14.83s (28544s total) loss: 205.668\n",
      "Epoch: [12] [ 8142/10059] total steps:[118791] lr:[0.00005000] time: 14.72s (28558s total) loss: 131.580\n",
      "Epoch: [12] [ 8152/10059] total steps:[118801] lr:[0.00005000] time: 14.88s (28573s total) loss: 88.253\n",
      "Epoch: [12] [ 8162/10059] total steps:[118811] lr:[0.00005000] time: 16.22s (28590s total) loss: 121.123\n",
      "Epoch: [12] [ 8172/10059] total steps:[118821] lr:[0.00005000] time: 14.75s (28604s total) loss: 196.244\n",
      "Epoch: [12] [ 8182/10059] total steps:[118831] lr:[0.00005000] time: 14.73s (28619s total) loss: 173.862\n",
      "Epoch: [12] [ 8192/10059] total steps:[118841] lr:[0.00005000] time: 14.82s (28634s total) loss: 120.367\n",
      "Epoch: [12] [ 8202/10059] total steps:[118851] lr:[0.00005000] time: 14.75s (28649s total) loss: 187.988\n",
      "Epoch: [12] [ 8212/10059] total steps:[118861] lr:[0.00005000] time: 14.88s (28663s total) loss: 128.858\n",
      "Epoch: [12] [ 8222/10059] total steps:[118871] lr:[0.00005000] time: 14.88s (28678s total) loss: 153.398\n",
      "Epoch: [12] [ 8232/10059] total steps:[118881] lr:[0.00005000] time: 14.80s (28693s total) loss: 98.661\n",
      "Epoch: [12] [ 8242/10059] total steps:[118891] lr:[0.00005000] time: 14.74s (28708s total) loss: 121.761\n",
      "Epoch: [12] [ 8252/10059] total steps:[118901] lr:[0.00005000] time: 14.82s (28723s total) loss: 216.726\n",
      "Epoch: [12] [ 8262/10059] total steps:[118911] lr:[0.00005000] time: 14.94s (28738s total) loss: 140.955\n",
      "Epoch: [12] [ 8272/10059] total steps:[118921] lr:[0.00005000] time: 14.78s (28752s total) loss: 124.734\n",
      "Epoch: [12] [ 8282/10059] total steps:[118931] lr:[0.00005000] time: 14.78s (28767s total) loss: 143.973\n",
      "Epoch: [12] [ 8292/10059] total steps:[118941] lr:[0.00005000] time: 14.91s (28782s total) loss: 129.339\n",
      "Epoch: [12] [ 8302/10059] total steps:[118951] lr:[0.00005000] time: 14.86s (28797s total) loss: 164.900\n",
      "Epoch: [12] [ 8312/10059] total steps:[118961] lr:[0.00005000] time: 14.83s (28812s total) loss: 123.768\n",
      "Epoch: [12] [ 8322/10059] total steps:[118971] lr:[0.00005000] time: 14.82s (28827s total) loss: 133.931\n",
      "Epoch: [12] [ 8332/10059] total steps:[118981] lr:[0.00005000] time: 14.93s (28842s total) loss: 177.714\n",
      "Epoch: [12] [ 8342/10059] total steps:[118991] lr:[0.00005000] time: 14.81s (28856s total) loss: 154.045\n",
      "Epoch: [12] [ 8352/10059] total steps:[119001] lr:[0.00005000] time: 14.79s (28871s total) loss: 177.513\n",
      "Epoch: [12] [ 8362/10059] total steps:[119011] lr:[0.00005000] time: 14.71s (28886s total) loss: 128.921\n",
      "Epoch: [12] [ 8372/10059] total steps:[119021] lr:[0.00005000] time: 14.70s (28901s total) loss: 120.656\n",
      "Epoch: [12] [ 8382/10059] total steps:[119031] lr:[0.00005000] time: 14.68s (28915s total) loss: 137.402\n",
      "Epoch: [12] [ 8392/10059] total steps:[119041] lr:[0.00005000] time: 14.81s (28930s total) loss: 123.749\n",
      "Epoch: [12] [ 8402/10059] total steps:[119051] lr:[0.00005000] time: 14.67s (28945s total) loss: 127.806\n",
      "Epoch: [12] [ 8412/10059] total steps:[119061] lr:[0.00005000] time: 14.69s (28959s total) loss: 104.334\n",
      "Epoch: [12] [ 8422/10059] total steps:[119071] lr:[0.00005000] time: 14.83s (28974s total) loss: 110.985\n",
      "Epoch: [12] [ 8432/10059] total steps:[119081] lr:[0.00005000] time: 14.81s (28989s total) loss: 166.573\n",
      "Epoch: [12] [ 8442/10059] total steps:[119091] lr:[0.00005000] time: 14.79s (29004s total) loss: 126.352\n",
      "Epoch: [12] [ 8452/10059] total steps:[119101] lr:[0.00005000] time: 14.72s (29019s total) loss: 138.477\n",
      "Epoch: [12] [ 8462/10059] total steps:[119111] lr:[0.00005000] time: 14.73s (29033s total) loss: 125.033\n",
      "Epoch: [12] [ 8472/10059] total steps:[119121] lr:[0.00005000] time: 14.80s (29048s total) loss: 123.453\n",
      "Epoch: [12] [ 8482/10059] total steps:[119131] lr:[0.00005000] time: 14.89s (29063s total) loss: 155.744\n",
      "Epoch: [12] [ 8492/10059] total steps:[119141] lr:[0.00005000] time: 14.73s (29078s total) loss: 108.782\n",
      "Epoch: [12] [ 8502/10059] total steps:[119151] lr:[0.00005000] time: 14.75s (29092s total) loss: 126.572\n",
      "Epoch: [12] [ 8512/10059] total steps:[119161] lr:[0.00005000] time: 14.78s (29107s total) loss: 126.545\n",
      "Epoch: [12] [ 8522/10059] total steps:[119171] lr:[0.00005000] time: 14.75s (29122s total) loss: 83.044\n",
      "Epoch: [12] [ 8532/10059] total steps:[119181] lr:[0.00005000] time: 14.75s (29137s total) loss: 139.513\n",
      "Epoch: [12] [ 8542/10059] total steps:[119191] lr:[0.00005000] time: 14.83s (29152s total) loss: 126.022\n",
      "Epoch: [12] [ 8552/10059] total steps:[119201] lr:[0.00005000] time: 14.76s (29166s total) loss: 139.566\n",
      "Epoch: [12] [ 8562/10059] total steps:[119211] lr:[0.00005000] time: 14.73s (29181s total) loss: 107.191\n",
      "Epoch: [12] [ 8572/10059] total steps:[119221] lr:[0.00005000] time: 14.88s (29196s total) loss: 123.089\n",
      "Epoch: [12] [ 8582/10059] total steps:[119231] lr:[0.00005000] time: 14.70s (29211s total) loss: 109.251\n",
      "Epoch: [12] [ 8592/10059] total steps:[119241] lr:[0.00005000] time: 14.73s (29225s total) loss: 162.683\n",
      "Epoch: [12] [ 8602/10059] total steps:[119251] lr:[0.00005000] time: 14.79s (29240s total) loss: 114.381\n",
      "Epoch: [12] [ 8612/10059] total steps:[119261] lr:[0.00005000] time: 14.70s (29255s total) loss: 117.716\n",
      "Epoch: [12] [ 8622/10059] total steps:[119271] lr:[0.00005000] time: 14.87s (29270s total) loss: 180.811\n",
      "Epoch: [12] [ 8632/10059] total steps:[119281] lr:[0.00005000] time: 14.75s (29284s total) loss: 111.658\n",
      "Epoch: [12] [ 8642/10059] total steps:[119291] lr:[0.00005000] time: 14.78s (29299s total) loss: 120.823\n",
      "Epoch: [12] [ 8652/10059] total steps:[119301] lr:[0.00005000] time: 14.79s (29314s total) loss: 104.991\n",
      "Epoch: [12] [ 8662/10059] total steps:[119311] lr:[0.00005000] time: 14.83s (29329s total) loss: 109.792\n",
      "Epoch: [12] [ 8672/10059] total steps:[119321] lr:[0.00005000] time: 14.71s (29344s total) loss: 102.086\n",
      "Epoch: [12] [ 8682/10059] total steps:[119331] lr:[0.00005000] time: 14.95s (29359s total) loss: 104.612\n",
      "Epoch: [12] [ 8692/10059] total steps:[119341] lr:[0.00005000] time: 14.81s (29373s total) loss: 156.460\n",
      "Epoch: [12] [ 8702/10059] total steps:[119351] lr:[0.00005000] time: 14.79s (29388s total) loss: 173.454\n",
      "Epoch: [12] [ 8712/10059] total steps:[119361] lr:[0.00005000] time: 14.68s (29403s total) loss: 98.927\n",
      "Epoch: [12] [ 8722/10059] total steps:[119371] lr:[0.00005000] time: 14.74s (29418s total) loss: 151.957\n",
      "Epoch: [12] [ 8732/10059] total steps:[119381] lr:[0.00005000] time: 14.89s (29432s total) loss: 174.199\n",
      "Epoch: [12] [ 8742/10059] total steps:[119391] lr:[0.00005000] time: 14.70s (29447s total) loss: 108.647\n",
      "Epoch: [12] [ 8752/10059] total steps:[119401] lr:[0.00005000] time: 14.79s (29462s total) loss: 151.685\n",
      "Epoch: [12] [ 8762/10059] total steps:[119411] lr:[0.00005000] time: 14.71s (29477s total) loss: 128.221\n",
      "Epoch: [12] [ 8772/10059] total steps:[119421] lr:[0.00005000] time: 14.91s (29492s total) loss: 126.013\n",
      "Epoch: [12] [ 8782/10059] total steps:[119431] lr:[0.00005000] time: 14.82s (29506s total) loss: 106.501\n",
      "Epoch: [12] [ 8792/10059] total steps:[119441] lr:[0.00005000] time: 14.79s (29521s total) loss: 123.503\n",
      "Epoch: [12] [ 8802/10059] total steps:[119451] lr:[0.00005000] time: 14.83s (29536s total) loss: 154.194\n",
      "Epoch: [12] [ 8812/10059] total steps:[119461] lr:[0.00005000] time: 14.78s (29551s total) loss: 89.988\n",
      "Epoch: [12] [ 8822/10059] total steps:[119471] lr:[0.00005000] time: 14.88s (29566s total) loss: 110.171\n",
      "Epoch: [12] [ 8832/10059] total steps:[119481] lr:[0.00005000] time: 14.71s (29580s total) loss: 171.869\n",
      "Epoch: [12] [ 8842/10059] total steps:[119491] lr:[0.00005000] time: 14.72s (29595s total) loss: 156.299\n",
      "Epoch: [12] [ 8852/10059] total steps:[119501] lr:[0.00005000] time: 14.91s (29610s total) loss: 104.926\n",
      "Epoch: [12] [ 8862/10059] total steps:[119511] lr:[0.00005000] time: 14.78s (29625s total) loss: 115.137\n",
      "Epoch: [12] [ 8872/10059] total steps:[119521] lr:[0.00005000] time: 14.76s (29640s total) loss: 174.435\n",
      "Epoch: [12] [ 8882/10059] total steps:[119531] lr:[0.00005000] time: 14.77s (29654s total) loss: 166.778\n",
      "Epoch: [12] [ 8892/10059] total steps:[119541] lr:[0.00005000] time: 14.86s (29669s total) loss: 106.768\n",
      "Epoch: [12] [ 8902/10059] total steps:[119551] lr:[0.00005000] time: 14.80s (29684s total) loss: 167.837\n",
      "Epoch: [12] [ 8912/10059] total steps:[119561] lr:[0.00005000] time: 14.73s (29699s total) loss: 183.855\n",
      "Epoch: [12] [ 8922/10059] total steps:[119571] lr:[0.00005000] time: 14.87s (29714s total) loss: 134.751\n",
      "Epoch: [12] [ 8932/10059] total steps:[119581] lr:[0.00005000] time: 14.90s (29728s total) loss: 130.569\n",
      "Epoch: [12] [ 8942/10059] total steps:[119591] lr:[0.00005000] time: 14.78s (29743s total) loss: 147.060\n",
      "Epoch: [12] [ 8952/10059] total steps:[119601] lr:[0.00005000] time: 14.80s (29758s total) loss: 102.111\n",
      "Epoch: [12] [ 8962/10059] total steps:[119611] lr:[0.00005000] time: 14.80s (29773s total) loss: 71.522\n",
      "Epoch: [12] [ 8972/10059] total steps:[119621] lr:[0.00005000] time: 14.78s (29788s total) loss: 145.411\n",
      "Epoch: [12] [ 8982/10059] total steps:[119631] lr:[0.00005000] time: 14.76s (29802s total) loss: 148.390\n",
      "Epoch: [12] [ 8992/10059] total steps:[119641] lr:[0.00005000] time: 14.78s (29817s total) loss: 114.588\n",
      "Epoch: [12] [ 9002/10059] total steps:[119651] lr:[0.00005000] time: 14.84s (29832s total) loss: 159.024\n",
      "Epoch: [12] [ 9012/10059] total steps:[119661] lr:[0.00005000] time: 14.81s (29847s total) loss: 180.676\n",
      "Epoch: [12] [ 9022/10059] total steps:[119671] lr:[0.00005000] time: 14.78s (29862s total) loss: 142.220\n",
      "Epoch: [12] [ 9032/10059] total steps:[119681] lr:[0.00005000] time: 14.77s (29876s total) loss: 127.343\n",
      "Epoch: [12] [ 9042/10059] total steps:[119691] lr:[0.00005000] time: 14.72s (29891s total) loss: 113.729\n",
      "Epoch: [12] [ 9052/10059] total steps:[119701] lr:[0.00005000] time: 14.69s (29906s total) loss: 115.965\n",
      "Epoch: [12] [ 9062/10059] total steps:[119711] lr:[0.00005000] time: 14.90s (29921s total) loss: 93.675\n",
      "Epoch: [12] [ 9072/10059] total steps:[119721] lr:[0.00005000] time: 14.77s (29935s total) loss: 121.836\n",
      "Epoch: [12] [ 9082/10059] total steps:[119731] lr:[0.00005000] time: 14.95s (29950s total) loss: 113.398\n",
      "Epoch: [12] [ 9092/10059] total steps:[119741] lr:[0.00005000] time: 14.86s (29965s total) loss: 105.756\n",
      "Epoch: [12] [ 9102/10059] total steps:[119751] lr:[0.00005000] time: 14.85s (29980s total) loss: 152.513\n",
      "Epoch: [12] [ 9112/10059] total steps:[119761] lr:[0.00005000] time: 14.68s (29995s total) loss: 126.726\n",
      "Epoch: [12] [ 9122/10059] total steps:[119771] lr:[0.00005000] time: 14.80s (30010s total) loss: 169.495\n",
      "Epoch: [12] [ 9132/10059] total steps:[119781] lr:[0.00005000] time: 14.77s (30024s total) loss: 183.474\n",
      "Epoch: [12] [ 9142/10059] total steps:[119791] lr:[0.00005000] time: 14.80s (30039s total) loss: 175.922\n",
      "Epoch: [12] [ 9152/10059] total steps:[119801] lr:[0.00005000] time: 14.79s (30054s total) loss: 108.349\n",
      "Epoch: [12] [ 9162/10059] total steps:[119811] lr:[0.00005000] time: 14.78s (30069s total) loss: 120.407\n",
      "Epoch: [12] [ 9172/10059] total steps:[119821] lr:[0.00005000] time: 14.72s (30083s total) loss: 108.685\n",
      "Epoch: [12] [ 9182/10059] total steps:[119831] lr:[0.00005000] time: 14.87s (30098s total) loss: 117.525\n",
      "Epoch: [12] [ 9192/10059] total steps:[119841] lr:[0.00005000] time: 14.82s (30113s total) loss: 188.172\n",
      "Epoch: [12] [ 9202/10059] total steps:[119851] lr:[0.00005000] time: 14.74s (30128s total) loss: 128.863\n",
      "Epoch: [12] [ 9212/10059] total steps:[119861] lr:[0.00005000] time: 14.86s (30143s total) loss: 153.360\n",
      "Epoch: [12] [ 9222/10059] total steps:[119871] lr:[0.00005000] time: 14.75s (30157s total) loss: 77.857\n",
      "Epoch: [12] [ 9232/10059] total steps:[119881] lr:[0.00005000] time: 14.88s (30172s total) loss: 134.954\n",
      "Epoch: [12] [ 9242/10059] total steps:[119891] lr:[0.00005000] time: 14.76s (30187s total) loss: 118.149\n",
      "Epoch: [12] [ 9252/10059] total steps:[119901] lr:[0.00005000] time: 14.73s (30202s total) loss: 120.714\n",
      "Epoch: [12] [ 9262/10059] total steps:[119911] lr:[0.00005000] time: 14.78s (30217s total) loss: 110.113\n",
      "Epoch: [12] [ 9272/10059] total steps:[119921] lr:[0.00005000] time: 14.74s (30231s total) loss: 112.829\n",
      "Epoch: [12] [ 9282/10059] total steps:[119931] lr:[0.00005000] time: 14.78s (30246s total) loss: 144.762\n",
      "Epoch: [12] [ 9292/10059] total steps:[119941] lr:[0.00005000] time: 14.75s (30261s total) loss: 130.161\n",
      "Epoch: [12] [ 9302/10059] total steps:[119951] lr:[0.00005000] time: 14.83s (30276s total) loss: 177.921\n",
      "Epoch: [12] [ 9312/10059] total steps:[119961] lr:[0.00005000] time: 14.81s (30291s total) loss: 122.002\n",
      "Epoch: [12] [ 9322/10059] total steps:[119971] lr:[0.00005000] time: 14.78s (30305s total) loss: 155.486\n",
      "Epoch: [12] [ 9332/10059] total steps:[119981] lr:[0.00005000] time: 14.74s (30320s total) loss: 104.317\n",
      "Epoch: [12] [ 9342/10059] total steps:[119991] lr:[0.00005000] time: 14.82s (30335s total) loss: 126.469\n",
      "Epoch: [12] [ 9352/10059] total steps:[120001] lr:[0.00005000] time: 14.92s (30350s total) loss: 139.906\n",
      "Epoch: [12] [ 9362/10059] total steps:[120011] lr:[0.00005000] time: 14.88s (30365s total) loss: 134.182\n",
      "Epoch: [12] [ 9372/10059] total steps:[120021] lr:[0.00005000] time: 14.86s (30380s total) loss: 158.617\n",
      "Epoch: [12] [ 9382/10059] total steps:[120031] lr:[0.00005000] time: 14.95s (30394s total) loss: 166.825\n",
      "Epoch: [12] [ 9392/10059] total steps:[120041] lr:[0.00005000] time: 14.77s (30409s total) loss: 115.877\n",
      "Epoch: [12] [ 9402/10059] total steps:[120051] lr:[0.00005000] time: 14.83s (30424s total) loss: 169.430\n",
      "Epoch: [12] [ 9412/10059] total steps:[120061] lr:[0.00005000] time: 14.76s (30439s total) loss: 125.389\n",
      "Epoch: [12] [ 9422/10059] total steps:[120071] lr:[0.00005000] time: 14.95s (30454s total) loss: 119.895\n",
      "Epoch: [12] [ 9432/10059] total steps:[120081] lr:[0.00005000] time: 14.81s (30469s total) loss: 120.487\n",
      "Epoch: [12] [ 9442/10059] total steps:[120091] lr:[0.00005000] time: 14.75s (30483s total) loss: 177.041\n",
      "Epoch: [12] [ 9452/10059] total steps:[120101] lr:[0.00005000] time: 14.83s (30498s total) loss: 163.353\n",
      "Epoch: [12] [ 9462/10059] total steps:[120111] lr:[0.00005000] time: 14.73s (30513s total) loss: 113.279\n",
      "Epoch: [12] [ 9472/10059] total steps:[120121] lr:[0.00005000] time: 14.79s (30528s total) loss: 111.274\n",
      "Epoch: [12] [ 9482/10059] total steps:[120131] lr:[0.00005000] time: 14.89s (30543s total) loss: 134.753\n",
      "Epoch: [12] [ 9492/10059] total steps:[120141] lr:[0.00005000] time: 14.74s (30557s total) loss: 113.448\n",
      "Epoch: [12] [ 9502/10059] total steps:[120151] lr:[0.00005000] time: 14.79s (30572s total) loss: 182.416\n",
      "Epoch: [12] [ 9512/10059] total steps:[120161] lr:[0.00005000] time: 14.82s (30587s total) loss: 123.357\n",
      "Epoch: [12] [ 9522/10059] total steps:[120171] lr:[0.00005000] time: 14.80s (30602s total) loss: 77.247\n",
      "Epoch: [12] [ 9532/10059] total steps:[120181] lr:[0.00005000] time: 14.83s (30617s total) loss: 108.589\n",
      "Epoch: [12] [ 9542/10059] total steps:[120191] lr:[0.00005000] time: 14.79s (30631s total) loss: 115.566\n",
      "Epoch: [12] [ 9552/10059] total steps:[120201] lr:[0.00005000] time: 14.78s (30646s total) loss: 88.216\n",
      "Epoch: [12] [ 9562/10059] total steps:[120211] lr:[0.00005000] time: 14.76s (30661s total) loss: 162.685\n",
      "Epoch: [12] [ 9572/10059] total steps:[120221] lr:[0.00005000] time: 14.87s (30676s total) loss: 100.723\n",
      "Epoch: [12] [ 9582/10059] total steps:[120231] lr:[0.00005000] time: 14.78s (30691s total) loss: 84.514\n",
      "Epoch: [12] [ 9592/10059] total steps:[120241] lr:[0.00005000] time: 14.75s (30705s total) loss: 96.909\n",
      "Epoch: [12] [ 9602/10059] total steps:[120251] lr:[0.00005000] time: 14.75s (30720s total) loss: 133.159\n",
      "Epoch: [12] [ 9612/10059] total steps:[120261] lr:[0.00005000] time: 14.86s (30735s total) loss: 168.450\n",
      "Epoch: [12] [ 9622/10059] total steps:[120271] lr:[0.00005000] time: 14.83s (30750s total) loss: 194.569\n",
      "Epoch: [12] [ 9632/10059] total steps:[120281] lr:[0.00005000] time: 14.80s (30765s total) loss: 155.792\n",
      "Epoch: [12] [ 9642/10059] total steps:[120291] lr:[0.00005000] time: 14.81s (30779s total) loss: 152.858\n",
      "Epoch: [12] [ 9652/10059] total steps:[120301] lr:[0.00005000] time: 14.86s (30794s total) loss: 170.921\n",
      "Epoch: [12] [ 9662/10059] total steps:[120311] lr:[0.00005000] time: 14.77s (30809s total) loss: 125.946\n",
      "Epoch: [12] [ 9672/10059] total steps:[120321] lr:[0.00005000] time: 14.78s (30824s total) loss: 147.147\n",
      "Epoch: [12] [ 9682/10059] total steps:[120331] lr:[0.00005000] time: 14.68s (30838s total) loss: 149.744\n",
      "Epoch: [12] [ 9692/10059] total steps:[120341] lr:[0.00005000] time: 14.88s (30853s total) loss: 108.900\n",
      "Epoch: [12] [ 9702/10059] total steps:[120351] lr:[0.00005000] time: 14.87s (30868s total) loss: 126.206\n",
      "Epoch: [12] [ 9712/10059] total steps:[120361] lr:[0.00005000] time: 14.76s (30883s total) loss: 102.560\n",
      "Epoch: [12] [ 9722/10059] total steps:[120371] lr:[0.00005000] time: 14.92s (30898s total) loss: 160.025\n",
      "Epoch: [12] [ 9732/10059] total steps:[120381] lr:[0.00005000] time: 14.75s (30913s total) loss: 155.157\n",
      "Epoch: [12] [ 9742/10059] total steps:[120391] lr:[0.00005000] time: 14.85s (30927s total) loss: 130.138\n",
      "Epoch: [12] [ 9752/10059] total steps:[120401] lr:[0.00005000] time: 14.96s (30942s total) loss: 181.057\n",
      "Epoch: [12] [ 9762/10059] total steps:[120411] lr:[0.00005000] time: 14.76s (30957s total) loss: 133.388\n",
      "Epoch: [12] [ 9772/10059] total steps:[120421] lr:[0.00005000] time: 14.82s (30972s total) loss: 146.033\n",
      "Epoch: [12] [ 9782/10059] total steps:[120431] lr:[0.00005000] time: 14.77s (30987s total) loss: 160.340\n",
      "Epoch: [12] [ 9792/10059] total steps:[120441] lr:[0.00005000] time: 14.84s (31002s total) loss: 121.980\n",
      "Epoch: [12] [ 9802/10059] total steps:[120451] lr:[0.00005000] time: 14.68s (31016s total) loss: 146.945\n",
      "Epoch: [12] [ 9812/10059] total steps:[120461] lr:[0.00005000] time: 14.62s (31031s total) loss: 119.825\n",
      "Epoch: [12] [ 9822/10059] total steps:[120471] lr:[0.00005000] time: 14.77s (31046s total) loss: 103.423\n",
      "Epoch: [12] [ 9832/10059] total steps:[120481] lr:[0.00005000] time: 14.85s (31061s total) loss: 161.207\n",
      "Epoch: [12] [ 9842/10059] total steps:[120491] lr:[0.00005000] time: 14.87s (31075s total) loss: 89.138\n",
      "Epoch: [12] [ 9852/10059] total steps:[120501] lr:[0.00005000] time: 14.95s (31090s total) loss: 160.042\n",
      "Epoch: [12] [ 9862/10059] total steps:[120511] lr:[0.00005000] time: 14.75s (31105s total) loss: 108.918\n",
      "Epoch: [12] [ 9872/10059] total steps:[120521] lr:[0.00005000] time: 14.77s (31120s total) loss: 129.504\n",
      "Epoch: [12] [ 9882/10059] total steps:[120531] lr:[0.00005000] time: 14.75s (31135s total) loss: 167.059\n",
      "Epoch: [12] [ 9892/10059] total steps:[120541] lr:[0.00005000] time: 14.74s (31149s total) loss: 140.785\n",
      "Epoch: [12] [ 9902/10059] total steps:[120551] lr:[0.00005000] time: 14.75s (31164s total) loss: 124.123\n",
      "Epoch: [12] [ 9912/10059] total steps:[120561] lr:[0.00005000] time: 14.76s (31179s total) loss: 138.569\n",
      "Epoch: [12] [ 9922/10059] total steps:[120571] lr:[0.00005000] time: 14.78s (31194s total) loss: 123.845\n",
      "Epoch: [12] [ 9932/10059] total steps:[120581] lr:[0.00005000] time: 14.77s (31208s total) loss: 166.834\n",
      "Epoch: [12] [ 9942/10059] total steps:[120591] lr:[0.00005000] time: 14.89s (31223s total) loss: 109.345\n",
      "Epoch: [12] [ 9952/10059] total steps:[120601] lr:[0.00005000] time: 14.87s (31238s total) loss: 163.425\n",
      "Epoch: [12] [ 9962/10059] total steps:[120611] lr:[0.00005000] time: 14.73s (31253s total) loss: 133.784\n",
      "Epoch: [12] [ 9972/10059] total steps:[120621] lr:[0.00005000] time: 14.79s (31268s total) loss: 108.219\n",
      "Epoch: [12] [ 9982/10059] total steps:[120631] lr:[0.00005000] time: 14.67s (31282s total) loss: 129.200\n",
      "Epoch: [12] [ 9992/10059] total steps:[120641] lr:[0.00005000] time: 14.82s (31297s total) loss: 142.071\n",
      "Epoch: [12] [10002/10059] total steps:[120651] lr:[0.00005000] time: 14.75s (31312s total) loss: 168.210\n",
      "Epoch: [12] [10012/10059] total steps:[120661] lr:[0.00005000] time: 14.71s (31327s total) loss: 124.558\n",
      "Epoch: [12] [10022/10059] total steps:[120671] lr:[0.00005000] time: 14.83s (31341s total) loss: 132.706\n",
      "Epoch: [12] [10032/10059] total steps:[120681] lr:[0.00005000] time: 14.84s (31356s total) loss: 153.157\n",
      "Epoch: [12] [10042/10059] total steps:[120691] lr:[0.00005000] time: 14.72s (31371s total) loss: 130.715\n",
      "Epoch: [12] [10052/10059] total steps:[120701] lr:[0.00005000] time: 14.79s (31386s total) loss: 127.650\n",
      "[Info] Saving checkpoint to ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints ...\n",
      "Epoch: [13] [    3/10059] total steps:[120711] lr:[0.00005000] time: 32.83s (31419s total) loss: 76.776\n",
      "Epoch: [13] [   13/10059] total steps:[120721] lr:[0.00005000] time: 14.79s (31433s total) loss: 104.368\n",
      "Epoch: [13] [   23/10059] total steps:[120731] lr:[0.00005000] time: 14.66s (31448s total) loss: 149.383\n",
      "Epoch: [13] [   33/10059] total steps:[120741] lr:[0.00005000] time: 14.84s (31463s total) loss: 159.625\n",
      "Epoch: [13] [   43/10059] total steps:[120751] lr:[0.00005000] time: 14.86s (31478s total) loss: 142.011\n",
      "Epoch: [13] [   53/10059] total steps:[120761] lr:[0.00005000] time: 14.69s (31492s total) loss: 119.516\n",
      "Epoch: [13] [   63/10059] total steps:[120771] lr:[0.00005000] time: 14.77s (31507s total) loss: 155.523\n",
      "Epoch: [13] [   73/10059] total steps:[120781] lr:[0.00005000] time: 14.78s (31522s total) loss: 128.678\n",
      "Epoch: [13] [   83/10059] total steps:[120791] lr:[0.00005000] time: 14.79s (31537s total) loss: 114.124\n",
      "Epoch: [13] [   93/10059] total steps:[120801] lr:[0.00005000] time: 14.69s (31552s total) loss: 144.734\n",
      "Epoch: [13] [  103/10059] total steps:[120811] lr:[0.00005000] time: 14.87s (31566s total) loss: 97.822\n",
      "Epoch: [13] [  113/10059] total steps:[120821] lr:[0.00005000] time: 14.72s (31581s total) loss: 126.479\n",
      "Epoch: [13] [  123/10059] total steps:[120831] lr:[0.00005000] time: 14.73s (31596s total) loss: 170.844\n",
      "Epoch: [13] [  133/10059] total steps:[120841] lr:[0.00005000] time: 14.73s (31611s total) loss: 91.656\n",
      "Epoch: [13] [  143/10059] total steps:[120851] lr:[0.00005000] time: 14.81s (31625s total) loss: 89.843\n",
      "Epoch: [13] [  153/10059] total steps:[120861] lr:[0.00005000] time: 14.87s (31640s total) loss: 108.370\n",
      "Epoch: [13] [  163/10059] total steps:[120871] lr:[0.00005000] time: 14.83s (31655s total) loss: 147.149\n",
      "Epoch: [13] [  173/10059] total steps:[120881] lr:[0.00005000] time: 14.89s (31670s total) loss: 139.065\n",
      "Epoch: [13] [  183/10059] total steps:[120891] lr:[0.00005000] time: 14.79s (31685s total) loss: 103.596\n",
      "Epoch: [13] [  193/10059] total steps:[120901] lr:[0.00005000] time: 14.83s (31700s total) loss: 129.687\n",
      "Epoch: [13] [  203/10059] total steps:[120911] lr:[0.00005000] time: 14.80s (31714s total) loss: 120.073\n",
      "Epoch: [13] [  213/10059] total steps:[120921] lr:[0.00005000] time: 14.70s (31729s total) loss: 124.663\n",
      "Epoch: [13] [  223/10059] total steps:[120931] lr:[0.00005000] time: 14.79s (31744s total) loss: 229.106\n",
      "Epoch: [13] [  233/10059] total steps:[120941] lr:[0.00005000] time: 14.71s (31759s total) loss: 155.196\n",
      "Epoch: [13] [  243/10059] total steps:[120951] lr:[0.00005000] time: 14.75s (31773s total) loss: 168.190\n",
      "Epoch: [13] [  253/10059] total steps:[120961] lr:[0.00005000] time: 14.78s (31788s total) loss: 102.603\n",
      "Epoch: [13] [  263/10059] total steps:[120971] lr:[0.00005000] time: 14.75s (31803s total) loss: 124.724\n",
      "Epoch: [13] [  273/10059] total steps:[120981] lr:[0.00005000] time: 14.84s (31818s total) loss: 132.528\n",
      "Epoch: [13] [  283/10059] total steps:[120991] lr:[0.00005000] time: 14.79s (31832s total) loss: 77.935\n",
      "Epoch: [13] [  293/10059] total steps:[121001] lr:[0.00005000] time: 14.94s (31847s total) loss: 114.202\n",
      "Epoch: [13] [  303/10059] total steps:[121011] lr:[0.00005000] time: 14.81s (31862s total) loss: 133.535\n",
      "Epoch: [13] [  313/10059] total steps:[121021] lr:[0.00005000] time: 14.76s (31877s total) loss: 121.620\n",
      "Epoch: [13] [  323/10059] total steps:[121031] lr:[0.00005000] time: 14.75s (31892s total) loss: 164.950\n",
      "Epoch: [13] [  333/10059] total steps:[121041] lr:[0.00005000] time: 14.79s (31907s total) loss: 126.630\n",
      "Epoch: [13] [  343/10059] total steps:[121051] lr:[0.00005000] time: 14.86s (31921s total) loss: 157.991\n",
      "Epoch: [13] [  353/10059] total steps:[121061] lr:[0.00005000] time: 14.85s (31936s total) loss: 111.618\n",
      "Epoch: [13] [  363/10059] total steps:[121071] lr:[0.00005000] time: 14.70s (31951s total) loss: 128.124\n",
      "Epoch: [13] [  373/10059] total steps:[121081] lr:[0.00005000] time: 14.76s (31966s total) loss: 133.053\n",
      "Epoch: [13] [  383/10059] total steps:[121091] lr:[0.00005000] time: 14.78s (31980s total) loss: 132.522\n",
      "Epoch: [13] [  393/10059] total steps:[121101] lr:[0.00005000] time: 14.99s (31995s total) loss: 141.490\n",
      "Epoch: [13] [  403/10059] total steps:[121111] lr:[0.00005000] time: 14.83s (32010s total) loss: 132.089\n",
      "Epoch: [13] [  413/10059] total steps:[121121] lr:[0.00005000] time: 14.84s (32025s total) loss: 143.487\n",
      "Epoch: [13] [  423/10059] total steps:[121131] lr:[0.00005000] time: 14.77s (32040s total) loss: 96.968\n",
      "Epoch: [13] [  433/10059] total steps:[121141] lr:[0.00005000] time: 14.72s (32055s total) loss: 92.887\n",
      "Epoch: [13] [  443/10059] total steps:[121151] lr:[0.00005000] time: 14.68s (32069s total) loss: 114.998\n",
      "Epoch: [13] [  453/10059] total steps:[121161] lr:[0.00005000] time: 14.74s (32084s total) loss: 102.908\n",
      "Epoch: [13] [  463/10059] total steps:[121171] lr:[0.00005000] time: 14.72s (32099s total) loss: 106.128\n",
      "Epoch: [13] [  473/10059] total steps:[121181] lr:[0.00005000] time: 14.87s (32114s total) loss: 105.598\n",
      "Epoch: [13] [  483/10059] total steps:[121191] lr:[0.00005000] time: 14.92s (32129s total) loss: 175.808\n",
      "Epoch: [13] [  493/10059] total steps:[121201] lr:[0.00005000] time: 14.74s (32143s total) loss: 92.379\n",
      "Epoch: [13] [  503/10059] total steps:[121211] lr:[0.00005000] time: 14.73s (32158s total) loss: 152.217\n",
      "Epoch: [13] [  513/10059] total steps:[121221] lr:[0.00005000] time: 14.69s (32173s total) loss: 166.632\n",
      "Epoch: [13] [  523/10059] total steps:[121231] lr:[0.00005000] time: 14.79s (32188s total) loss: 111.717\n",
      "Epoch: [13] [  533/10059] total steps:[121241] lr:[0.00005000] time: 14.73s (32202s total) loss: 129.088\n",
      "Epoch: [13] [  543/10059] total steps:[121251] lr:[0.00005000] time: 14.89s (32217s total) loss: 143.130\n",
      "Epoch: [13] [  553/10059] total steps:[121261] lr:[0.00005000] time: 14.92s (32232s total) loss: 145.712\n",
      "Epoch: [13] [  563/10059] total steps:[121271] lr:[0.00005000] time: 14.72s (32247s total) loss: 142.019\n",
      "Epoch: [13] [  573/10059] total steps:[121281] lr:[0.00005000] time: 14.79s (32262s total) loss: 110.711\n",
      "Epoch: [13] [  583/10059] total steps:[121291] lr:[0.00005000] time: 14.72s (32276s total) loss: 173.647\n",
      "Epoch: [13] [  593/10059] total steps:[121301] lr:[0.00005000] time: 14.87s (32291s total) loss: 144.406\n",
      "Epoch: [13] [  603/10059] total steps:[121311] lr:[0.00005000] time: 14.75s (32306s total) loss: 190.247\n",
      "Epoch: [13] [  613/10059] total steps:[121321] lr:[0.00005000] time: 14.80s (32321s total) loss: 145.423\n",
      "Epoch: [13] [  623/10059] total steps:[121331] lr:[0.00005000] time: 14.73s (32335s total) loss: 139.100\n",
      "Epoch: [13] [  633/10059] total steps:[121341] lr:[0.00005000] time: 14.82s (32350s total) loss: 99.052\n",
      "Epoch: [13] [  643/10059] total steps:[121351] lr:[0.00005000] time: 14.73s (32365s total) loss: 138.214\n",
      "Epoch: [13] [  653/10059] total steps:[121361] lr:[0.00005000] time: 14.71s (32380s total) loss: 111.376\n",
      "Epoch: [13] [  663/10059] total steps:[121371] lr:[0.00005000] time: 14.79s (32394s total) loss: 198.871\n",
      "Epoch: [13] [  673/10059] total steps:[121381] lr:[0.00005000] time: 16.42s (32411s total) loss: 145.171\n",
      "Epoch: [13] [  683/10059] total steps:[121391] lr:[0.00005000] time: 14.88s (32426s total) loss: 164.941\n",
      "Epoch: [13] [  693/10059] total steps:[121401] lr:[0.00005000] time: 14.84s (32441s total) loss: 173.850\n",
      "Epoch: [13] [  703/10059] total steps:[121411] lr:[0.00005000] time: 15.01s (32456s total) loss: 141.960\n",
      "Epoch: [13] [  713/10059] total steps:[121421] lr:[0.00005000] time: 14.71s (32470s total) loss: 111.633\n",
      "Epoch: [13] [  723/10059] total steps:[121431] lr:[0.00005000] time: 14.80s (32485s total) loss: 137.370\n",
      "Epoch: [13] [  733/10059] total steps:[121441] lr:[0.00005000] time: 14.81s (32500s total) loss: 108.156\n",
      "Epoch: [13] [  743/10059] total steps:[121451] lr:[0.00005000] time: 14.91s (32515s total) loss: 132.481\n",
      "Epoch: [13] [  753/10059] total steps:[121461] lr:[0.00005000] time: 14.71s (32530s total) loss: 120.256\n",
      "Epoch: [13] [  763/10059] total steps:[121471] lr:[0.00005000] time: 14.69s (32544s total) loss: 131.703\n",
      "Epoch: [13] [  773/10059] total steps:[121481] lr:[0.00005000] time: 14.87s (32559s total) loss: 115.193\n",
      "Epoch: [13] [  783/10059] total steps:[121491] lr:[0.00005000] time: 14.68s (32574s total) loss: 127.171\n",
      "Epoch: [13] [  793/10059] total steps:[121501] lr:[0.00005000] time: 14.77s (32589s total) loss: 137.647\n",
      "Epoch: [13] [  803/10059] total steps:[121511] lr:[0.00005000] time: 14.88s (32603s total) loss: 116.602\n",
      "Epoch: [13] [  813/10059] total steps:[121521] lr:[0.00005000] time: 14.81s (32618s total) loss: 103.111\n",
      "Epoch: [13] [  823/10059] total steps:[121531] lr:[0.00005000] time: 14.85s (32633s total) loss: 115.042\n",
      "Epoch: [13] [  833/10059] total steps:[121541] lr:[0.00005000] time: 14.67s (32648s total) loss: 157.544\n",
      "Epoch: [13] [  843/10059] total steps:[121551] lr:[0.00005000] time: 14.91s (32663s total) loss: 200.601\n",
      "Epoch: [13] [  853/10059] total steps:[121561] lr:[0.00005000] time: 14.90s (32678s total) loss: 156.132\n",
      "Epoch: [13] [  863/10059] total steps:[121571] lr:[0.00005000] time: 14.81s (32692s total) loss: 141.894\n",
      "Epoch: [13] [  873/10059] total steps:[121581] lr:[0.00005000] time: 14.82s (32707s total) loss: 89.174\n",
      "Epoch: [13] [  883/10059] total steps:[121591] lr:[0.00005000] time: 14.73s (32722s total) loss: 129.172\n",
      "Epoch: [13] [  893/10059] total steps:[121601] lr:[0.00005000] time: 14.70s (32737s total) loss: 97.085\n",
      "Epoch: [13] [  903/10059] total steps:[121611] lr:[0.00005000] time: 14.85s (32752s total) loss: 177.491\n",
      "Epoch: [13] [  913/10059] total steps:[121621] lr:[0.00005000] time: 14.76s (32766s total) loss: 128.910\n",
      "Epoch: [13] [  923/10059] total steps:[121631] lr:[0.00005000] time: 14.77s (32781s total) loss: 129.750\n",
      "Epoch: [13] [  933/10059] total steps:[121641] lr:[0.00005000] time: 14.85s (32796s total) loss: 158.975\n",
      "Epoch: [13] [  943/10059] total steps:[121651] lr:[0.00005000] time: 14.77s (32811s total) loss: 133.024\n",
      "Epoch: [13] [  953/10059] total steps:[121661] lr:[0.00005000] time: 14.77s (32825s total) loss: 189.293\n",
      "Epoch: [13] [  963/10059] total steps:[121671] lr:[0.00005000] time: 14.71s (32840s total) loss: 144.189\n",
      "Epoch: [13] [  973/10059] total steps:[121681] lr:[0.00005000] time: 14.93s (32855s total) loss: 150.401\n",
      "Epoch: [13] [  983/10059] total steps:[121691] lr:[0.00005000] time: 14.84s (32870s total) loss: 149.499\n",
      "Epoch: [13] [  993/10059] total steps:[121701] lr:[0.00005000] time: 14.84s (32885s total) loss: 129.768\n",
      "Epoch: [13] [ 1003/10059] total steps:[121711] lr:[0.00005000] time: 14.75s (32900s total) loss: 116.870\n",
      "Epoch: [13] [ 1013/10059] total steps:[121721] lr:[0.00005000] time: 14.70s (32914s total) loss: 143.840\n",
      "Epoch: [13] [ 1023/10059] total steps:[121731] lr:[0.00005000] time: 14.89s (32929s total) loss: 124.279\n",
      "Epoch: [13] [ 1033/10059] total steps:[121741] lr:[0.00005000] time: 14.79s (32944s total) loss: 135.269\n",
      "Epoch: [13] [ 1043/10059] total steps:[121751] lr:[0.00005000] time: 14.76s (32959s total) loss: 171.667\n",
      "Epoch: [13] [ 1053/10059] total steps:[121761] lr:[0.00005000] time: 14.86s (32974s total) loss: 178.415\n",
      "Epoch: [13] [ 1063/10059] total steps:[121771] lr:[0.00005000] time: 14.86s (32988s total) loss: 143.287\n",
      "Epoch: [13] [ 1073/10059] total steps:[121781] lr:[0.00005000] time: 14.81s (33003s total) loss: 135.019\n",
      "Epoch: [13] [ 1083/10059] total steps:[121791] lr:[0.00005000] time: 14.79s (33018s total) loss: 122.860\n",
      "Epoch: [13] [ 1093/10059] total steps:[121801] lr:[0.00005000] time: 14.92s (33033s total) loss: 133.653\n",
      "Epoch: [13] [ 1103/10059] total steps:[121811] lr:[0.00005000] time: 14.87s (33048s total) loss: 96.529\n",
      "Epoch: [13] [ 1113/10059] total steps:[121821] lr:[0.00005000] time: 14.86s (33063s total) loss: 176.283\n",
      "Epoch: [13] [ 1123/10059] total steps:[121831] lr:[0.00005000] time: 14.72s (33077s total) loss: 124.836\n",
      "Epoch: [13] [ 1133/10059] total steps:[121841] lr:[0.00005000] time: 14.73s (33092s total) loss: 114.897\n",
      "Epoch: [13] [ 1143/10059] total steps:[121851] lr:[0.00005000] time: 14.77s (33107s total) loss: 134.827\n",
      "Epoch: [13] [ 1153/10059] total steps:[121861] lr:[0.00005000] time: 14.78s (33122s total) loss: 181.240\n",
      "Epoch: [13] [ 1163/10059] total steps:[121871] lr:[0.00005000] time: 14.97s (33137s total) loss: 68.709\n",
      "Epoch: [13] [ 1173/10059] total steps:[121881] lr:[0.00005000] time: 14.82s (33151s total) loss: 132.284\n",
      "Epoch: [13] [ 1183/10059] total steps:[121891] lr:[0.00005000] time: 14.72s (33166s total) loss: 125.574\n",
      "Epoch: [13] [ 1193/10059] total steps:[121901] lr:[0.00005000] time: 14.78s (33181s total) loss: 80.699\n",
      "Epoch: [13] [ 1203/10059] total steps:[121911] lr:[0.00005000] time: 14.75s (33196s total) loss: 108.165\n",
      "Epoch: [13] [ 1213/10059] total steps:[121921] lr:[0.00005000] time: 14.74s (33210s total) loss: 145.265\n",
      "Epoch: [13] [ 1223/10059] total steps:[121931] lr:[0.00005000] time: 14.81s (33225s total) loss: 129.153\n",
      "Epoch: [13] [ 1233/10059] total steps:[121941] lr:[0.00005000] time: 14.81s (33240s total) loss: 150.264\n",
      "Epoch: [13] [ 1243/10059] total steps:[121951] lr:[0.00005000] time: 14.73s (33255s total) loss: 104.197\n",
      "Epoch: [13] [ 1253/10059] total steps:[121961] lr:[0.00005000] time: 14.81s (33270s total) loss: 128.467\n",
      "Epoch: [13] [ 1263/10059] total steps:[121971] lr:[0.00005000] time: 14.70s (33284s total) loss: 99.733\n",
      "Epoch: [13] [ 1273/10059] total steps:[121981] lr:[0.00005000] time: 14.78s (33299s total) loss: 125.112\n",
      "Epoch: [13] [ 1283/10059] total steps:[121991] lr:[0.00005000] time: 14.79s (33314s total) loss: 165.372\n",
      "Epoch: [13] [ 1293/10059] total steps:[122001] lr:[0.00005000] time: 14.76s (33329s total) loss: 96.838\n",
      "Epoch: [13] [ 1303/10059] total steps:[122011] lr:[0.00005000] time: 14.73s (33343s total) loss: 123.254\n",
      "Epoch: [13] [ 1313/10059] total steps:[122021] lr:[0.00005000] time: 14.70s (33358s total) loss: 109.048\n",
      "Epoch: [13] [ 1323/10059] total steps:[122031] lr:[0.00005000] time: 14.81s (33373s total) loss: 100.217\n",
      "Epoch: [13] [ 1333/10059] total steps:[122041] lr:[0.00005000] time: 15.01s (33388s total) loss: 181.427\n",
      "Epoch: [13] [ 1343/10059] total steps:[122051] lr:[0.00005000] time: 14.78s (33403s total) loss: 111.042\n",
      "Epoch: [13] [ 1353/10059] total steps:[122061] lr:[0.00005000] time: 15.02s (33418s total) loss: 102.858\n",
      "Epoch: [13] [ 1363/10059] total steps:[122071] lr:[0.00005000] time: 14.71s (33432s total) loss: 110.661\n",
      "Epoch: [13] [ 1373/10059] total steps:[122081] lr:[0.00005000] time: 14.70s (33447s total) loss: 155.957\n",
      "Epoch: [13] [ 1383/10059] total steps:[122091] lr:[0.00005000] time: 14.76s (33462s total) loss: 110.153\n",
      "Epoch: [13] [ 1393/10059] total steps:[122101] lr:[0.00005000] time: 14.81s (33477s total) loss: 152.407\n",
      "Epoch: [13] [ 1403/10059] total steps:[122111] lr:[0.00005000] time: 14.86s (33491s total) loss: 96.750\n",
      "Epoch: [13] [ 1413/10059] total steps:[122121] lr:[0.00005000] time: 14.66s (33506s total) loss: 88.609\n",
      "Epoch: [13] [ 1423/10059] total steps:[122131] lr:[0.00005000] time: 14.67s (33521s total) loss: 116.000\n",
      "Epoch: [13] [ 1433/10059] total steps:[122141] lr:[0.00005000] time: 14.74s (33536s total) loss: 160.101\n",
      "Epoch: [13] [ 1443/10059] total steps:[122151] lr:[0.00005000] time: 14.82s (33550s total) loss: 174.899\n",
      "Epoch: [13] [ 1453/10059] total steps:[122161] lr:[0.00005000] time: 14.65s (33565s total) loss: 182.514\n",
      "Epoch: [13] [ 1463/10059] total steps:[122171] lr:[0.00005000] time: 14.79s (33580s total) loss: 109.171\n",
      "Epoch: [13] [ 1473/10059] total steps:[122181] lr:[0.00005000] time: 14.74s (33595s total) loss: 131.648\n",
      "Epoch: [13] [ 1483/10059] total steps:[122191] lr:[0.00005000] time: 14.95s (33610s total) loss: 80.265\n",
      "Epoch: [13] [ 1493/10059] total steps:[122201] lr:[0.00005000] time: 14.95s (33624s total) loss: 167.378\n",
      "Epoch: [13] [ 1503/10059] total steps:[122211] lr:[0.00005000] time: 14.74s (33639s total) loss: 147.476\n",
      "Epoch: [13] [ 1513/10059] total steps:[122221] lr:[0.00005000] time: 14.79s (33654s total) loss: 172.742\n",
      "Epoch: [13] [ 1523/10059] total steps:[122231] lr:[0.00005000] time: 14.67s (33669s total) loss: 105.170\n",
      "Epoch: [13] [ 1533/10059] total steps:[122241] lr:[0.00005000] time: 14.71s (33683s total) loss: 159.526\n",
      "Epoch: [13] [ 1543/10059] total steps:[122251] lr:[0.00005000] time: 14.71s (33698s total) loss: 156.417\n",
      "Epoch: [13] [ 1553/10059] total steps:[122261] lr:[0.00005000] time: 14.82s (33713s total) loss: 142.472\n",
      "Epoch: [13] [ 1563/10059] total steps:[122271] lr:[0.00005000] time: 14.73s (33728s total) loss: 163.535\n",
      "Epoch: [13] [ 1573/10059] total steps:[122281] lr:[0.00005000] time: 14.78s (33742s total) loss: 132.669\n",
      "Epoch: [13] [ 1583/10059] total steps:[122291] lr:[0.00005000] time: 14.88s (33757s total) loss: 136.906\n",
      "Epoch: [13] [ 1593/10059] total steps:[122301] lr:[0.00005000] time: 14.77s (33772s total) loss: 221.691\n",
      "Epoch: [13] [ 1603/10059] total steps:[122311] lr:[0.00005000] time: 14.81s (33787s total) loss: 141.998\n",
      "Epoch: [13] [ 1613/10059] total steps:[122321] lr:[0.00005000] time: 14.87s (33802s total) loss: 161.940\n",
      "Epoch: [13] [ 1623/10059] total steps:[122331] lr:[0.00005000] time: 14.81s (33817s total) loss: 90.556\n",
      "Epoch: [13] [ 1633/10059] total steps:[122341] lr:[0.00005000] time: 14.71s (33831s total) loss: 95.687\n",
      "Epoch: [13] [ 1643/10059] total steps:[122351] lr:[0.00005000] time: 14.88s (33846s total) loss: 119.409\n",
      "Epoch: [13] [ 1653/10059] total steps:[122361] lr:[0.00005000] time: 15.00s (33861s total) loss: 159.229\n",
      "Epoch: [13] [ 1663/10059] total steps:[122371] lr:[0.00005000] time: 14.72s (33876s total) loss: 168.973\n",
      "Epoch: [13] [ 1673/10059] total steps:[122381] lr:[0.00005000] time: 14.83s (33891s total) loss: 102.922\n",
      "Epoch: [13] [ 1683/10059] total steps:[122391] lr:[0.00005000] time: 14.73s (33905s total) loss: 163.755\n",
      "Epoch: [13] [ 1693/10059] total steps:[122401] lr:[0.00005000] time: 14.95s (33920s total) loss: 167.933\n",
      "Epoch: [13] [ 1703/10059] total steps:[122411] lr:[0.00005000] time: 14.73s (33935s total) loss: 155.161\n",
      "Epoch: [13] [ 1713/10059] total steps:[122421] lr:[0.00005000] time: 14.76s (33950s total) loss: 119.748\n",
      "Epoch: [13] [ 1723/10059] total steps:[122431] lr:[0.00005000] time: 14.80s (33965s total) loss: 162.667\n",
      "Epoch: [13] [ 1733/10059] total steps:[122441] lr:[0.00005000] time: 14.93s (33980s total) loss: 141.365\n",
      "Epoch: [13] [ 1743/10059] total steps:[122451] lr:[0.00005000] time: 14.85s (33994s total) loss: 93.984\n",
      "Epoch: [13] [ 1753/10059] total steps:[122461] lr:[0.00005000] time: 14.72s (34009s total) loss: 123.180\n",
      "Epoch: [13] [ 1763/10059] total steps:[122471] lr:[0.00005000] time: 14.78s (34024s total) loss: 141.570\n",
      "Epoch: [13] [ 1773/10059] total steps:[122481] lr:[0.00005000] time: 14.82s (34039s total) loss: 214.315\n",
      "Epoch: [13] [ 1783/10059] total steps:[122491] lr:[0.00005000] time: 14.80s (34054s total) loss: 148.662\n",
      "Epoch: [13] [ 1793/10059] total steps:[122501] lr:[0.00005000] time: 14.85s (34068s total) loss: 132.184\n",
      "Epoch: [13] [ 1803/10059] total steps:[122511] lr:[0.00005000] time: 14.80s (34083s total) loss: 149.129\n",
      "Epoch: [13] [ 1813/10059] total steps:[122521] lr:[0.00005000] time: 14.64s (34098s total) loss: 143.680\n",
      "Epoch: [13] [ 1823/10059] total steps:[122531] lr:[0.00005000] time: 14.79s (34113s total) loss: 87.834\n",
      "Epoch: [13] [ 1833/10059] total steps:[122541] lr:[0.00005000] time: 14.78s (34127s total) loss: 161.358\n",
      "Epoch: [13] [ 1843/10059] total steps:[122551] lr:[0.00005000] time: 14.86s (34142s total) loss: 91.388\n",
      "Epoch: [13] [ 1853/10059] total steps:[122561] lr:[0.00005000] time: 14.88s (34157s total) loss: 138.655\n",
      "Epoch: [13] [ 1863/10059] total steps:[122571] lr:[0.00005000] time: 14.67s (34172s total) loss: 97.187\n",
      "Epoch: [13] [ 1873/10059] total steps:[122581] lr:[0.00005000] time: 14.80s (34187s total) loss: 115.013\n",
      "Epoch: [13] [ 1883/10059] total steps:[122591] lr:[0.00005000] time: 14.66s (34201s total) loss: 132.572\n",
      "Epoch: [13] [ 1893/10059] total steps:[122601] lr:[0.00005000] time: 14.81s (34216s total) loss: 160.513\n",
      "Epoch: [13] [ 1903/10059] total steps:[122611] lr:[0.00005000] time: 14.78s (34231s total) loss: 99.278\n",
      "Epoch: [13] [ 1913/10059] total steps:[122621] lr:[0.00005000] time: 14.82s (34246s total) loss: 166.568\n",
      "Epoch: [13] [ 1923/10059] total steps:[122631] lr:[0.00005000] time: 14.78s (34260s total) loss: 115.570\n",
      "Epoch: [13] [ 1933/10059] total steps:[122641] lr:[0.00005000] time: 14.89s (34275s total) loss: 130.516\n",
      "Epoch: [13] [ 1943/10059] total steps:[122651] lr:[0.00005000] time: 14.77s (34290s total) loss: 195.945\n",
      "Epoch: [13] [ 1953/10059] total steps:[122661] lr:[0.00005000] time: 14.69s (34305s total) loss: 147.243\n",
      "Epoch: [13] [ 1963/10059] total steps:[122671] lr:[0.00005000] time: 14.67s (34319s total) loss: 74.868\n",
      "Epoch: [13] [ 1973/10059] total steps:[122681] lr:[0.00005000] time: 14.73s (34334s total) loss: 125.721\n",
      "Epoch: [13] [ 1983/10059] total steps:[122691] lr:[0.00005000] time: 14.77s (34349s total) loss: 128.985\n",
      "Epoch: [13] [ 1993/10059] total steps:[122701] lr:[0.00005000] time: 14.73s (34364s total) loss: 162.841\n",
      "Epoch: [13] [ 2003/10059] total steps:[122711] lr:[0.00005000] time: 14.84s (34379s total) loss: 133.023\n",
      "Epoch: [13] [ 2013/10059] total steps:[122721] lr:[0.00005000] time: 14.84s (34393s total) loss: 113.106\n",
      "Epoch: [13] [ 2023/10059] total steps:[122731] lr:[0.00005000] time: 14.86s (34408s total) loss: 156.919\n",
      "Epoch: [13] [ 2033/10059] total steps:[122741] lr:[0.00005000] time: 14.83s (34423s total) loss: 132.139\n",
      "Epoch: [13] [ 2043/10059] total steps:[122751] lr:[0.00005000] time: 14.81s (34438s total) loss: 166.936\n",
      "Epoch: [13] [ 2053/10059] total steps:[122761] lr:[0.00005000] time: 14.78s (34453s total) loss: 140.998\n",
      "Epoch: [13] [ 2063/10059] total steps:[122771] lr:[0.00005000] time: 14.78s (34467s total) loss: 145.430\n",
      "Epoch: [13] [ 2073/10059] total steps:[122781] lr:[0.00005000] time: 14.79s (34482s total) loss: 136.778\n",
      "Epoch: [13] [ 2083/10059] total steps:[122791] lr:[0.00005000] time: 14.79s (34497s total) loss: 171.060\n",
      "Epoch: [13] [ 2093/10059] total steps:[122801] lr:[0.00005000] time: 14.93s (34512s total) loss: 100.340\n",
      "Epoch: [13] [ 2103/10059] total steps:[122811] lr:[0.00005000] time: 14.80s (34527s total) loss: 111.702\n",
      "Epoch: [13] [ 2113/10059] total steps:[122821] lr:[0.00005000] time: 14.87s (34542s total) loss: 168.406\n",
      "Epoch: [13] [ 2123/10059] total steps:[122831] lr:[0.00005000] time: 14.76s (34556s total) loss: 126.325\n",
      "Epoch: [13] [ 2133/10059] total steps:[122841] lr:[0.00005000] time: 14.75s (34571s total) loss: 151.375\n",
      "Epoch: [13] [ 2143/10059] total steps:[122851] lr:[0.00005000] time: 14.76s (34586s total) loss: 120.484\n",
      "Epoch: [13] [ 2153/10059] total steps:[122861] lr:[0.00005000] time: 14.77s (34601s total) loss: 140.360\n",
      "Epoch: [13] [ 2163/10059] total steps:[122871] lr:[0.00005000] time: 14.84s (34616s total) loss: 214.050\n",
      "Epoch: [13] [ 2173/10059] total steps:[122881] lr:[0.00005000] time: 14.74s (34630s total) loss: 125.256\n",
      "Epoch: [13] [ 2183/10059] total steps:[122891] lr:[0.00005000] time: 14.74s (34645s total) loss: 153.517\n",
      "Epoch: [13] [ 2193/10059] total steps:[122901] lr:[0.00005000] time: 14.85s (34660s total) loss: 172.763\n",
      "Epoch: [13] [ 2203/10059] total steps:[122911] lr:[0.00005000] time: 14.82s (34675s total) loss: 155.875\n",
      "Epoch: [13] [ 2213/10059] total steps:[122921] lr:[0.00005000] time: 14.66s (34689s total) loss: 122.389\n",
      "Epoch: [13] [ 2223/10059] total steps:[122931] lr:[0.00005000] time: 14.78s (34704s total) loss: 154.401\n",
      "Epoch: [13] [ 2233/10059] total steps:[122941] lr:[0.00005000] time: 14.82s (34719s total) loss: 146.332\n",
      "Epoch: [13] [ 2243/10059] total steps:[122951] lr:[0.00005000] time: 14.76s (34734s total) loss: 143.254\n",
      "Epoch: [13] [ 2253/10059] total steps:[122961] lr:[0.00005000] time: 14.74s (34748s total) loss: 127.449\n",
      "Epoch: [13] [ 2263/10059] total steps:[122971] lr:[0.00005000] time: 14.76s (34763s total) loss: 135.429\n",
      "Epoch: [13] [ 2273/10059] total steps:[122981] lr:[0.00005000] time: 14.92s (34778s total) loss: 120.863\n",
      "Epoch: [13] [ 2283/10059] total steps:[122991] lr:[0.00005000] time: 14.78s (34793s total) loss: 153.110\n",
      "Epoch: [13] [ 2293/10059] total steps:[123001] lr:[0.00005000] time: 14.84s (34808s total) loss: 118.940\n",
      "Epoch: [13] [ 2303/10059] total steps:[123011] lr:[0.00005000] time: 14.71s (34822s total) loss: 133.027\n",
      "Epoch: [13] [ 2313/10059] total steps:[123021] lr:[0.00005000] time: 14.69s (34837s total) loss: 118.197\n",
      "Epoch: [13] [ 2323/10059] total steps:[123031] lr:[0.00005000] time: 14.68s (34852s total) loss: 129.241\n",
      "Epoch: [13] [ 2333/10059] total steps:[123041] lr:[0.00005000] time: 14.69s (34867s total) loss: 109.168\n",
      "Epoch: [13] [ 2343/10059] total steps:[123051] lr:[0.00005000] time: 14.80s (34881s total) loss: 119.614\n",
      "Epoch: [13] [ 2353/10059] total steps:[123061] lr:[0.00005000] time: 14.71s (34896s total) loss: 104.008\n",
      "Epoch: [13] [ 2363/10059] total steps:[123071] lr:[0.00005000] time: 14.83s (34911s total) loss: 93.531\n",
      "Epoch: [13] [ 2373/10059] total steps:[123081] lr:[0.00005000] time: 14.67s (34926s total) loss: 122.591\n",
      "Epoch: [13] [ 2383/10059] total steps:[123091] lr:[0.00005000] time: 14.85s (34940s total) loss: 146.611\n",
      "Epoch: [13] [ 2393/10059] total steps:[123101] lr:[0.00005000] time: 14.82s (34955s total) loss: 164.093\n",
      "Epoch: [13] [ 2403/10059] total steps:[123111] lr:[0.00005000] time: 14.65s (34970s total) loss: 162.929\n",
      "Epoch: [13] [ 2413/10059] total steps:[123121] lr:[0.00005000] time: 14.82s (34985s total) loss: 200.259\n",
      "Epoch: [13] [ 2423/10059] total steps:[123131] lr:[0.00005000] time: 14.69s (34999s total) loss: 131.692\n",
      "Epoch: [13] [ 2433/10059] total steps:[123141] lr:[0.00005000] time: 14.77s (35014s total) loss: 128.944\n",
      "Epoch: [13] [ 2443/10059] total steps:[123151] lr:[0.00005000] time: 14.77s (35029s total) loss: 143.678\n",
      "Epoch: [13] [ 2453/10059] total steps:[123161] lr:[0.00005000] time: 14.93s (35044s total) loss: 134.887\n",
      "Epoch: [13] [ 2463/10059] total steps:[123171] lr:[0.00005000] time: 14.68s (35058s total) loss: 117.340\n",
      "Epoch: [13] [ 2473/10059] total steps:[123181] lr:[0.00005000] time: 14.83s (35073s total) loss: 106.392\n",
      "Epoch: [13] [ 2483/10059] total steps:[123191] lr:[0.00005000] time: 14.71s (35088s total) loss: 179.597\n",
      "Epoch: [13] [ 2493/10059] total steps:[123201] lr:[0.00005000] time: 14.93s (35103s total) loss: 124.858\n",
      "Epoch: [13] [ 2503/10059] total steps:[123211] lr:[0.00005000] time: 14.86s (35118s total) loss: 138.324\n",
      "Epoch: [13] [ 2513/10059] total steps:[123221] lr:[0.00005000] time: 14.74s (35133s total) loss: 182.705\n",
      "Epoch: [13] [ 2523/10059] total steps:[123231] lr:[0.00005000] time: 14.85s (35147s total) loss: 121.877\n",
      "Epoch: [13] [ 2533/10059] total steps:[123241] lr:[0.00005000] time: 14.82s (35162s total) loss: 123.609\n",
      "Epoch: [13] [ 2543/10059] total steps:[123251] lr:[0.00005000] time: 14.69s (35177s total) loss: 112.142\n",
      "Epoch: [13] [ 2553/10059] total steps:[123261] lr:[0.00005000] time: 14.77s (35192s total) loss: 143.464\n",
      "Epoch: [13] [ 2563/10059] total steps:[123271] lr:[0.00005000] time: 14.76s (35206s total) loss: 144.819\n",
      "Epoch: [13] [ 2573/10059] total steps:[123281] lr:[0.00005000] time: 14.72s (35221s total) loss: 142.573\n",
      "Epoch: [13] [ 2583/10059] total steps:[123291] lr:[0.00005000] time: 14.71s (35236s total) loss: 165.737\n",
      "Epoch: [13] [ 2593/10059] total steps:[123301] lr:[0.00005000] time: 14.71s (35251s total) loss: 167.546\n",
      "Epoch: [13] [ 2603/10059] total steps:[123311] lr:[0.00005000] time: 14.75s (35265s total) loss: 106.884\n",
      "Epoch: [13] [ 2613/10059] total steps:[123321] lr:[0.00005000] time: 14.89s (35280s total) loss: 158.582\n",
      "Epoch: [13] [ 2623/10059] total steps:[123331] lr:[0.00005000] time: 14.87s (35295s total) loss: 103.508\n",
      "Epoch: [13] [ 2633/10059] total steps:[123341] lr:[0.00005000] time: 14.66s (35310s total) loss: 162.423\n",
      "Epoch: [13] [ 2643/10059] total steps:[123351] lr:[0.00005000] time: 14.81s (35325s total) loss: 158.932\n",
      "Epoch: [13] [ 2653/10059] total steps:[123361] lr:[0.00005000] time: 14.89s (35339s total) loss: 89.511\n",
      "Epoch: [13] [ 2663/10059] total steps:[123371] lr:[0.00005000] time: 14.91s (35354s total) loss: 169.642\n",
      "Epoch: [13] [ 2673/10059] total steps:[123381] lr:[0.00005000] time: 14.83s (35369s total) loss: 127.461\n",
      "Epoch: [13] [ 2683/10059] total steps:[123391] lr:[0.00005000] time: 14.77s (35384s total) loss: 111.165\n",
      "Epoch: [13] [ 2693/10059] total steps:[123401] lr:[0.00005000] time: 14.82s (35399s total) loss: 150.424\n",
      "Epoch: [13] [ 2703/10059] total steps:[123411] lr:[0.00005000] time: 14.69s (35413s total) loss: 95.157\n",
      "Epoch: [13] [ 2713/10059] total steps:[123421] lr:[0.00005000] time: 14.87s (35428s total) loss: 107.068\n",
      "Epoch: [13] [ 2723/10059] total steps:[123431] lr:[0.00005000] time: 14.71s (35443s total) loss: 116.107\n",
      "Epoch: [13] [ 2733/10059] total steps:[123441] lr:[0.00005000] time: 14.80s (35458s total) loss: 170.005\n",
      "Epoch: [13] [ 2743/10059] total steps:[123451] lr:[0.00005000] time: 14.68s (35473s total) loss: 153.020\n",
      "Epoch: [13] [ 2753/10059] total steps:[123461] lr:[0.00005000] time: 14.84s (35487s total) loss: 89.738\n",
      "Epoch: [13] [ 2763/10059] total steps:[123471] lr:[0.00005000] time: 14.89s (35502s total) loss: 163.632\n",
      "Epoch: [13] [ 2773/10059] total steps:[123481] lr:[0.00005000] time: 14.83s (35517s total) loss: 144.937\n",
      "Epoch: [13] [ 2783/10059] total steps:[123491] lr:[0.00005000] time: 14.78s (35532s total) loss: 124.321\n",
      "Epoch: [13] [ 2793/10059] total steps:[123501] lr:[0.00005000] time: 14.73s (35547s total) loss: 126.779\n",
      "Epoch: [13] [ 2803/10059] total steps:[123511] lr:[0.00005000] time: 14.73s (35561s total) loss: 136.460\n",
      "Epoch: [13] [ 2813/10059] total steps:[123521] lr:[0.00005000] time: 14.79s (35576s total) loss: 123.959\n",
      "Epoch: [13] [ 2823/10059] total steps:[123531] lr:[0.00005000] time: 14.71s (35591s total) loss: 147.933\n",
      "Epoch: [13] [ 2833/10059] total steps:[123541] lr:[0.00005000] time: 14.74s (35606s total) loss: 160.647\n",
      "Epoch: [13] [ 2843/10059] total steps:[123551] lr:[0.00005000] time: 14.67s (35620s total) loss: 162.836\n",
      "Epoch: [13] [ 2853/10059] total steps:[123561] lr:[0.00005000] time: 14.81s (35635s total) loss: 147.359\n",
      "Epoch: [13] [ 2863/10059] total steps:[123571] lr:[0.00005000] time: 14.82s (35650s total) loss: 111.219\n",
      "Epoch: [13] [ 2873/10059] total steps:[123581] lr:[0.00005000] time: 14.93s (35665s total) loss: 110.827\n",
      "Epoch: [13] [ 2883/10059] total steps:[123591] lr:[0.00005000] time: 14.84s (35680s total) loss: 168.748\n",
      "Epoch: [13] [ 2893/10059] total steps:[123601] lr:[0.00005000] time: 14.83s (35694s total) loss: 146.905\n",
      "Epoch: [13] [ 2903/10059] total steps:[123611] lr:[0.00005000] time: 14.85s (35709s total) loss: 179.263\n",
      "Epoch: [13] [ 2913/10059] total steps:[123621] lr:[0.00005000] time: 14.65s (35724s total) loss: 97.835\n",
      "Epoch: [13] [ 2923/10059] total steps:[123631] lr:[0.00005000] time: 14.82s (35739s total) loss: 127.854\n",
      "Epoch: [13] [ 2933/10059] total steps:[123641] lr:[0.00005000] time: 14.86s (35754s total) loss: 133.448\n",
      "Epoch: [13] [ 2943/10059] total steps:[123651] lr:[0.00005000] time: 14.66s (35768s total) loss: 115.100\n",
      "Epoch: [13] [ 2953/10059] total steps:[123661] lr:[0.00005000] time: 14.86s (35783s total) loss: 132.238\n",
      "Epoch: [13] [ 2963/10059] total steps:[123671] lr:[0.00005000] time: 14.87s (35798s total) loss: 112.050\n",
      "Epoch: [13] [ 2973/10059] total steps:[123681] lr:[0.00005000] time: 14.76s (35813s total) loss: 70.060\n",
      "Epoch: [13] [ 2983/10059] total steps:[123691] lr:[0.00005000] time: 14.80s (35828s total) loss: 160.555\n",
      "Epoch: [13] [ 2993/10059] total steps:[123701] lr:[0.00005000] time: 14.85s (35842s total) loss: 137.767\n",
      "Epoch: [13] [ 3003/10059] total steps:[123711] lr:[0.00005000] time: 14.74s (35857s total) loss: 134.702\n",
      "Epoch: [13] [ 3013/10059] total steps:[123721] lr:[0.00005000] time: 14.80s (35872s total) loss: 122.762\n",
      "Epoch: [13] [ 3023/10059] total steps:[123731] lr:[0.00005000] time: 14.75s (35887s total) loss: 152.898\n",
      "Epoch: [13] [ 3033/10059] total steps:[123741] lr:[0.00005000] time: 14.83s (35902s total) loss: 160.324\n",
      "Epoch: [13] [ 3043/10059] total steps:[123751] lr:[0.00005000] time: 14.80s (35916s total) loss: 92.418\n",
      "Epoch: [13] [ 3053/10059] total steps:[123761] lr:[0.00005000] time: 14.80s (35931s total) loss: 153.511\n",
      "Epoch: [13] [ 3063/10059] total steps:[123771] lr:[0.00005000] time: 14.72s (35946s total) loss: 107.068\n",
      "Epoch: [13] [ 3073/10059] total steps:[123781] lr:[0.00005000] time: 14.82s (35961s total) loss: 165.736\n",
      "Epoch: [13] [ 3083/10059] total steps:[123791] lr:[0.00005000] time: 14.84s (35976s total) loss: 100.527\n",
      "Epoch: [13] [ 3093/10059] total steps:[123801] lr:[0.00005000] time: 14.76s (35990s total) loss: 123.564\n",
      "Epoch: [13] [ 3103/10059] total steps:[123811] lr:[0.00005000] time: 14.88s (36005s total) loss: 160.832\n",
      "Epoch: [13] [ 3113/10059] total steps:[123821] lr:[0.00005000] time: 14.94s (36020s total) loss: 230.658\n",
      "Epoch: [13] [ 3123/10059] total steps:[123831] lr:[0.00005000] time: 14.93s (36035s total) loss: 134.203\n",
      "Epoch: [13] [ 3133/10059] total steps:[123841] lr:[0.00005000] time: 14.78s (36050s total) loss: 157.128\n",
      "Epoch: [13] [ 3143/10059] total steps:[123851] lr:[0.00005000] time: 14.72s (36065s total) loss: 89.803\n",
      "Epoch: [13] [ 3153/10059] total steps:[123861] lr:[0.00005000] time: 14.68s (36079s total) loss: 165.242\n",
      "Epoch: [13] [ 3163/10059] total steps:[123871] lr:[0.00005000] time: 14.82s (36094s total) loss: 146.757\n",
      "Epoch: [13] [ 3173/10059] total steps:[123881] lr:[0.00005000] time: 14.78s (36109s total) loss: 119.053\n",
      "Epoch: [13] [ 3183/10059] total steps:[123891] lr:[0.00005000] time: 14.63s (36123s total) loss: 142.845\n",
      "Epoch: [13] [ 3193/10059] total steps:[123901] lr:[0.00005000] time: 14.94s (36138s total) loss: 101.910\n",
      "Epoch: [13] [ 3203/10059] total steps:[123911] lr:[0.00005000] time: 14.87s (36153s total) loss: 121.880\n",
      "Epoch: [13] [ 3213/10059] total steps:[123921] lr:[0.00005000] time: 14.86s (36168s total) loss: 205.566\n",
      "Epoch: [13] [ 3223/10059] total steps:[123931] lr:[0.00005000] time: 14.78s (36183s total) loss: 100.489\n",
      "Epoch: [13] [ 3233/10059] total steps:[123941] lr:[0.00005000] time: 14.73s (36198s total) loss: 137.528\n",
      "Epoch: [13] [ 3243/10059] total steps:[123951] lr:[0.00005000] time: 14.87s (36213s total) loss: 142.271\n",
      "Epoch: [13] [ 3253/10059] total steps:[123961] lr:[0.00005000] time: 16.61s (36229s total) loss: 87.352\n",
      "Epoch: [13] [ 3263/10059] total steps:[123971] lr:[0.00005000] time: 14.84s (36244s total) loss: 158.268\n",
      "Epoch: [13] [ 3273/10059] total steps:[123981] lr:[0.00005000] time: 14.76s (36259s total) loss: 170.357\n",
      "Epoch: [13] [ 3283/10059] total steps:[123991] lr:[0.00005000] time: 14.83s (36274s total) loss: 107.521\n",
      "Epoch: [13] [ 3293/10059] total steps:[124001] lr:[0.00005000] time: 14.79s (36288s total) loss: 123.310\n",
      "Epoch: [13] [ 3303/10059] total steps:[124011] lr:[0.00005000] time: 14.68s (36303s total) loss: 102.661\n",
      "Epoch: [13] [ 3313/10059] total steps:[124021] lr:[0.00005000] time: 14.90s (36318s total) loss: 149.420\n",
      "Epoch: [13] [ 3323/10059] total steps:[124031] lr:[0.00005000] time: 14.78s (36333s total) loss: 115.150\n",
      "Epoch: [13] [ 3333/10059] total steps:[124041] lr:[0.00005000] time: 14.90s (36348s total) loss: 113.725\n",
      "Epoch: [13] [ 3343/10059] total steps:[124051] lr:[0.00005000] time: 15.05s (36363s total) loss: 104.161\n",
      "Epoch: [13] [ 3353/10059] total steps:[124061] lr:[0.00005000] time: 14.78s (36377s total) loss: 148.599\n",
      "Epoch: [13] [ 3363/10059] total steps:[124071] lr:[0.00005000] time: 14.86s (36392s total) loss: 147.631\n",
      "Epoch: [13] [ 3373/10059] total steps:[124081] lr:[0.00005000] time: 14.88s (36407s total) loss: 116.838\n",
      "Epoch: [13] [ 3383/10059] total steps:[124091] lr:[0.00005000] time: 14.72s (36422s total) loss: 163.349\n",
      "Epoch: [13] [ 3393/10059] total steps:[124101] lr:[0.00005000] time: 14.77s (36437s total) loss: 119.986\n",
      "Epoch: [13] [ 3403/10059] total steps:[124111] lr:[0.00005000] time: 14.73s (36451s total) loss: 171.481\n",
      "Epoch: [13] [ 3413/10059] total steps:[124121] lr:[0.00005000] time: 14.94s (36466s total) loss: 173.936\n",
      "Epoch: [13] [ 3423/10059] total steps:[124131] lr:[0.00005000] time: 14.80s (36481s total) loss: 157.961\n",
      "Epoch: [13] [ 3433/10059] total steps:[124141] lr:[0.00005000] time: 14.80s (36496s total) loss: 115.972\n",
      "Epoch: [13] [ 3443/10059] total steps:[124151] lr:[0.00005000] time: 14.78s (36511s total) loss: 117.397\n",
      "Epoch: [13] [ 3453/10059] total steps:[124161] lr:[0.00005000] time: 14.74s (36525s total) loss: 161.718\n",
      "Epoch: [13] [ 3463/10059] total steps:[124171] lr:[0.00005000] time: 14.85s (36540s total) loss: 178.601\n",
      "Epoch: [13] [ 3473/10059] total steps:[124181] lr:[0.00005000] time: 14.85s (36555s total) loss: 108.238\n",
      "Epoch: [13] [ 3483/10059] total steps:[124191] lr:[0.00005000] time: 14.73s (36570s total) loss: 159.510\n",
      "Epoch: [13] [ 3493/10059] total steps:[124201] lr:[0.00005000] time: 14.80s (36585s total) loss: 101.402\n",
      "Epoch: [13] [ 3503/10059] total steps:[124211] lr:[0.00005000] time: 14.90s (36600s total) loss: 94.449\n",
      "Epoch: [13] [ 3513/10059] total steps:[124221] lr:[0.00005000] time: 14.76s (36614s total) loss: 109.026\n",
      "Epoch: [13] [ 3523/10059] total steps:[124231] lr:[0.00005000] time: 14.70s (36629s total) loss: 121.671\n",
      "Epoch: [13] [ 3533/10059] total steps:[124241] lr:[0.00005000] time: 14.70s (36644s total) loss: 174.701\n",
      "Epoch: [13] [ 3543/10059] total steps:[124251] lr:[0.00005000] time: 14.70s (36658s total) loss: 141.553\n",
      "Epoch: [13] [ 3553/10059] total steps:[124261] lr:[0.00005000] time: 14.78s (36673s total) loss: 116.749\n",
      "Epoch: [13] [ 3563/10059] total steps:[124271] lr:[0.00005000] time: 14.82s (36688s total) loss: 170.281\n",
      "Epoch: [13] [ 3573/10059] total steps:[124281] lr:[0.00005000] time: 14.78s (36703s total) loss: 139.550\n",
      "Epoch: [13] [ 3583/10059] total steps:[124291] lr:[0.00005000] time: 14.95s (36718s total) loss: 98.595\n",
      "Epoch: [13] [ 3593/10059] total steps:[124301] lr:[0.00005000] time: 14.82s (36733s total) loss: 162.209\n",
      "Epoch: [13] [ 3603/10059] total steps:[124311] lr:[0.00005000] time: 14.86s (36747s total) loss: 209.518\n",
      "Epoch: [13] [ 3613/10059] total steps:[124321] lr:[0.00005000] time: 14.89s (36762s total) loss: 109.301\n",
      "Epoch: [13] [ 3623/10059] total steps:[124331] lr:[0.00005000] time: 14.70s (36777s total) loss: 125.592\n",
      "Epoch: [13] [ 3633/10059] total steps:[124341] lr:[0.00005000] time: 14.76s (36792s total) loss: 124.363\n",
      "Epoch: [13] [ 3643/10059] total steps:[124351] lr:[0.00005000] time: 14.79s (36807s total) loss: 124.077\n",
      "Epoch: [13] [ 3653/10059] total steps:[124361] lr:[0.00005000] time: 14.72s (36821s total) loss: 155.883\n",
      "Epoch: [13] [ 3663/10059] total steps:[124371] lr:[0.00005000] time: 14.78s (36836s total) loss: 128.677\n",
      "Epoch: [13] [ 3673/10059] total steps:[124381] lr:[0.00005000] time: 14.69s (36851s total) loss: 126.036\n",
      "Epoch: [13] [ 3683/10059] total steps:[124391] lr:[0.00005000] time: 14.69s (36865s total) loss: 192.083\n",
      "Epoch: [13] [ 3693/10059] total steps:[124401] lr:[0.00005000] time: 14.76s (36880s total) loss: 122.218\n",
      "Epoch: [13] [ 3703/10059] total steps:[124411] lr:[0.00005000] time: 14.75s (36895s total) loss: 135.971\n",
      "Epoch: [13] [ 3713/10059] total steps:[124421] lr:[0.00005000] time: 14.82s (36910s total) loss: 135.393\n",
      "Epoch: [13] [ 3723/10059] total steps:[124431] lr:[0.00005000] time: 14.73s (36925s total) loss: 116.208\n",
      "Epoch: [13] [ 3733/10059] total steps:[124441] lr:[0.00005000] time: 14.81s (36939s total) loss: 105.368\n",
      "Epoch: [13] [ 3743/10059] total steps:[124451] lr:[0.00005000] time: 14.79s (36954s total) loss: 159.452\n",
      "Epoch: [13] [ 3753/10059] total steps:[124461] lr:[0.00005000] time: 14.83s (36969s total) loss: 133.325\n",
      "Epoch: [13] [ 3763/10059] total steps:[124471] lr:[0.00005000] time: 14.79s (36984s total) loss: 159.256\n",
      "Epoch: [13] [ 3773/10059] total steps:[124481] lr:[0.00005000] time: 14.78s (36999s total) loss: 143.146\n",
      "Epoch: [13] [ 3783/10059] total steps:[124491] lr:[0.00005000] time: 14.78s (37013s total) loss: 148.109\n",
      "Epoch: [13] [ 3793/10059] total steps:[124501] lr:[0.00005000] time: 14.83s (37028s total) loss: 129.486\n",
      "Epoch: [13] [ 3803/10059] total steps:[124511] lr:[0.00005000] time: 14.97s (37043s total) loss: 134.205\n",
      "Epoch: [13] [ 3813/10059] total steps:[124521] lr:[0.00005000] time: 14.71s (37058s total) loss: 132.420\n",
      "Epoch: [13] [ 3823/10059] total steps:[124531] lr:[0.00005000] time: 14.78s (37073s total) loss: 150.592\n",
      "Epoch: [13] [ 3833/10059] total steps:[124541] lr:[0.00005000] time: 14.86s (37087s total) loss: 129.782\n",
      "Epoch: [13] [ 3843/10059] total steps:[124551] lr:[0.00005000] time: 14.64s (37102s total) loss: 173.429\n",
      "Epoch: [13] [ 3853/10059] total steps:[124561] lr:[0.00005000] time: 14.73s (37117s total) loss: 146.665\n",
      "Epoch: [13] [ 3863/10059] total steps:[124571] lr:[0.00005000] time: 14.77s (37132s total) loss: 127.455\n",
      "Epoch: [13] [ 3873/10059] total steps:[124581] lr:[0.00005000] time: 14.72s (37146s total) loss: 174.004\n",
      "Epoch: [13] [ 3883/10059] total steps:[124591] lr:[0.00005000] time: 14.81s (37161s total) loss: 111.960\n",
      "Epoch: [13] [ 3893/10059] total steps:[124601] lr:[0.00005000] time: 14.97s (37176s total) loss: 107.752\n",
      "Epoch: [13] [ 3903/10059] total steps:[124611] lr:[0.00005000] time: 14.84s (37191s total) loss: 95.766\n",
      "Epoch: [13] [ 3913/10059] total steps:[124621] lr:[0.00005000] time: 14.70s (37206s total) loss: 97.486\n",
      "Epoch: [13] [ 3923/10059] total steps:[124631] lr:[0.00005000] time: 14.68s (37220s total) loss: 158.995\n",
      "Epoch: [13] [ 3933/10059] total steps:[124641] lr:[0.00005000] time: 14.83s (37235s total) loss: 89.516\n",
      "Epoch: [13] [ 3943/10059] total steps:[124651] lr:[0.00005000] time: 14.85s (37250s total) loss: 159.533\n",
      "Epoch: [13] [ 3953/10059] total steps:[124661] lr:[0.00005000] time: 14.75s (37265s total) loss: 164.124\n",
      "Epoch: [13] [ 3963/10059] total steps:[124671] lr:[0.00005000] time: 14.68s (37279s total) loss: 129.550\n",
      "Epoch: [13] [ 3973/10059] total steps:[124681] lr:[0.00005000] time: 14.97s (37294s total) loss: 105.836\n",
      "Epoch: [13] [ 3983/10059] total steps:[124691] lr:[0.00005000] time: 14.75s (37309s total) loss: 101.014\n",
      "Epoch: [13] [ 3993/10059] total steps:[124701] lr:[0.00005000] time: 14.67s (37324s total) loss: 137.960\n",
      "Epoch: [13] [ 4003/10059] total steps:[124711] lr:[0.00005000] time: 14.68s (37338s total) loss: 150.846\n",
      "Epoch: [13] [ 4013/10059] total steps:[124721] lr:[0.00005000] time: 14.71s (37353s total) loss: 198.901\n",
      "Epoch: [13] [ 4023/10059] total steps:[124731] lr:[0.00005000] time: 14.76s (37368s total) loss: 97.921\n",
      "Epoch: [13] [ 4033/10059] total steps:[124741] lr:[0.00005000] time: 14.82s (37383s total) loss: 186.858\n",
      "Epoch: [13] [ 4043/10059] total steps:[124751] lr:[0.00005000] time: 14.82s (37398s total) loss: 155.272\n",
      "Epoch: [13] [ 4053/10059] total steps:[124761] lr:[0.00005000] time: 14.76s (37412s total) loss: 98.766\n",
      "Epoch: [13] [ 4063/10059] total steps:[124771] lr:[0.00005000] time: 14.74s (37427s total) loss: 156.582\n",
      "Epoch: [13] [ 4073/10059] total steps:[124781] lr:[0.00005000] time: 14.67s (37442s total) loss: 139.754\n",
      "Epoch: [13] [ 4083/10059] total steps:[124791] lr:[0.00005000] time: 14.79s (37457s total) loss: 161.483\n",
      "Epoch: [13] [ 4093/10059] total steps:[124801] lr:[0.00005000] time: 14.88s (37471s total) loss: 155.135\n",
      "Epoch: [13] [ 4103/10059] total steps:[124811] lr:[0.00005000] time: 14.74s (37486s total) loss: 125.417\n",
      "Epoch: [13] [ 4113/10059] total steps:[124821] lr:[0.00005000] time: 14.80s (37501s total) loss: 116.736\n",
      "Epoch: [13] [ 4123/10059] total steps:[124831] lr:[0.00005000] time: 14.82s (37516s total) loss: 128.365\n",
      "Epoch: [13] [ 4133/10059] total steps:[124841] lr:[0.00005000] time: 14.80s (37531s total) loss: 125.536\n",
      "Epoch: [13] [ 4143/10059] total steps:[124851] lr:[0.00005000] time: 14.71s (37545s total) loss: 96.741\n",
      "Epoch: [13] [ 4153/10059] total steps:[124861] lr:[0.00005000] time: 14.84s (37560s total) loss: 138.868\n",
      "Epoch: [13] [ 4163/10059] total steps:[124871] lr:[0.00005000] time: 14.76s (37575s total) loss: 195.384\n",
      "Epoch: [13] [ 4173/10059] total steps:[124881] lr:[0.00005000] time: 14.83s (37590s total) loss: 115.418\n",
      "Epoch: [13] [ 4183/10059] total steps:[124891] lr:[0.00005000] time: 14.72s (37604s total) loss: 120.692\n",
      "Epoch: [13] [ 4193/10059] total steps:[124901] lr:[0.00005000] time: 14.78s (37619s total) loss: 112.785\n",
      "Epoch: [13] [ 4203/10059] total steps:[124911] lr:[0.00005000] time: 14.81s (37634s total) loss: 139.739\n",
      "Epoch: [13] [ 4213/10059] total steps:[124921] lr:[0.00005000] time: 14.74s (37649s total) loss: 120.978\n",
      "Epoch: [13] [ 4223/10059] total steps:[124931] lr:[0.00005000] time: 14.89s (37664s total) loss: 165.490\n",
      "Epoch: [13] [ 4233/10059] total steps:[124941] lr:[0.00005000] time: 14.77s (37678s total) loss: 137.106\n",
      "Epoch: [13] [ 4243/10059] total steps:[124951] lr:[0.00005000] time: 14.84s (37693s total) loss: 140.314\n",
      "Epoch: [13] [ 4253/10059] total steps:[124961] lr:[0.00005000] time: 14.77s (37708s total) loss: 163.140\n",
      "Epoch: [13] [ 4263/10059] total steps:[124971] lr:[0.00005000] time: 14.85s (37723s total) loss: 148.053\n",
      "Epoch: [13] [ 4273/10059] total steps:[124981] lr:[0.00005000] time: 14.83s (37738s total) loss: 127.476\n",
      "Epoch: [13] [ 4283/10059] total steps:[124991] lr:[0.00005000] time: 14.77s (37753s total) loss: 141.371\n",
      "Epoch: [13] [ 4293/10059] total steps:[125001] lr:[0.00005000] time: 14.81s (37767s total) loss: 178.954\n",
      "Epoch: [13] [ 4303/10059] total steps:[125011] lr:[0.00005000] time: 14.75s (37782s total) loss: 155.606\n",
      "Epoch: [13] [ 4313/10059] total steps:[125021] lr:[0.00005000] time: 14.80s (37797s total) loss: 180.875\n",
      "Epoch: [13] [ 4323/10059] total steps:[125031] lr:[0.00005000] time: 15.04s (37812s total) loss: 151.477\n",
      "Epoch: [13] [ 4333/10059] total steps:[125041] lr:[0.00005000] time: 14.76s (37827s total) loss: 114.877\n",
      "Epoch: [13] [ 4343/10059] total steps:[125051] lr:[0.00005000] time: 14.87s (37842s total) loss: 167.692\n",
      "Epoch: [13] [ 4353/10059] total steps:[125061] lr:[0.00005000] time: 14.73s (37856s total) loss: 113.645\n",
      "Epoch: [13] [ 4363/10059] total steps:[125071] lr:[0.00005000] time: 14.72s (37871s total) loss: 126.747\n",
      "Epoch: [13] [ 4373/10059] total steps:[125081] lr:[0.00005000] time: 14.78s (37886s total) loss: 151.262\n",
      "Epoch: [13] [ 4383/10059] total steps:[125091] lr:[0.00005000] time: 14.83s (37901s total) loss: 109.435\n",
      "Epoch: [13] [ 4393/10059] total steps:[125101] lr:[0.00005000] time: 14.81s (37915s total) loss: 154.229\n",
      "Epoch: [13] [ 4403/10059] total steps:[125111] lr:[0.00005000] time: 14.82s (37930s total) loss: 87.352\n",
      "Epoch: [13] [ 4413/10059] total steps:[125121] lr:[0.00005000] time: 14.87s (37945s total) loss: 170.110\n",
      "Epoch: [13] [ 4423/10059] total steps:[125131] lr:[0.00005000] time: 14.76s (37960s total) loss: 145.678\n",
      "Epoch: [13] [ 4433/10059] total steps:[125141] lr:[0.00005000] time: 14.63s (37974s total) loss: 103.154\n",
      "Epoch: [13] [ 4443/10059] total steps:[125151] lr:[0.00005000] time: 14.89s (37989s total) loss: 138.025\n",
      "Epoch: [13] [ 4453/10059] total steps:[125161] lr:[0.00005000] time: 14.85s (38004s total) loss: 164.313\n",
      "Epoch: [13] [ 4463/10059] total steps:[125171] lr:[0.00005000] time: 14.66s (38019s total) loss: 153.053\n",
      "Epoch: [13] [ 4473/10059] total steps:[125181] lr:[0.00005000] time: 14.75s (38034s total) loss: 150.652\n",
      "Epoch: [13] [ 4483/10059] total steps:[125191] lr:[0.00005000] time: 14.70s (38048s total) loss: 143.624\n",
      "Epoch: [13] [ 4493/10059] total steps:[125201] lr:[0.00005000] time: 14.82s (38063s total) loss: 104.664\n",
      "Epoch: [13] [ 4503/10059] total steps:[125211] lr:[0.00005000] time: 14.84s (38078s total) loss: 158.981\n",
      "Epoch: [13] [ 4513/10059] total steps:[125221] lr:[0.00005000] time: 14.81s (38093s total) loss: 130.603\n",
      "Epoch: [13] [ 4523/10059] total steps:[125231] lr:[0.00005000] time: 14.94s (38108s total) loss: 140.905\n",
      "Epoch: [13] [ 4533/10059] total steps:[125241] lr:[0.00005000] time: 14.74s (38122s total) loss: 105.306\n",
      "Epoch: [13] [ 4543/10059] total steps:[125251] lr:[0.00005000] time: 14.78s (38137s total) loss: 99.307\n",
      "Epoch: [13] [ 4553/10059] total steps:[125261] lr:[0.00005000] time: 14.70s (38152s total) loss: 122.599\n",
      "Epoch: [13] [ 4563/10059] total steps:[125271] lr:[0.00005000] time: 14.80s (38167s total) loss: 124.843\n",
      "Epoch: [13] [ 4573/10059] total steps:[125281] lr:[0.00005000] time: 14.89s (38182s total) loss: 156.146\n",
      "Epoch: [13] [ 4583/10059] total steps:[125291] lr:[0.00005000] time: 14.84s (38196s total) loss: 125.971\n",
      "Epoch: [13] [ 4593/10059] total steps:[125301] lr:[0.00005000] time: 14.81s (38211s total) loss: 131.960\n",
      "Epoch: [13] [ 4603/10059] total steps:[125311] lr:[0.00005000] time: 14.84s (38226s total) loss: 92.287\n",
      "Epoch: [13] [ 4613/10059] total steps:[125321] lr:[0.00005000] time: 14.76s (38241s total) loss: 141.807\n",
      "Epoch: [13] [ 4623/10059] total steps:[125331] lr:[0.00005000] time: 14.79s (38256s total) loss: 132.031\n",
      "Epoch: [13] [ 4633/10059] total steps:[125341] lr:[0.00005000] time: 14.77s (38270s total) loss: 99.611\n",
      "Epoch: [13] [ 4643/10059] total steps:[125351] lr:[0.00005000] time: 14.74s (38285s total) loss: 105.374\n",
      "Epoch: [13] [ 4653/10059] total steps:[125361] lr:[0.00005000] time: 14.83s (38300s total) loss: 94.971\n",
      "Epoch: [13] [ 4663/10059] total steps:[125371] lr:[0.00005000] time: 14.77s (38315s total) loss: 158.397\n",
      "Epoch: [13] [ 4673/10059] total steps:[125381] lr:[0.00005000] time: 14.76s (38330s total) loss: 133.674\n",
      "Epoch: [13] [ 4683/10059] total steps:[125391] lr:[0.00005000] time: 14.75s (38344s total) loss: 113.230\n",
      "Epoch: [13] [ 4693/10059] total steps:[125401] lr:[0.00005000] time: 14.85s (38359s total) loss: 115.734\n",
      "Epoch: [13] [ 4703/10059] total steps:[125411] lr:[0.00005000] time: 14.90s (38374s total) loss: 107.356\n",
      "Epoch: [13] [ 4713/10059] total steps:[125421] lr:[0.00005000] time: 14.76s (38389s total) loss: 126.886\n",
      "Epoch: [13] [ 4723/10059] total steps:[125431] lr:[0.00005000] time: 14.72s (38404s total) loss: 130.142\n",
      "Epoch: [13] [ 4733/10059] total steps:[125441] lr:[0.00005000] time: 14.76s (38418s total) loss: 137.173\n",
      "Epoch: [13] [ 4743/10059] total steps:[125451] lr:[0.00005000] time: 14.89s (38433s total) loss: 120.280\n",
      "Epoch: [13] [ 4753/10059] total steps:[125461] lr:[0.00005000] time: 14.81s (38448s total) loss: 103.703\n",
      "Epoch: [13] [ 4763/10059] total steps:[125471] lr:[0.00005000] time: 14.66s (38463s total) loss: 127.931\n",
      "Epoch: [13] [ 4773/10059] total steps:[125481] lr:[0.00005000] time: 14.71s (38477s total) loss: 145.604\n",
      "Epoch: [13] [ 4783/10059] total steps:[125491] lr:[0.00005000] time: 14.79s (38492s total) loss: 96.756\n",
      "Epoch: [13] [ 4793/10059] total steps:[125501] lr:[0.00005000] time: 14.82s (38507s total) loss: 153.180\n",
      "Epoch: [13] [ 4803/10059] total steps:[125511] lr:[0.00005000] time: 14.80s (38522s total) loss: 135.632\n",
      "Epoch: [13] [ 4813/10059] total steps:[125521] lr:[0.00005000] time: 14.94s (38537s total) loss: 200.191\n",
      "Epoch: [13] [ 4823/10059] total steps:[125531] lr:[0.00005000] time: 14.80s (38552s total) loss: 90.234\n",
      "Epoch: [13] [ 4833/10059] total steps:[125541] lr:[0.00005000] time: 14.88s (38566s total) loss: 148.142\n",
      "Epoch: [13] [ 4843/10059] total steps:[125551] lr:[0.00005000] time: 14.74s (38581s total) loss: 119.499\n",
      "Epoch: [13] [ 4853/10059] total steps:[125561] lr:[0.00005000] time: 14.91s (38596s total) loss: 125.050\n",
      "Epoch: [13] [ 4863/10059] total steps:[125571] lr:[0.00005000] time: 14.87s (38611s total) loss: 124.660\n",
      "Epoch: [13] [ 4873/10059] total steps:[125581] lr:[0.00005000] time: 14.74s (38626s total) loss: 105.855\n",
      "Epoch: [13] [ 4883/10059] total steps:[125591] lr:[0.00005000] time: 14.86s (38641s total) loss: 122.486\n",
      "Epoch: [13] [ 4893/10059] total steps:[125601] lr:[0.00005000] time: 14.84s (38655s total) loss: 131.833\n",
      "Epoch: [13] [ 4903/10059] total steps:[125611] lr:[0.00005000] time: 14.76s (38670s total) loss: 186.848\n",
      "Epoch: [13] [ 4913/10059] total steps:[125621] lr:[0.00005000] time: 14.86s (38685s total) loss: 104.759\n",
      "Epoch: [13] [ 4923/10059] total steps:[125631] lr:[0.00005000] time: 14.91s (38700s total) loss: 124.839\n",
      "Epoch: [13] [ 4933/10059] total steps:[125641] lr:[0.00005000] time: 14.76s (38715s total) loss: 127.044\n",
      "Epoch: [13] [ 4943/10059] total steps:[125651] lr:[0.00005000] time: 14.85s (38729s total) loss: 121.264\n",
      "Epoch: [13] [ 4953/10059] total steps:[125661] lr:[0.00005000] time: 14.73s (38744s total) loss: 116.354\n",
      "Epoch: [13] [ 4963/10059] total steps:[125671] lr:[0.00005000] time: 14.88s (38759s total) loss: 104.708\n",
      "Epoch: [13] [ 4973/10059] total steps:[125681] lr:[0.00005000] time: 14.75s (38774s total) loss: 117.294\n",
      "Epoch: [13] [ 4983/10059] total steps:[125691] lr:[0.00005000] time: 14.86s (38789s total) loss: 121.651\n",
      "Epoch: [13] [ 4993/10059] total steps:[125701] lr:[0.00005000] time: 14.88s (38804s total) loss: 115.298\n",
      "Epoch: [13] [ 5003/10059] total steps:[125711] lr:[0.00005000] time: 14.85s (38818s total) loss: 132.347\n",
      "Epoch: [13] [ 5013/10059] total steps:[125721] lr:[0.00005000] time: 14.83s (38833s total) loss: 101.360\n",
      "Epoch: [13] [ 5023/10059] total steps:[125731] lr:[0.00005000] time: 14.67s (38848s total) loss: 172.479\n",
      "Epoch: [13] [ 5033/10059] total steps:[125741] lr:[0.00005000] time: 14.76s (38863s total) loss: 157.353\n",
      "Epoch: [13] [ 5043/10059] total steps:[125751] lr:[0.00005000] time: 14.80s (38878s total) loss: 136.663\n",
      "Epoch: [13] [ 5053/10059] total steps:[125761] lr:[0.00005000] time: 14.75s (38892s total) loss: 161.406\n",
      "Epoch: [13] [ 5063/10059] total steps:[125771] lr:[0.00005000] time: 14.73s (38907s total) loss: 133.893\n",
      "Epoch: [13] [ 5073/10059] total steps:[125781] lr:[0.00005000] time: 14.76s (38922s total) loss: 103.856\n",
      "Epoch: [13] [ 5083/10059] total steps:[125791] lr:[0.00005000] time: 14.74s (38937s total) loss: 122.546\n",
      "Epoch: [13] [ 5093/10059] total steps:[125801] lr:[0.00005000] time: 14.88s (38951s total) loss: 153.253\n",
      "Epoch: [13] [ 5103/10059] total steps:[125811] lr:[0.00005000] time: 14.82s (38966s total) loss: 105.442\n",
      "Epoch: [13] [ 5113/10059] total steps:[125821] lr:[0.00005000] time: 14.78s (38981s total) loss: 101.365\n",
      "Epoch: [13] [ 5123/10059] total steps:[125831] lr:[0.00005000] time: 14.82s (38996s total) loss: 162.921\n",
      "Epoch: [13] [ 5133/10059] total steps:[125841] lr:[0.00005000] time: 14.94s (39011s total) loss: 127.174\n",
      "Epoch: [13] [ 5143/10059] total steps:[125851] lr:[0.00005000] time: 14.81s (39026s total) loss: 180.536\n",
      "Epoch: [13] [ 5153/10059] total steps:[125861] lr:[0.00005000] time: 14.75s (39040s total) loss: 125.914\n",
      "Epoch: [13] [ 5163/10059] total steps:[125871] lr:[0.00005000] time: 14.87s (39055s total) loss: 102.669\n",
      "Epoch: [13] [ 5173/10059] total steps:[125881] lr:[0.00005000] time: 14.82s (39070s total) loss: 161.181\n",
      "Epoch: [13] [ 5183/10059] total steps:[125891] lr:[0.00005000] time: 14.77s (39085s total) loss: 168.902\n",
      "Epoch: [13] [ 5193/10059] total steps:[125901] lr:[0.00005000] time: 14.81s (39100s total) loss: 150.101\n",
      "Epoch: [13] [ 5203/10059] total steps:[125911] lr:[0.00005000] time: 14.80s (39114s total) loss: 91.640\n",
      "Epoch: [13] [ 5213/10059] total steps:[125921] lr:[0.00005000] time: 14.85s (39129s total) loss: 164.914\n",
      "Epoch: [13] [ 5223/10059] total steps:[125931] lr:[0.00005000] time: 14.73s (39144s total) loss: 135.744\n",
      "Epoch: [13] [ 5233/10059] total steps:[125941] lr:[0.00005000] time: 14.72s (39159s total) loss: 162.247\n",
      "Epoch: [13] [ 5243/10059] total steps:[125951] lr:[0.00005000] time: 14.75s (39173s total) loss: 165.293\n",
      "Epoch: [13] [ 5253/10059] total steps:[125961] lr:[0.00005000] time: 14.77s (39188s total) loss: 171.158\n",
      "Epoch: [13] [ 5263/10059] total steps:[125971] lr:[0.00005000] time: 14.80s (39203s total) loss: 104.608\n",
      "Epoch: [13] [ 5273/10059] total steps:[125981] lr:[0.00005000] time: 14.91s (39218s total) loss: 158.570\n",
      "Epoch: [13] [ 5283/10059] total steps:[125991] lr:[0.00005000] time: 14.82s (39233s total) loss: 138.316\n",
      "Epoch: [13] [ 5293/10059] total steps:[126001] lr:[0.00005000] time: 14.88s (39248s total) loss: 170.160\n",
      "Epoch: [13] [ 5303/10059] total steps:[126011] lr:[0.00005000] time: 14.79s (39262s total) loss: 118.091\n",
      "Epoch: [13] [ 5313/10059] total steps:[126021] lr:[0.00005000] time: 14.78s (39277s total) loss: 153.440\n",
      "Epoch: [13] [ 5323/10059] total steps:[126031] lr:[0.00005000] time: 14.80s (39292s total) loss: 115.686\n",
      "Epoch: [13] [ 5333/10059] total steps:[126041] lr:[0.00005000] time: 14.86s (39307s total) loss: 81.443\n",
      "Epoch: [13] [ 5343/10059] total steps:[126051] lr:[0.00005000] time: 14.84s (39322s total) loss: 122.090\n",
      "Epoch: [13] [ 5353/10059] total steps:[126061] lr:[0.00005000] time: 14.83s (39337s total) loss: 106.724\n",
      "Epoch: [13] [ 5363/10059] total steps:[126071] lr:[0.00005000] time: 14.80s (39351s total) loss: 175.062\n",
      "Epoch: [13] [ 5373/10059] total steps:[126081] lr:[0.00005000] time: 14.71s (39366s total) loss: 111.832\n",
      "Epoch: [13] [ 5383/10059] total steps:[126091] lr:[0.00005000] time: 14.79s (39381s total) loss: 160.986\n",
      "Epoch: [13] [ 5393/10059] total steps:[126101] lr:[0.00005000] time: 14.83s (39396s total) loss: 113.558\n",
      "Epoch: [13] [ 5403/10059] total steps:[126111] lr:[0.00005000] time: 14.73s (39410s total) loss: 87.741\n",
      "Epoch: [13] [ 5413/10059] total steps:[126121] lr:[0.00005000] time: 14.79s (39425s total) loss: 119.544\n",
      "Epoch: [13] [ 5423/10059] total steps:[126131] lr:[0.00005000] time: 14.81s (39440s total) loss: 112.123\n",
      "Epoch: [13] [ 5433/10059] total steps:[126141] lr:[0.00005000] time: 14.93s (39455s total) loss: 154.286\n",
      "Epoch: [13] [ 5443/10059] total steps:[126151] lr:[0.00005000] time: 14.80s (39470s total) loss: 119.058\n",
      "Epoch: [13] [ 5453/10059] total steps:[126161] lr:[0.00005000] time: 14.72s (39484s total) loss: 108.125\n",
      "Epoch: [13] [ 5463/10059] total steps:[126171] lr:[0.00005000] time: 14.86s (39499s total) loss: 92.097\n",
      "Epoch: [13] [ 5473/10059] total steps:[126181] lr:[0.00005000] time: 14.70s (39514s total) loss: 164.886\n",
      "Epoch: [13] [ 5483/10059] total steps:[126191] lr:[0.00005000] time: 14.77s (39529s total) loss: 150.201\n",
      "Epoch: [13] [ 5493/10059] total steps:[126201] lr:[0.00005000] time: 14.90s (39544s total) loss: 89.185\n",
      "Epoch: [13] [ 5503/10059] total steps:[126211] lr:[0.00005000] time: 14.71s (39558s total) loss: 120.012\n",
      "Epoch: [13] [ 5513/10059] total steps:[126221] lr:[0.00005000] time: 14.82s (39573s total) loss: 148.597\n",
      "Epoch: [13] [ 5523/10059] total steps:[126231] lr:[0.00005000] time: 14.82s (39588s total) loss: 138.215\n",
      "Epoch: [13] [ 5533/10059] total steps:[126241] lr:[0.00005000] time: 14.87s (39603s total) loss: 88.501\n",
      "Epoch: [13] [ 5543/10059] total steps:[126251] lr:[0.00005000] time: 14.73s (39618s total) loss: 150.520\n",
      "Epoch: [13] [ 5553/10059] total steps:[126261] lr:[0.00005000] time: 14.76s (39632s total) loss: 134.279\n",
      "Epoch: [13] [ 5563/10059] total steps:[126271] lr:[0.00005000] time: 14.91s (39647s total) loss: 178.120\n",
      "Epoch: [13] [ 5573/10059] total steps:[126281] lr:[0.00005000] time: 14.80s (39662s total) loss: 137.963\n",
      "Epoch: [13] [ 5583/10059] total steps:[126291] lr:[0.00005000] time: 14.89s (39677s total) loss: 182.325\n",
      "Epoch: [13] [ 5593/10059] total steps:[126301] lr:[0.00005000] time: 14.84s (39692s total) loss: 141.260\n",
      "Epoch: [13] [ 5603/10059] total steps:[126311] lr:[0.00005000] time: 14.78s (39707s total) loss: 190.963\n",
      "Epoch: [13] [ 5613/10059] total steps:[126321] lr:[0.00005000] time: 14.78s (39721s total) loss: 152.005\n",
      "Epoch: [13] [ 5623/10059] total steps:[126331] lr:[0.00005000] time: 14.90s (39736s total) loss: 138.298\n",
      "Epoch: [13] [ 5633/10059] total steps:[126341] lr:[0.00005000] time: 14.78s (39751s total) loss: 158.894\n",
      "Epoch: [13] [ 5643/10059] total steps:[126351] lr:[0.00005000] time: 14.71s (39766s total) loss: 120.664\n",
      "Epoch: [13] [ 5653/10059] total steps:[126361] lr:[0.00005000] time: 14.94s (39781s total) loss: 142.301\n",
      "Epoch: [13] [ 5663/10059] total steps:[126371] lr:[0.00005000] time: 14.85s (39796s total) loss: 123.327\n",
      "Epoch: [13] [ 5673/10059] total steps:[126381] lr:[0.00005000] time: 14.92s (39810s total) loss: 109.627\n",
      "Epoch: [13] [ 5683/10059] total steps:[126391] lr:[0.00005000] time: 14.73s (39825s total) loss: 151.482\n",
      "Epoch: [13] [ 5693/10059] total steps:[126401] lr:[0.00005000] time: 14.76s (39840s total) loss: 160.615\n",
      "Epoch: [13] [ 5703/10059] total steps:[126411] lr:[0.00005000] time: 14.85s (39855s total) loss: 123.273\n",
      "Epoch: [13] [ 5713/10059] total steps:[126421] lr:[0.00005000] time: 14.75s (39870s total) loss: 126.442\n",
      "Epoch: [13] [ 5723/10059] total steps:[126431] lr:[0.00005000] time: 14.84s (39884s total) loss: 173.479\n",
      "Epoch: [13] [ 5733/10059] total steps:[126441] lr:[0.00005000] time: 14.94s (39899s total) loss: 150.239\n",
      "Epoch: [13] [ 5743/10059] total steps:[126451] lr:[0.00005000] time: 14.85s (39914s total) loss: 111.298\n",
      "Epoch: [13] [ 5753/10059] total steps:[126461] lr:[0.00005000] time: 14.87s (39929s total) loss: 120.528\n",
      "Epoch: [13] [ 5763/10059] total steps:[126471] lr:[0.00005000] time: 14.86s (39944s total) loss: 117.036\n",
      "Epoch: [13] [ 5773/10059] total steps:[126481] lr:[0.00005000] time: 14.78s (39959s total) loss: 101.784\n",
      "Epoch: [13] [ 5783/10059] total steps:[126491] lr:[0.00005000] time: 14.73s (39973s total) loss: 191.271\n",
      "Epoch: [13] [ 5793/10059] total steps:[126501] lr:[0.00005000] time: 14.77s (39988s total) loss: 127.637\n",
      "Epoch: [13] [ 5803/10059] total steps:[126511] lr:[0.00005000] time: 14.84s (40003s total) loss: 134.233\n",
      "Epoch: [13] [ 5813/10059] total steps:[126521] lr:[0.00005000] time: 14.91s (40018s total) loss: 128.455\n",
      "Epoch: [13] [ 5823/10059] total steps:[126531] lr:[0.00005000] time: 16.46s (40034s total) loss: 175.751\n",
      "Epoch: [13] [ 5833/10059] total steps:[126541] lr:[0.00005000] time: 14.82s (40049s total) loss: 151.332\n",
      "Epoch: [13] [ 5843/10059] total steps:[126551] lr:[0.00005000] time: 14.84s (40064s total) loss: 187.537\n",
      "Epoch: [13] [ 5853/10059] total steps:[126561] lr:[0.00005000] time: 14.79s (40079s total) loss: 122.008\n",
      "Epoch: [13] [ 5863/10059] total steps:[126571] lr:[0.00005000] time: 14.77s (40094s total) loss: 255.800\n",
      "Epoch: [13] [ 5873/10059] total steps:[126581] lr:[0.00005000] time: 14.83s (40108s total) loss: 140.544\n",
      "Epoch: [13] [ 5883/10059] total steps:[126591] lr:[0.00005000] time: 14.86s (40123s total) loss: 139.476\n",
      "Epoch: [13] [ 5893/10059] total steps:[126601] lr:[0.00005000] time: 14.78s (40138s total) loss: 145.514\n",
      "Epoch: [13] [ 5903/10059] total steps:[126611] lr:[0.00005000] time: 14.70s (40153s total) loss: 103.772\n",
      "Epoch: [13] [ 5913/10059] total steps:[126621] lr:[0.00005000] time: 14.76s (40168s total) loss: 100.126\n",
      "Epoch: [13] [ 5923/10059] total steps:[126631] lr:[0.00005000] time: 14.74s (40182s total) loss: 111.602\n",
      "Epoch: [13] [ 5933/10059] total steps:[126641] lr:[0.00005000] time: 14.75s (40197s total) loss: 115.878\n",
      "Epoch: [13] [ 5943/10059] total steps:[126651] lr:[0.00005000] time: 14.77s (40212s total) loss: 157.074\n",
      "Epoch: [13] [ 5953/10059] total steps:[126661] lr:[0.00005000] time: 14.82s (40227s total) loss: 129.263\n",
      "Epoch: [13] [ 5963/10059] total steps:[126671] lr:[0.00005000] time: 15.04s (40242s total) loss: 140.915\n",
      "Epoch: [13] [ 5973/10059] total steps:[126681] lr:[0.00005000] time: 14.82s (40256s total) loss: 134.940\n",
      "Epoch: [13] [ 5983/10059] total steps:[126691] lr:[0.00005000] time: 14.83s (40271s total) loss: 177.002\n",
      "Epoch: [13] [ 5993/10059] total steps:[126701] lr:[0.00005000] time: 14.92s (40286s total) loss: 179.356\n",
      "Epoch: [13] [ 6003/10059] total steps:[126711] lr:[0.00005000] time: 14.73s (40301s total) loss: 136.102\n",
      "Epoch: [13] [ 6013/10059] total steps:[126721] lr:[0.00005000] time: 14.84s (40316s total) loss: 159.685\n",
      "Epoch: [13] [ 6023/10059] total steps:[126731] lr:[0.00005000] time: 14.76s (40331s total) loss: 102.383\n",
      "Epoch: [13] [ 6033/10059] total steps:[126741] lr:[0.00005000] time: 14.80s (40345s total) loss: 133.556\n",
      "Epoch: [13] [ 6043/10059] total steps:[126751] lr:[0.00005000] time: 14.70s (40360s total) loss: 184.056\n",
      "Epoch: [13] [ 6053/10059] total steps:[126761] lr:[0.00005000] time: 14.76s (40375s total) loss: 165.771\n",
      "Epoch: [13] [ 6063/10059] total steps:[126771] lr:[0.00005000] time: 14.83s (40390s total) loss: 182.618\n",
      "Epoch: [13] [ 6073/10059] total steps:[126781] lr:[0.00005000] time: 15.04s (40405s total) loss: 162.211\n",
      "Epoch: [13] [ 6083/10059] total steps:[126791] lr:[0.00005000] time: 14.73s (40419s total) loss: 146.619\n",
      "Epoch: [13] [ 6093/10059] total steps:[126801] lr:[0.00005000] time: 15.04s (40434s total) loss: 120.396\n",
      "Epoch: [13] [ 6103/10059] total steps:[126811] lr:[0.00005000] time: 14.85s (40449s total) loss: 92.851\n",
      "Epoch: [13] [ 6113/10059] total steps:[126821] lr:[0.00005000] time: 14.79s (40464s total) loss: 142.600\n",
      "Epoch: [13] [ 6123/10059] total steps:[126831] lr:[0.00005000] time: 14.75s (40479s total) loss: 124.644\n",
      "Epoch: [13] [ 6133/10059] total steps:[126841] lr:[0.00005000] time: 14.83s (40494s total) loss: 106.351\n",
      "Epoch: [13] [ 6143/10059] total steps:[126851] lr:[0.00005000] time: 14.87s (40509s total) loss: 177.149\n",
      "Epoch: [13] [ 6153/10059] total steps:[126861] lr:[0.00005000] time: 14.85s (40523s total) loss: 138.170\n",
      "Epoch: [13] [ 6163/10059] total steps:[126871] lr:[0.00005000] time: 14.89s (40538s total) loss: 159.150\n",
      "Epoch: [13] [ 6173/10059] total steps:[126881] lr:[0.00005000] time: 14.82s (40553s total) loss: 145.948\n",
      "Epoch: [13] [ 6183/10059] total steps:[126891] lr:[0.00005000] time: 14.81s (40568s total) loss: 139.335\n",
      "Epoch: [13] [ 6193/10059] total steps:[126901] lr:[0.00005000] time: 14.76s (40583s total) loss: 117.739\n",
      "Epoch: [13] [ 6203/10059] total steps:[126911] lr:[0.00005000] time: 14.72s (40597s total) loss: 129.599\n",
      "Epoch: [13] [ 6213/10059] total steps:[126921] lr:[0.00005000] time: 14.83s (40612s total) loss: 134.591\n",
      "Epoch: [13] [ 6223/10059] total steps:[126931] lr:[0.00005000] time: 14.79s (40627s total) loss: 162.753\n",
      "Epoch: [13] [ 6233/10059] total steps:[126941] lr:[0.00005000] time: 14.78s (40642s total) loss: 121.876\n",
      "Epoch: [13] [ 6243/10059] total steps:[126951] lr:[0.00005000] time: 14.83s (40657s total) loss: 132.094\n",
      "Epoch: [13] [ 6253/10059] total steps:[126961] lr:[0.00005000] time: 14.80s (40671s total) loss: 118.089\n",
      "Epoch: [13] [ 6263/10059] total steps:[126971] lr:[0.00005000] time: 14.84s (40686s total) loss: 187.942\n",
      "Epoch: [13] [ 6273/10059] total steps:[126981] lr:[0.00005000] time: 14.81s (40701s total) loss: 148.488\n",
      "Epoch: [13] [ 6283/10059] total steps:[126991] lr:[0.00005000] time: 14.87s (40716s total) loss: 141.244\n",
      "Epoch: [13] [ 6293/10059] total steps:[127001] lr:[0.00005000] time: 14.84s (40731s total) loss: 160.537\n",
      "Epoch: [13] [ 6303/10059] total steps:[127011] lr:[0.00005000] time: 14.81s (40746s total) loss: 158.618\n",
      "Epoch: [13] [ 6313/10059] total steps:[127021] lr:[0.00005000] time: 14.91s (40761s total) loss: 137.577\n",
      "Epoch: [13] [ 6323/10059] total steps:[127031] lr:[0.00005000] time: 14.74s (40775s total) loss: 141.085\n",
      "Epoch: [13] [ 6333/10059] total steps:[127041] lr:[0.00005000] time: 14.76s (40790s total) loss: 120.449\n",
      "Epoch: [13] [ 6343/10059] total steps:[127051] lr:[0.00005000] time: 14.75s (40805s total) loss: 95.628\n",
      "Epoch: [13] [ 6353/10059] total steps:[127061] lr:[0.00005000] time: 14.85s (40820s total) loss: 121.574\n",
      "Epoch: [13] [ 6363/10059] total steps:[127071] lr:[0.00005000] time: 14.73s (40834s total) loss: 135.855\n",
      "Epoch: [13] [ 6373/10059] total steps:[127081] lr:[0.00005000] time: 14.91s (40849s total) loss: 94.452\n",
      "Epoch: [13] [ 6383/10059] total steps:[127091] lr:[0.00005000] time: 14.85s (40864s total) loss: 145.846\n",
      "Epoch: [13] [ 6393/10059] total steps:[127101] lr:[0.00005000] time: 14.88s (40879s total) loss: 189.291\n",
      "Epoch: [13] [ 6403/10059] total steps:[127111] lr:[0.00005000] time: 14.68s (40894s total) loss: 100.017\n",
      "Epoch: [13] [ 6413/10059] total steps:[127121] lr:[0.00005000] time: 14.80s (40908s total) loss: 142.474\n",
      "Epoch: [13] [ 6423/10059] total steps:[127131] lr:[0.00005000] time: 14.71s (40923s total) loss: 173.909\n",
      "Epoch: [13] [ 6433/10059] total steps:[127141] lr:[0.00005000] time: 14.70s (40938s total) loss: 95.730\n",
      "Epoch: [13] [ 6443/10059] total steps:[127151] lr:[0.00005000] time: 14.79s (40953s total) loss: 182.968\n",
      "Epoch: [13] [ 6453/10059] total steps:[127161] lr:[0.00005000] time: 14.82s (40967s total) loss: 182.904\n",
      "Epoch: [13] [ 6463/10059] total steps:[127171] lr:[0.00005000] time: 14.86s (40982s total) loss: 132.315\n",
      "Epoch: [13] [ 6473/10059] total steps:[127181] lr:[0.00005000] time: 14.79s (40997s total) loss: 137.196\n",
      "Epoch: [13] [ 6483/10059] total steps:[127191] lr:[0.00005000] time: 14.79s (41012s total) loss: 160.877\n",
      "Epoch: [13] [ 6493/10059] total steps:[127201] lr:[0.00005000] time: 14.73s (41027s total) loss: 129.989\n",
      "Epoch: [13] [ 6503/10059] total steps:[127211] lr:[0.00005000] time: 14.69s (41041s total) loss: 135.773\n",
      "Epoch: [13] [ 6513/10059] total steps:[127221] lr:[0.00005000] time: 14.78s (41056s total) loss: 141.753\n",
      "Epoch: [13] [ 6523/10059] total steps:[127231] lr:[0.00005000] time: 14.75s (41071s total) loss: 97.076\n",
      "Epoch: [13] [ 6533/10059] total steps:[127241] lr:[0.00005000] time: 14.91s (41086s total) loss: 152.279\n",
      "Epoch: [13] [ 6543/10059] total steps:[127251] lr:[0.00005000] time: 14.71s (41100s total) loss: 130.917\n",
      "Epoch: [13] [ 6553/10059] total steps:[127261] lr:[0.00005000] time: 14.78s (41115s total) loss: 157.251\n",
      "Epoch: [13] [ 6563/10059] total steps:[127271] lr:[0.00005000] time: 14.79s (41130s total) loss: 149.924\n",
      "Epoch: [13] [ 6573/10059] total steps:[127281] lr:[0.00005000] time: 14.81s (41145s total) loss: 137.288\n",
      "Epoch: [13] [ 6583/10059] total steps:[127291] lr:[0.00005000] time: 14.82s (41160s total) loss: 125.400\n",
      "Epoch: [13] [ 6593/10059] total steps:[127301] lr:[0.00005000] time: 14.78s (41174s total) loss: 130.164\n",
      "Epoch: [13] [ 6603/10059] total steps:[127311] lr:[0.00005000] time: 14.75s (41189s total) loss: 94.716\n",
      "Epoch: [13] [ 6613/10059] total steps:[127321] lr:[0.00005000] time: 14.87s (41204s total) loss: 132.549\n",
      "Epoch: [13] [ 6623/10059] total steps:[127331] lr:[0.00005000] time: 14.81s (41219s total) loss: 142.876\n",
      "Epoch: [13] [ 6633/10059] total steps:[127341] lr:[0.00005000] time: 14.74s (41234s total) loss: 165.064\n",
      "Epoch: [13] [ 6643/10059] total steps:[127351] lr:[0.00005000] time: 14.80s (41248s total) loss: 104.686\n",
      "Epoch: [13] [ 6653/10059] total steps:[127361] lr:[0.00005000] time: 14.69s (41263s total) loss: 133.668\n",
      "Epoch: [13] [ 6663/10059] total steps:[127371] lr:[0.00005000] time: 14.76s (41278s total) loss: 114.448\n",
      "Epoch: [13] [ 6673/10059] total steps:[127381] lr:[0.00005000] time: 14.94s (41293s total) loss: 101.374\n",
      "Epoch: [13] [ 6683/10059] total steps:[127391] lr:[0.00005000] time: 14.75s (41308s total) loss: 144.897\n",
      "Epoch: [13] [ 6693/10059] total steps:[127401] lr:[0.00005000] time: 14.80s (41322s total) loss: 107.274\n",
      "Epoch: [13] [ 6703/10059] total steps:[127411] lr:[0.00005000] time: 14.70s (41337s total) loss: 122.538\n",
      "Epoch: [13] [ 6713/10059] total steps:[127421] lr:[0.00005000] time: 14.82s (41352s total) loss: 114.905\n",
      "Epoch: [13] [ 6723/10059] total steps:[127431] lr:[0.00005000] time: 14.69s (41367s total) loss: 116.212\n",
      "Epoch: [13] [ 6733/10059] total steps:[127441] lr:[0.00005000] time: 14.76s (41381s total) loss: 121.999\n",
      "Epoch: [13] [ 6743/10059] total steps:[127451] lr:[0.00005000] time: 14.82s (41396s total) loss: 139.305\n",
      "Epoch: [13] [ 6753/10059] total steps:[127461] lr:[0.00005000] time: 14.74s (41411s total) loss: 135.707\n",
      "Epoch: [13] [ 6763/10059] total steps:[127471] lr:[0.00005000] time: 14.81s (41426s total) loss: 134.076\n",
      "Epoch: [13] [ 6773/10059] total steps:[127481] lr:[0.00005000] time: 14.80s (41441s total) loss: 186.235\n",
      "Epoch: [13] [ 6783/10059] total steps:[127491] lr:[0.00005000] time: 14.77s (41455s total) loss: 133.914\n",
      "Epoch: [13] [ 6793/10059] total steps:[127501] lr:[0.00005000] time: 14.85s (41470s total) loss: 125.957\n",
      "Epoch: [13] [ 6803/10059] total steps:[127511] lr:[0.00005000] time: 14.71s (41485s total) loss: 162.161\n",
      "Epoch: [13] [ 6813/10059] total steps:[127521] lr:[0.00005000] time: 14.79s (41500s total) loss: 153.347\n",
      "Epoch: [13] [ 6823/10059] total steps:[127531] lr:[0.00005000] time: 14.81s (41514s total) loss: 178.887\n",
      "Epoch: [13] [ 6833/10059] total steps:[127541] lr:[0.00005000] time: 14.81s (41529s total) loss: 180.857\n",
      "Epoch: [13] [ 6843/10059] total steps:[127551] lr:[0.00005000] time: 14.81s (41544s total) loss: 181.932\n",
      "Epoch: [13] [ 6853/10059] total steps:[127561] lr:[0.00005000] time: 14.81s (41559s total) loss: 132.444\n",
      "Epoch: [13] [ 6863/10059] total steps:[127571] lr:[0.00005000] time: 14.82s (41574s total) loss: 207.279\n",
      "Epoch: [13] [ 6873/10059] total steps:[127581] lr:[0.00005000] time: 14.78s (41588s total) loss: 157.480\n",
      "Epoch: [13] [ 6883/10059] total steps:[127591] lr:[0.00005000] time: 14.68s (41603s total) loss: 167.213\n",
      "Epoch: [13] [ 6893/10059] total steps:[127601] lr:[0.00005000] time: 14.85s (41618s total) loss: 99.856\n",
      "Epoch: [13] [ 6903/10059] total steps:[127611] lr:[0.00005000] time: 14.76s (41633s total) loss: 133.979\n",
      "Epoch: [13] [ 6913/10059] total steps:[127621] lr:[0.00005000] time: 14.91s (41648s total) loss: 102.163\n",
      "Epoch: [13] [ 6923/10059] total steps:[127631] lr:[0.00005000] time: 14.74s (41662s total) loss: 146.756\n",
      "Epoch: [13] [ 6933/10059] total steps:[127641] lr:[0.00005000] time: 14.78s (41677s total) loss: 166.066\n",
      "Epoch: [13] [ 6943/10059] total steps:[127651] lr:[0.00005000] time: 14.79s (41692s total) loss: 135.345\n",
      "Epoch: [13] [ 6953/10059] total steps:[127661] lr:[0.00005000] time: 14.91s (41707s total) loss: 88.211\n",
      "Epoch: [13] [ 6963/10059] total steps:[127671] lr:[0.00005000] time: 14.71s (41722s total) loss: 180.491\n",
      "Epoch: [13] [ 6973/10059] total steps:[127681] lr:[0.00005000] time: 14.76s (41736s total) loss: 146.942\n",
      "Epoch: [13] [ 6983/10059] total steps:[127691] lr:[0.00005000] time: 14.90s (41751s total) loss: 103.445\n",
      "Epoch: [13] [ 6993/10059] total steps:[127701] lr:[0.00005000] time: 14.87s (41766s total) loss: 152.700\n",
      "Epoch: [13] [ 7003/10059] total steps:[127711] lr:[0.00005000] time: 14.79s (41781s total) loss: 166.606\n",
      "Epoch: [13] [ 7013/10059] total steps:[127721] lr:[0.00005000] time: 14.91s (41796s total) loss: 103.172\n",
      "Epoch: [13] [ 7023/10059] total steps:[127731] lr:[0.00005000] time: 14.79s (41811s total) loss: 165.148\n",
      "Epoch: [13] [ 7033/10059] total steps:[127741] lr:[0.00005000] time: 14.84s (41825s total) loss: 192.209\n",
      "Epoch: [13] [ 7043/10059] total steps:[127751] lr:[0.00005000] time: 14.77s (41840s total) loss: 171.174\n",
      "Epoch: [13] [ 7053/10059] total steps:[127761] lr:[0.00005000] time: 14.77s (41855s total) loss: 197.298\n",
      "Epoch: [13] [ 7063/10059] total steps:[127771] lr:[0.00005000] time: 14.78s (41870s total) loss: 109.070\n",
      "Epoch: [13] [ 7073/10059] total steps:[127781] lr:[0.00005000] time: 14.80s (41885s total) loss: 185.109\n",
      "Epoch: [13] [ 7083/10059] total steps:[127791] lr:[0.00005000] time: 14.72s (41899s total) loss: 119.756\n",
      "Epoch: [13] [ 7093/10059] total steps:[127801] lr:[0.00005000] time: 14.87s (41914s total) loss: 111.289\n",
      "Epoch: [13] [ 7103/10059] total steps:[127811] lr:[0.00005000] time: 14.70s (41929s total) loss: 176.861\n",
      "Epoch: [13] [ 7113/10059] total steps:[127821] lr:[0.00005000] time: 14.80s (41944s total) loss: 137.800\n",
      "Epoch: [13] [ 7123/10059] total steps:[127831] lr:[0.00005000] time: 14.80s (41958s total) loss: 166.449\n",
      "Epoch: [13] [ 7133/10059] total steps:[127841] lr:[0.00005000] time: 14.72s (41973s total) loss: 125.662\n",
      "Epoch: [13] [ 7143/10059] total steps:[127851] lr:[0.00005000] time: 14.79s (41988s total) loss: 116.592\n",
      "Epoch: [13] [ 7153/10059] total steps:[127861] lr:[0.00005000] time: 14.85s (42003s total) loss: 111.352\n",
      "Epoch: [13] [ 7163/10059] total steps:[127871] lr:[0.00005000] time: 14.82s (42018s total) loss: 137.030\n",
      "Epoch: [13] [ 7173/10059] total steps:[127881] lr:[0.00005000] time: 14.84s (42032s total) loss: 104.415\n",
      "Epoch: [13] [ 7183/10059] total steps:[127891] lr:[0.00005000] time: 14.94s (42047s total) loss: 169.211\n",
      "Epoch: [13] [ 7193/10059] total steps:[127901] lr:[0.00005000] time: 14.78s (42062s total) loss: 104.524\n",
      "Epoch: [13] [ 7203/10059] total steps:[127911] lr:[0.00005000] time: 14.85s (42077s total) loss: 97.156\n",
      "Epoch: [13] [ 7213/10059] total steps:[127921] lr:[0.00005000] time: 14.95s (42092s total) loss: 113.659\n",
      "Epoch: [13] [ 7223/10059] total steps:[127931] lr:[0.00005000] time: 14.82s (42107s total) loss: 187.745\n",
      "Epoch: [13] [ 7233/10059] total steps:[127941] lr:[0.00005000] time: 14.73s (42122s total) loss: 158.230\n",
      "Epoch: [13] [ 7243/10059] total steps:[127951] lr:[0.00005000] time: 14.76s (42136s total) loss: 120.537\n",
      "Epoch: [13] [ 7253/10059] total steps:[127961] lr:[0.00005000] time: 14.97s (42151s total) loss: 157.464\n",
      "Epoch: [13] [ 7263/10059] total steps:[127971] lr:[0.00005000] time: 14.75s (42166s total) loss: 167.851\n",
      "Epoch: [13] [ 7273/10059] total steps:[127981] lr:[0.00005000] time: 14.73s (42181s total) loss: 168.383\n",
      "Epoch: [13] [ 7283/10059] total steps:[127991] lr:[0.00005000] time: 14.69s (42195s total) loss: 109.298\n",
      "Epoch: [13] [ 7293/10059] total steps:[128001] lr:[0.00005000] time: 14.82s (42210s total) loss: 72.791\n",
      "Epoch: [13] [ 7303/10059] total steps:[128011] lr:[0.00005000] time: 14.97s (42225s total) loss: 96.935\n",
      "Epoch: [13] [ 7313/10059] total steps:[128021] lr:[0.00005000] time: 14.84s (42240s total) loss: 167.575\n",
      "Epoch: [13] [ 7323/10059] total steps:[128031] lr:[0.00005000] time: 14.89s (42255s total) loss: 157.175\n",
      "Epoch: [13] [ 7333/10059] total steps:[128041] lr:[0.00005000] time: 14.80s (42270s total) loss: 148.786\n",
      "Epoch: [13] [ 7343/10059] total steps:[128051] lr:[0.00005000] time: 14.82s (42285s total) loss: 106.134\n",
      "Epoch: [13] [ 7353/10059] total steps:[128061] lr:[0.00005000] time: 14.74s (42299s total) loss: 134.159\n",
      "Epoch: [13] [ 7363/10059] total steps:[128071] lr:[0.00005000] time: 14.77s (42314s total) loss: 107.012\n",
      "Epoch: [13] [ 7373/10059] total steps:[128081] lr:[0.00005000] time: 14.76s (42329s total) loss: 135.522\n",
      "Epoch: [13] [ 7383/10059] total steps:[128091] lr:[0.00005000] time: 14.81s (42344s total) loss: 144.242\n",
      "Epoch: [13] [ 7393/10059] total steps:[128101] lr:[0.00005000] time: 14.79s (42358s total) loss: 112.068\n",
      "Epoch: [13] [ 7403/10059] total steps:[128111] lr:[0.00005000] time: 15.04s (42373s total) loss: 149.809\n",
      "Epoch: [13] [ 7413/10059] total steps:[128121] lr:[0.00005000] time: 14.72s (42388s total) loss: 119.707\n",
      "Epoch: [13] [ 7423/10059] total steps:[128131] lr:[0.00005000] time: 14.77s (42403s total) loss: 139.145\n",
      "Epoch: [13] [ 7433/10059] total steps:[128141] lr:[0.00005000] time: 14.86s (42418s total) loss: 127.913\n",
      "Epoch: [13] [ 7443/10059] total steps:[128151] lr:[0.00005000] time: 14.86s (42433s total) loss: 110.125\n",
      "Epoch: [13] [ 7453/10059] total steps:[128161] lr:[0.00005000] time: 14.76s (42447s total) loss: 187.310\n",
      "Epoch: [13] [ 7463/10059] total steps:[128171] lr:[0.00005000] time: 14.75s (42462s total) loss: 101.791\n",
      "Epoch: [13] [ 7473/10059] total steps:[128181] lr:[0.00005000] time: 14.85s (42477s total) loss: 161.655\n",
      "Epoch: [13] [ 7483/10059] total steps:[128191] lr:[0.00005000] time: 14.76s (42492s total) loss: 148.144\n",
      "Epoch: [13] [ 7493/10059] total steps:[128201] lr:[0.00005000] time: 14.79s (42507s total) loss: 129.811\n",
      "Epoch: [13] [ 7503/10059] total steps:[128211] lr:[0.00005000] time: 14.75s (42521s total) loss: 115.287\n",
      "Epoch: [13] [ 7513/10059] total steps:[128221] lr:[0.00005000] time: 14.69s (42536s total) loss: 145.757\n",
      "Epoch: [13] [ 7523/10059] total steps:[128231] lr:[0.00005000] time: 14.71s (42551s total) loss: 98.321\n",
      "Epoch: [13] [ 7533/10059] total steps:[128241] lr:[0.00005000] time: 14.84s (42566s total) loss: 149.568\n",
      "Epoch: [13] [ 7543/10059] total steps:[128251] lr:[0.00005000] time: 14.66s (42580s total) loss: 135.560\n",
      "Epoch: [13] [ 7553/10059] total steps:[128261] lr:[0.00005000] time: 14.76s (42595s total) loss: 139.339\n",
      "Epoch: [13] [ 7563/10059] total steps:[128271] lr:[0.00005000] time: 14.66s (42610s total) loss: 129.271\n",
      "Epoch: [13] [ 7573/10059] total steps:[128281] lr:[0.00005000] time: 14.80s (42624s total) loss: 153.080\n",
      "Epoch: [13] [ 7583/10059] total steps:[128291] lr:[0.00005000] time: 14.85s (42639s total) loss: 133.503\n",
      "Epoch: [13] [ 7593/10059] total steps:[128301] lr:[0.00005000] time: 14.80s (42654s total) loss: 108.544\n",
      "Epoch: [13] [ 7603/10059] total steps:[128311] lr:[0.00005000] time: 14.70s (42669s total) loss: 102.764\n",
      "Epoch: [13] [ 7613/10059] total steps:[128321] lr:[0.00005000] time: 14.77s (42684s total) loss: 144.764\n",
      "Epoch: [13] [ 7623/10059] total steps:[128331] lr:[0.00005000] time: 14.79s (42698s total) loss: 189.334\n",
      "Epoch: [13] [ 7633/10059] total steps:[128341] lr:[0.00005000] time: 14.83s (42713s total) loss: 96.905\n",
      "Epoch: [13] [ 7643/10059] total steps:[128351] lr:[0.00005000] time: 14.76s (42728s total) loss: 171.441\n",
      "Epoch: [13] [ 7653/10059] total steps:[128361] lr:[0.00005000] time: 14.96s (42743s total) loss: 112.959\n",
      "Epoch: [13] [ 7663/10059] total steps:[128371] lr:[0.00005000] time: 14.77s (42758s total) loss: 154.671\n",
      "Epoch: [13] [ 7673/10059] total steps:[128381] lr:[0.00005000] time: 14.78s (42772s total) loss: 118.793\n",
      "Epoch: [13] [ 7683/10059] total steps:[128391] lr:[0.00005000] time: 14.72s (42787s total) loss: 118.143\n",
      "Epoch: [13] [ 7693/10059] total steps:[128401] lr:[0.00005000] time: 14.83s (42802s total) loss: 144.080\n",
      "Epoch: [13] [ 7703/10059] total steps:[128411] lr:[0.00005000] time: 14.76s (42817s total) loss: 150.684\n",
      "Epoch: [13] [ 7713/10059] total steps:[128421] lr:[0.00005000] time: 14.74s (42832s total) loss: 150.141\n",
      "Epoch: [13] [ 7723/10059] total steps:[128431] lr:[0.00005000] time: 14.66s (42846s total) loss: 127.123\n",
      "Epoch: [13] [ 7733/10059] total steps:[128441] lr:[0.00005000] time: 14.82s (42861s total) loss: 146.893\n",
      "Epoch: [13] [ 7743/10059] total steps:[128451] lr:[0.00005000] time: 14.96s (42876s total) loss: 143.699\n",
      "Epoch: [13] [ 7753/10059] total steps:[128461] lr:[0.00005000] time: 14.79s (42891s total) loss: 105.123\n",
      "Epoch: [13] [ 7763/10059] total steps:[128471] lr:[0.00005000] time: 14.79s (42906s total) loss: 149.062\n",
      "Epoch: [13] [ 7773/10059] total steps:[128481] lr:[0.00005000] time: 14.69s (42920s total) loss: 108.916\n",
      "Epoch: [13] [ 7783/10059] total steps:[128491] lr:[0.00005000] time: 14.87s (42935s total) loss: 159.319\n",
      "Epoch: [13] [ 7793/10059] total steps:[128501] lr:[0.00005000] time: 14.79s (42950s total) loss: 223.782\n",
      "Epoch: [13] [ 7803/10059] total steps:[128511] lr:[0.00005000] time: 14.65s (42965s total) loss: 98.012\n",
      "Epoch: [13] [ 7813/10059] total steps:[128521] lr:[0.00005000] time: 14.85s (42979s total) loss: 141.274\n",
      "Epoch: [13] [ 7823/10059] total steps:[128531] lr:[0.00005000] time: 14.84s (42994s total) loss: 131.900\n",
      "Epoch: [13] [ 7833/10059] total steps:[128541] lr:[0.00005000] time: 14.71s (43009s total) loss: 107.540\n",
      "Epoch: [13] [ 7843/10059] total steps:[128551] lr:[0.00005000] time: 14.79s (43024s total) loss: 108.463\n",
      "Epoch: [13] [ 7853/10059] total steps:[128561] lr:[0.00005000] time: 14.71s (43038s total) loss: 125.702\n",
      "Epoch: [13] [ 7863/10059] total steps:[128571] lr:[0.00005000] time: 14.81s (43053s total) loss: 91.082\n",
      "Epoch: [13] [ 7873/10059] total steps:[128581] lr:[0.00005000] time: 14.76s (43068s total) loss: 102.393\n",
      "Epoch: [13] [ 7883/10059] total steps:[128591] lr:[0.00005000] time: 14.74s (43083s total) loss: 104.042\n",
      "Epoch: [13] [ 7893/10059] total steps:[128601] lr:[0.00005000] time: 14.76s (43098s total) loss: 113.954\n",
      "Epoch: [13] [ 7903/10059] total steps:[128611] lr:[0.00005000] time: 14.81s (43112s total) loss: 161.510\n",
      "Epoch: [13] [ 7913/10059] total steps:[128621] lr:[0.00005000] time: 14.77s (43127s total) loss: 131.214\n",
      "Epoch: [13] [ 7923/10059] total steps:[128631] lr:[0.00005000] time: 14.67s (43142s total) loss: 133.404\n",
      "Epoch: [13] [ 7933/10059] total steps:[128641] lr:[0.00005000] time: 14.91s (43157s total) loss: 195.693\n",
      "Epoch: [13] [ 7943/10059] total steps:[128651] lr:[0.00005000] time: 14.84s (43172s total) loss: 156.960\n",
      "Epoch: [13] [ 7953/10059] total steps:[128661] lr:[0.00005000] time: 14.65s (43186s total) loss: 123.663\n",
      "Epoch: [13] [ 7963/10059] total steps:[128671] lr:[0.00005000] time: 14.81s (43201s total) loss: 100.397\n",
      "Epoch: [13] [ 7973/10059] total steps:[128681] lr:[0.00005000] time: 14.97s (43216s total) loss: 172.728\n",
      "Epoch: [13] [ 7983/10059] total steps:[128691] lr:[0.00005000] time: 14.75s (43231s total) loss: 112.973\n",
      "Epoch: [13] [ 7993/10059] total steps:[128701] lr:[0.00005000] time: 14.85s (43246s total) loss: 99.581\n",
      "Epoch: [13] [ 8003/10059] total steps:[128711] lr:[0.00005000] time: 14.90s (43260s total) loss: 146.022\n",
      "Epoch: [13] [ 8013/10059] total steps:[128721] lr:[0.00005000] time: 14.84s (43275s total) loss: 102.288\n",
      "Epoch: [13] [ 8023/10059] total steps:[128731] lr:[0.00005000] time: 14.90s (43290s total) loss: 131.276\n",
      "Epoch: [13] [ 8033/10059] total steps:[128741] lr:[0.00005000] time: 14.79s (43305s total) loss: 151.518\n",
      "Epoch: [13] [ 8043/10059] total steps:[128751] lr:[0.00005000] time: 14.79s (43320s total) loss: 153.718\n",
      "Epoch: [13] [ 8053/10059] total steps:[128761] lr:[0.00005000] time: 14.72s (43334s total) loss: 159.390\n",
      "Epoch: [13] [ 8063/10059] total steps:[128771] lr:[0.00005000] time: 14.79s (43349s total) loss: 149.205\n",
      "Epoch: [13] [ 8073/10059] total steps:[128781] lr:[0.00005000] time: 14.91s (43364s total) loss: 122.523\n",
      "Epoch: [13] [ 8083/10059] total steps:[128791] lr:[0.00005000] time: 14.71s (43379s total) loss: 100.546\n",
      "Epoch: [13] [ 8093/10059] total steps:[128801] lr:[0.00005000] time: 14.80s (43394s total) loss: 99.739\n",
      "Epoch: [13] [ 8103/10059] total steps:[128811] lr:[0.00005000] time: 14.77s (43408s total) loss: 122.145\n",
      "Epoch: [13] [ 8113/10059] total steps:[128821] lr:[0.00005000] time: 14.81s (43423s total) loss: 81.721\n",
      "Epoch: [13] [ 8123/10059] total steps:[128831] lr:[0.00005000] time: 14.83s (43438s total) loss: 211.383\n",
      "Epoch: [13] [ 8133/10059] total steps:[128841] lr:[0.00005000] time: 14.87s (43453s total) loss: 116.029\n",
      "Epoch: [13] [ 8143/10059] total steps:[128851] lr:[0.00005000] time: 14.80s (43468s total) loss: 154.496\n",
      "Epoch: [13] [ 8153/10059] total steps:[128861] lr:[0.00005000] time: 14.77s (43483s total) loss: 127.973\n",
      "Epoch: [13] [ 8163/10059] total steps:[128871] lr:[0.00005000] time: 14.87s (43497s total) loss: 139.343\n",
      "Epoch: [13] [ 8173/10059] total steps:[128881] lr:[0.00005000] time: 14.72s (43512s total) loss: 103.702\n",
      "Epoch: [13] [ 8183/10059] total steps:[128891] lr:[0.00005000] time: 14.80s (43527s total) loss: 132.041\n",
      "Epoch: [13] [ 8193/10059] total steps:[128901] lr:[0.00005000] time: 14.76s (43542s total) loss: 121.478\n",
      "Epoch: [13] [ 8203/10059] total steps:[128911] lr:[0.00005000] time: 14.68s (43556s total) loss: 175.177\n",
      "Epoch: [13] [ 8213/10059] total steps:[128921] lr:[0.00005000] time: 14.73s (43571s total) loss: 131.635\n",
      "Epoch: [13] [ 8223/10059] total steps:[128931] lr:[0.00005000] time: 14.75s (43586s total) loss: 133.835\n",
      "Epoch: [13] [ 8233/10059] total steps:[128941] lr:[0.00005000] time: 14.84s (43601s total) loss: 129.759\n",
      "Epoch: [13] [ 8243/10059] total steps:[128951] lr:[0.00005000] time: 14.69s (43615s total) loss: 179.813\n",
      "Epoch: [13] [ 8253/10059] total steps:[128961] lr:[0.00005000] time: 14.74s (43630s total) loss: 191.189\n",
      "Epoch: [13] [ 8263/10059] total steps:[128971] lr:[0.00005000] time: 14.97s (43645s total) loss: 189.314\n",
      "Epoch: [13] [ 8273/10059] total steps:[128981] lr:[0.00005000] time: 14.72s (43660s total) loss: 158.044\n",
      "Epoch: [13] [ 8283/10059] total steps:[128991] lr:[0.00005000] time: 14.81s (43675s total) loss: 126.306\n",
      "Epoch: [13] [ 8293/10059] total steps:[129001] lr:[0.00005000] time: 14.85s (43689s total) loss: 157.294\n",
      "Epoch: [13] [ 8303/10059] total steps:[129011] lr:[0.00005000] time: 14.73s (43704s total) loss: 180.091\n",
      "Epoch: [13] [ 8313/10059] total steps:[129021] lr:[0.00005000] time: 14.74s (43719s total) loss: 162.948\n",
      "Epoch: [13] [ 8323/10059] total steps:[129031] lr:[0.00005000] time: 14.65s (43734s total) loss: 175.175\n",
      "Epoch: [13] [ 8333/10059] total steps:[129041] lr:[0.00005000] time: 14.71s (43748s total) loss: 80.072\n",
      "Epoch: [13] [ 8343/10059] total steps:[129051] lr:[0.00005000] time: 14.81s (43763s total) loss: 150.598\n",
      "Epoch: [13] [ 8353/10059] total steps:[129061] lr:[0.00005000] time: 14.78s (43778s total) loss: 114.406\n",
      "Epoch: [13] [ 8363/10059] total steps:[129071] lr:[0.00005000] time: 14.85s (43793s total) loss: 123.269\n",
      "Epoch: [13] [ 8373/10059] total steps:[129081] lr:[0.00005000] time: 14.64s (43807s total) loss: 166.090\n",
      "Epoch: [13] [ 8383/10059] total steps:[129091] lr:[0.00005000] time: 14.79s (43822s total) loss: 124.685\n",
      "Epoch: [13] [ 8393/10059] total steps:[129101] lr:[0.00005000] time: 14.73s (43837s total) loss: 93.912\n",
      "Epoch: [13] [ 8403/10059] total steps:[129111] lr:[0.00005000] time: 16.09s (43853s total) loss: 158.681\n",
      "Epoch: [13] [ 8413/10059] total steps:[129121] lr:[0.00005000] time: 14.78s (43868s total) loss: 122.696\n",
      "Epoch: [13] [ 8423/10059] total steps:[129131] lr:[0.00005000] time: 14.75s (43883s total) loss: 101.220\n",
      "Epoch: [13] [ 8433/10059] total steps:[129141] lr:[0.00005000] time: 14.65s (43897s total) loss: 140.532\n",
      "Epoch: [13] [ 8443/10059] total steps:[129151] lr:[0.00005000] time: 14.80s (43912s total) loss: 188.456\n",
      "Epoch: [13] [ 8453/10059] total steps:[129161] lr:[0.00005000] time: 14.78s (43927s total) loss: 164.872\n",
      "Epoch: [13] [ 8463/10059] total steps:[129171] lr:[0.00005000] time: 14.92s (43942s total) loss: 147.250\n",
      "Epoch: [13] [ 8473/10059] total steps:[129181] lr:[0.00005000] time: 14.81s (43956s total) loss: 154.053\n",
      "Epoch: [13] [ 8483/10059] total steps:[129191] lr:[0.00005000] time: 14.68s (43971s total) loss: 105.365\n",
      "Epoch: [13] [ 8493/10059] total steps:[129201] lr:[0.00005000] time: 14.83s (43986s total) loss: 72.094\n",
      "Epoch: [13] [ 8503/10059] total steps:[129211] lr:[0.00005000] time: 14.76s (44001s total) loss: 138.338\n",
      "Epoch: [13] [ 8513/10059] total steps:[129221] lr:[0.00005000] time: 14.75s (44015s total) loss: 127.153\n",
      "Epoch: [13] [ 8523/10059] total steps:[129231] lr:[0.00005000] time: 14.79s (44030s total) loss: 190.851\n",
      "Epoch: [13] [ 8533/10059] total steps:[129241] lr:[0.00005000] time: 14.80s (44045s total) loss: 192.916\n",
      "Epoch: [13] [ 8543/10059] total steps:[129251] lr:[0.00005000] time: 14.67s (44060s total) loss: 158.509\n",
      "Epoch: [13] [ 8553/10059] total steps:[129261] lr:[0.00005000] time: 14.71s (44074s total) loss: 129.057\n",
      "Epoch: [13] [ 8563/10059] total steps:[129271] lr:[0.00005000] time: 14.80s (44089s total) loss: 100.092\n",
      "Epoch: [13] [ 8573/10059] total steps:[129281] lr:[0.00005000] time: 14.70s (44104s total) loss: 116.599\n",
      "Epoch: [13] [ 8583/10059] total steps:[129291] lr:[0.00005000] time: 14.71s (44119s total) loss: 143.696\n",
      "Epoch: [13] [ 8593/10059] total steps:[129301] lr:[0.00005000] time: 14.89s (44134s total) loss: 147.964\n",
      "Epoch: [13] [ 8603/10059] total steps:[129311] lr:[0.00005000] time: 14.68s (44148s total) loss: 187.837\n",
      "Epoch: [13] [ 8613/10059] total steps:[129321] lr:[0.00005000] time: 14.72s (44163s total) loss: 117.954\n",
      "Epoch: [13] [ 8623/10059] total steps:[129331] lr:[0.00005000] time: 14.93s (44178s total) loss: 97.112\n",
      "Epoch: [13] [ 8633/10059] total steps:[129341] lr:[0.00005000] time: 14.83s (44193s total) loss: 208.463\n",
      "Epoch: [13] [ 8643/10059] total steps:[129351] lr:[0.00005000] time: 14.84s (44208s total) loss: 163.658\n",
      "Epoch: [13] [ 8653/10059] total steps:[129361] lr:[0.00005000] time: 14.71s (44222s total) loss: 129.769\n",
      "Epoch: [13] [ 8663/10059] total steps:[129371] lr:[0.00005000] time: 14.72s (44237s total) loss: 112.530\n",
      "Epoch: [13] [ 8673/10059] total steps:[129381] lr:[0.00005000] time: 14.72s (44252s total) loss: 183.569\n",
      "Epoch: [13] [ 8683/10059] total steps:[129391] lr:[0.00005000] time: 14.71s (44266s total) loss: 132.617\n",
      "Epoch: [13] [ 8693/10059] total steps:[129401] lr:[0.00005000] time: 14.83s (44281s total) loss: 150.320\n",
      "Epoch: [13] [ 8703/10059] total steps:[129411] lr:[0.00005000] time: 14.79s (44296s total) loss: 111.557\n",
      "Epoch: [13] [ 8713/10059] total steps:[129421] lr:[0.00005000] time: 14.69s (44311s total) loss: 139.109\n",
      "Epoch: [13] [ 8723/10059] total steps:[129431] lr:[0.00005000] time: 14.70s (44325s total) loss: 109.420\n",
      "Epoch: [13] [ 8733/10059] total steps:[129441] lr:[0.00005000] time: 14.82s (44340s total) loss: 120.898\n",
      "Epoch: [13] [ 8743/10059] total steps:[129451] lr:[0.00005000] time: 14.68s (44355s total) loss: 135.857\n",
      "Epoch: [13] [ 8753/10059] total steps:[129461] lr:[0.00005000] time: 14.89s (44370s total) loss: 156.176\n",
      "Epoch: [13] [ 8763/10059] total steps:[129471] lr:[0.00005000] time: 14.73s (44385s total) loss: 109.234\n",
      "Epoch: [13] [ 8773/10059] total steps:[129481] lr:[0.00005000] time: 14.78s (44399s total) loss: 129.651\n",
      "Epoch: [13] [ 8783/10059] total steps:[129491] lr:[0.00005000] time: 14.65s (44414s total) loss: 230.313\n",
      "Epoch: [13] [ 8793/10059] total steps:[129501] lr:[0.00005000] time: 14.84s (44429s total) loss: 118.303\n",
      "Epoch: [13] [ 8803/10059] total steps:[129511] lr:[0.00005000] time: 14.79s (44444s total) loss: 117.830\n",
      "Epoch: [13] [ 8813/10059] total steps:[129521] lr:[0.00005000] time: 14.78s (44458s total) loss: 132.399\n",
      "Epoch: [13] [ 8823/10059] total steps:[129531] lr:[0.00005000] time: 14.80s (44473s total) loss: 154.644\n",
      "Epoch: [13] [ 8833/10059] total steps:[129541] lr:[0.00005000] time: 14.71s (44488s total) loss: 134.873\n",
      "Epoch: [13] [ 8843/10059] total steps:[129551] lr:[0.00005000] time: 14.72s (44503s total) loss: 154.232\n",
      "Epoch: [13] [ 8853/10059] total steps:[129561] lr:[0.00005000] time: 14.74s (44517s total) loss: 173.975\n",
      "Epoch: [13] [ 8863/10059] total steps:[129571] lr:[0.00005000] time: 14.74s (44532s total) loss: 218.532\n",
      "Epoch: [13] [ 8873/10059] total steps:[129581] lr:[0.00005000] time: 14.82s (44547s total) loss: 121.019\n",
      "Epoch: [13] [ 8883/10059] total steps:[129591] lr:[0.00005000] time: 14.72s (44562s total) loss: 105.887\n",
      "Epoch: [13] [ 8893/10059] total steps:[129601] lr:[0.00005000] time: 14.81s (44576s total) loss: 98.845\n",
      "Epoch: [13] [ 8903/10059] total steps:[129611] lr:[0.00005000] time: 14.91s (44591s total) loss: 173.236\n",
      "Epoch: [13] [ 8913/10059] total steps:[129621] lr:[0.00005000] time: 14.78s (44606s total) loss: 75.121\n",
      "Epoch: [13] [ 8923/10059] total steps:[129631] lr:[0.00005000] time: 14.74s (44621s total) loss: 154.181\n",
      "Epoch: [13] [ 8933/10059] total steps:[129641] lr:[0.00005000] time: 14.84s (44636s total) loss: 177.922\n",
      "Epoch: [13] [ 8943/10059] total steps:[129651] lr:[0.00005000] time: 14.81s (44651s total) loss: 116.417\n",
      "Epoch: [13] [ 8953/10059] total steps:[129661] lr:[0.00005000] time: 14.76s (44665s total) loss: 96.008\n",
      "Epoch: [13] [ 8963/10059] total steps:[129671] lr:[0.00005000] time: 14.86s (44680s total) loss: 164.445\n",
      "Epoch: [13] [ 8973/10059] total steps:[129681] lr:[0.00005000] time: 14.78s (44695s total) loss: 171.786\n",
      "Epoch: [13] [ 8983/10059] total steps:[129691] lr:[0.00005000] time: 14.69s (44710s total) loss: 121.813\n",
      "Epoch: [13] [ 8993/10059] total steps:[129701] lr:[0.00005000] time: 14.85s (44724s total) loss: 94.106\n",
      "Epoch: [13] [ 9003/10059] total steps:[129711] lr:[0.00005000] time: 14.83s (44739s total) loss: 123.097\n",
      "Epoch: [13] [ 9013/10059] total steps:[129721] lr:[0.00005000] time: 14.78s (44754s total) loss: 117.113\n",
      "Epoch: [13] [ 9023/10059] total steps:[129731] lr:[0.00005000] time: 14.79s (44769s total) loss: 167.389\n",
      "Epoch: [13] [ 9033/10059] total steps:[129741] lr:[0.00005000] time: 14.72s (44784s total) loss: 133.612\n",
      "Epoch: [13] [ 9043/10059] total steps:[129751] lr:[0.00005000] time: 14.85s (44798s total) loss: 172.775\n",
      "Epoch: [13] [ 9053/10059] total steps:[129761] lr:[0.00005000] time: 14.72s (44813s total) loss: 113.665\n",
      "Epoch: [13] [ 9063/10059] total steps:[129771] lr:[0.00005000] time: 14.79s (44828s total) loss: 113.628\n",
      "Epoch: [13] [ 9073/10059] total steps:[129781] lr:[0.00005000] time: 14.86s (44843s total) loss: 127.313\n",
      "Epoch: [13] [ 9083/10059] total steps:[129791] lr:[0.00005000] time: 14.75s (44858s total) loss: 150.654\n",
      "Epoch: [13] [ 9093/10059] total steps:[129801] lr:[0.00005000] time: 14.83s (44872s total) loss: 127.974\n",
      "Epoch: [13] [ 9103/10059] total steps:[129811] lr:[0.00005000] time: 14.74s (44887s total) loss: 113.758\n",
      "Epoch: [13] [ 9113/10059] total steps:[129821] lr:[0.00005000] time: 14.73s (44902s total) loss: 137.976\n",
      "Epoch: [13] [ 9123/10059] total steps:[129831] lr:[0.00005000] time: 14.82s (44917s total) loss: 119.848\n",
      "Epoch: [13] [ 9133/10059] total steps:[129841] lr:[0.00005000] time: 14.75s (44931s total) loss: 122.741\n",
      "Epoch: [13] [ 9143/10059] total steps:[129851] lr:[0.00005000] time: 14.83s (44946s total) loss: 80.507\n",
      "Epoch: [13] [ 9153/10059] total steps:[129861] lr:[0.00005000] time: 14.92s (44961s total) loss: 113.829\n",
      "Epoch: [13] [ 9163/10059] total steps:[129871] lr:[0.00005000] time: 14.79s (44976s total) loss: 132.402\n",
      "Epoch: [13] [ 9173/10059] total steps:[129881] lr:[0.00005000] time: 14.70s (44991s total) loss: 144.775\n",
      "Epoch: [13] [ 9183/10059] total steps:[129891] lr:[0.00005000] time: 14.89s (45006s total) loss: 149.273\n",
      "Epoch: [13] [ 9193/10059] total steps:[129901] lr:[0.00005000] time: 14.81s (45020s total) loss: 130.817\n",
      "Epoch: [13] [ 9203/10059] total steps:[129911] lr:[0.00005000] time: 14.81s (45035s total) loss: 180.910\n",
      "Epoch: [13] [ 9213/10059] total steps:[129921] lr:[0.00005000] time: 14.94s (45050s total) loss: 169.916\n",
      "Epoch: [13] [ 9223/10059] total steps:[129931] lr:[0.00005000] time: 14.82s (45065s total) loss: 154.326\n",
      "Epoch: [13] [ 9233/10059] total steps:[129941] lr:[0.00005000] time: 14.70s (45080s total) loss: 117.934\n",
      "Epoch: [13] [ 9243/10059] total steps:[129951] lr:[0.00005000] time: 14.76s (45094s total) loss: 107.141\n",
      "Epoch: [13] [ 9253/10059] total steps:[129961] lr:[0.00005000] time: 14.92s (45109s total) loss: 121.352\n",
      "Epoch: [13] [ 9263/10059] total steps:[129971] lr:[0.00005000] time: 14.72s (45124s total) loss: 180.118\n",
      "Epoch: [13] [ 9273/10059] total steps:[129981] lr:[0.00005000] time: 14.77s (45139s total) loss: 110.177\n",
      "Epoch: [13] [ 9283/10059] total steps:[129991] lr:[0.00005000] time: 14.79s (45154s total) loss: 158.942\n",
      "Epoch: [13] [ 9293/10059] total steps:[130001] lr:[0.00005000] time: 14.85s (45168s total) loss: 121.299\n",
      "Epoch: [13] [ 9303/10059] total steps:[130011] lr:[0.00005000] time: 14.76s (45183s total) loss: 156.307\n",
      "Epoch: [13] [ 9313/10059] total steps:[130021] lr:[0.00005000] time: 14.73s (45198s total) loss: 102.276\n",
      "Epoch: [13] [ 9323/10059] total steps:[130031] lr:[0.00005000] time: 14.77s (45213s total) loss: 93.553\n",
      "Epoch: [13] [ 9333/10059] total steps:[130041] lr:[0.00005000] time: 14.94s (45228s total) loss: 121.204\n",
      "Epoch: [13] [ 9343/10059] total steps:[130051] lr:[0.00005000] time: 14.81s (45242s total) loss: 167.488\n",
      "Epoch: [13] [ 9353/10059] total steps:[130061] lr:[0.00005000] time: 14.80s (45257s total) loss: 149.797\n",
      "Epoch: [13] [ 9363/10059] total steps:[130071] lr:[0.00005000] time: 14.79s (45272s total) loss: 147.663\n",
      "Epoch: [13] [ 9373/10059] total steps:[130081] lr:[0.00005000] time: 14.87s (45287s total) loss: 96.615\n",
      "Epoch: [13] [ 9383/10059] total steps:[130091] lr:[0.00005000] time: 14.70s (45302s total) loss: 109.505\n",
      "Epoch: [13] [ 9393/10059] total steps:[130101] lr:[0.00005000] time: 14.81s (45316s total) loss: 126.232\n",
      "Epoch: [13] [ 9403/10059] total steps:[130111] lr:[0.00005000] time: 14.75s (45331s total) loss: 133.169\n",
      "Epoch: [13] [ 9413/10059] total steps:[130121] lr:[0.00005000] time: 14.75s (45346s total) loss: 182.555\n",
      "Epoch: [13] [ 9423/10059] total steps:[130131] lr:[0.00005000] time: 14.74s (45361s total) loss: 172.381\n",
      "Epoch: [13] [ 9433/10059] total steps:[130141] lr:[0.00005000] time: 14.81s (45375s total) loss: 128.331\n",
      "Epoch: [13] [ 9443/10059] total steps:[130151] lr:[0.00005000] time: 14.68s (45390s total) loss: 100.915\n",
      "Epoch: [13] [ 9453/10059] total steps:[130161] lr:[0.00005000] time: 14.92s (45405s total) loss: 105.708\n",
      "Epoch: [13] [ 9463/10059] total steps:[130171] lr:[0.00005000] time: 14.88s (45420s total) loss: 132.667\n",
      "Epoch: [13] [ 9473/10059] total steps:[130181] lr:[0.00005000] time: 14.77s (45435s total) loss: 149.797\n",
      "Epoch: [13] [ 9483/10059] total steps:[130191] lr:[0.00005000] time: 14.80s (45450s total) loss: 90.655\n",
      "Epoch: [13] [ 9493/10059] total steps:[130201] lr:[0.00005000] time: 14.89s (45464s total) loss: 122.274\n",
      "Epoch: [13] [ 9503/10059] total steps:[130211] lr:[0.00005000] time: 14.88s (45479s total) loss: 145.064\n",
      "Epoch: [13] [ 9513/10059] total steps:[130221] lr:[0.00005000] time: 14.81s (45494s total) loss: 126.380\n",
      "Epoch: [13] [ 9523/10059] total steps:[130231] lr:[0.00005000] time: 14.77s (45509s total) loss: 140.992\n",
      "Epoch: [13] [ 9533/10059] total steps:[130241] lr:[0.00005000] time: 14.72s (45524s total) loss: 152.495\n",
      "Epoch: [13] [ 9543/10059] total steps:[130251] lr:[0.00005000] time: 14.78s (45538s total) loss: 128.221\n",
      "Epoch: [13] [ 9553/10059] total steps:[130261] lr:[0.00005000] time: 14.73s (45553s total) loss: 121.637\n",
      "Epoch: [13] [ 9563/10059] total steps:[130271] lr:[0.00005000] time: 14.78s (45568s total) loss: 125.611\n",
      "Epoch: [13] [ 9573/10059] total steps:[130281] lr:[0.00005000] time: 14.70s (45583s total) loss: 174.503\n",
      "Epoch: [13] [ 9583/10059] total steps:[130291] lr:[0.00005000] time: 14.81s (45597s total) loss: 130.253\n",
      "Epoch: [13] [ 9593/10059] total steps:[130301] lr:[0.00005000] time: 14.82s (45612s total) loss: 156.024\n",
      "Epoch: [13] [ 9603/10059] total steps:[130311] lr:[0.00005000] time: 14.88s (45627s total) loss: 146.007\n",
      "Epoch: [13] [ 9613/10059] total steps:[130321] lr:[0.00005000] time: 14.95s (45642s total) loss: 140.903\n",
      "Epoch: [13] [ 9623/10059] total steps:[130331] lr:[0.00005000] time: 14.75s (45657s total) loss: 150.288\n",
      "Epoch: [13] [ 9633/10059] total steps:[130341] lr:[0.00005000] time: 14.77s (45672s total) loss: 112.152\n",
      "Epoch: [13] [ 9643/10059] total steps:[130351] lr:[0.00005000] time: 14.76s (45686s total) loss: 176.050\n",
      "Epoch: [13] [ 9653/10059] total steps:[130361] lr:[0.00005000] time: 14.71s (45701s total) loss: 112.604\n",
      "Epoch: [13] [ 9663/10059] total steps:[130371] lr:[0.00005000] time: 14.70s (45716s total) loss: 110.532\n",
      "Epoch: [13] [ 9673/10059] total steps:[130381] lr:[0.00005000] time: 14.71s (45730s total) loss: 166.066\n",
      "Epoch: [13] [ 9683/10059] total steps:[130391] lr:[0.00005000] time: 14.77s (45745s total) loss: 147.997\n",
      "Epoch: [13] [ 9693/10059] total steps:[130401] lr:[0.00005000] time: 14.89s (45760s total) loss: 143.651\n",
      "Epoch: [13] [ 9703/10059] total steps:[130411] lr:[0.00005000] time: 14.72s (45775s total) loss: 162.167\n",
      "Epoch: [13] [ 9713/10059] total steps:[130421] lr:[0.00005000] time: 14.78s (45790s total) loss: 97.658\n",
      "Epoch: [13] [ 9723/10059] total steps:[130431] lr:[0.00005000] time: 14.92s (45805s total) loss: 114.762\n",
      "Epoch: [13] [ 9733/10059] total steps:[130441] lr:[0.00005000] time: 14.80s (45819s total) loss: 164.922\n",
      "Epoch: [13] [ 9743/10059] total steps:[130451] lr:[0.00005000] time: 14.85s (45834s total) loss: 194.356\n",
      "Epoch: [13] [ 9753/10059] total steps:[130461] lr:[0.00005000] time: 14.75s (45849s total) loss: 98.550\n",
      "Epoch: [13] [ 9763/10059] total steps:[130471] lr:[0.00005000] time: 14.76s (45864s total) loss: 122.881\n",
      "Epoch: [13] [ 9773/10059] total steps:[130481] lr:[0.00005000] time: 14.86s (45879s total) loss: 119.600\n",
      "Epoch: [13] [ 9783/10059] total steps:[130491] lr:[0.00005000] time: 14.82s (45893s total) loss: 130.573\n",
      "Epoch: [13] [ 9793/10059] total steps:[130501] lr:[0.00005000] time: 14.86s (45908s total) loss: 143.440\n",
      "Epoch: [13] [ 9803/10059] total steps:[130511] lr:[0.00005000] time: 14.75s (45923s total) loss: 116.156\n",
      "Epoch: [13] [ 9813/10059] total steps:[130521] lr:[0.00005000] time: 14.84s (45938s total) loss: 140.580\n",
      "Epoch: [13] [ 9823/10059] total steps:[130531] lr:[0.00005000] time: 14.85s (45953s total) loss: 172.472\n",
      "Epoch: [13] [ 9833/10059] total steps:[130541] lr:[0.00005000] time: 14.83s (45967s total) loss: 169.156\n",
      "Epoch: [13] [ 9843/10059] total steps:[130551] lr:[0.00005000] time: 14.81s (45982s total) loss: 99.325\n",
      "Epoch: [13] [ 9853/10059] total steps:[130561] lr:[0.00005000] time: 14.85s (45997s total) loss: 130.531\n",
      "Epoch: [13] [ 9863/10059] total steps:[130571] lr:[0.00005000] time: 14.71s (46012s total) loss: 99.994\n",
      "Epoch: [13] [ 9873/10059] total steps:[130581] lr:[0.00005000] time: 14.75s (46027s total) loss: 161.822\n",
      "Epoch: [13] [ 9883/10059] total steps:[130591] lr:[0.00005000] time: 14.65s (46041s total) loss: 123.218\n",
      "Epoch: [13] [ 9893/10059] total steps:[130601] lr:[0.00005000] time: 14.86s (46056s total) loss: 112.995\n",
      "Epoch: [13] [ 9903/10059] total steps:[130611] lr:[0.00005000] time: 14.72s (46071s total) loss: 136.239\n",
      "Epoch: [13] [ 9913/10059] total steps:[130621] lr:[0.00005000] time: 14.78s (46086s total) loss: 186.852\n",
      "Epoch: [13] [ 9923/10059] total steps:[130631] lr:[0.00005000] time: 14.74s (46100s total) loss: 109.820\n",
      "Epoch: [13] [ 9933/10059] total steps:[130641] lr:[0.00005000] time: 14.81s (46115s total) loss: 165.308\n",
      "Epoch: [13] [ 9943/10059] total steps:[130651] lr:[0.00005000] time: 14.70s (46130s total) loss: 159.458\n",
      "Epoch: [13] [ 9953/10059] total steps:[130661] lr:[0.00005000] time: 14.79s (46145s total) loss: 174.107\n",
      "Epoch: [13] [ 9963/10059] total steps:[130671] lr:[0.00005000] time: 14.75s (46159s total) loss: 127.039\n",
      "Epoch: [13] [ 9973/10059] total steps:[130681] lr:[0.00005000] time: 14.79s (46174s total) loss: 176.553\n",
      "Epoch: [13] [ 9983/10059] total steps:[130691] lr:[0.00005000] time: 14.80s (46189s total) loss: 123.754\n",
      "Epoch: [13] [ 9993/10059] total steps:[130701] lr:[0.00005000] time: 14.85s (46204s total) loss: 143.721\n",
      "Epoch: [13] [10003/10059] total steps:[130711] lr:[0.00005000] time: 14.67s (46219s total) loss: 138.492\n",
      "Epoch: [13] [10013/10059] total steps:[130721] lr:[0.00005000] time: 14.73s (46233s total) loss: 94.198\n",
      "Epoch: [13] [10023/10059] total steps:[130731] lr:[0.00005000] time: 14.74s (46248s total) loss: 167.053\n",
      "Epoch: [13] [10033/10059] total steps:[130741] lr:[0.00005000] time: 14.71s (46263s total) loss: 178.395\n",
      "Epoch: [13] [10043/10059] total steps:[130751] lr:[0.00005000] time: 14.80s (46277s total) loss: 144.792\n",
      "Epoch: [13] [10053/10059] total steps:[130761] lr:[0.00005000] time: 14.85s (46292s total) loss: 120.466\n",
      "[Info] Saving checkpoint to ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints ...\n",
      "Epoch: [14] [    4/10059] total steps:[130771] lr:[0.00005000] time: 27.60s (46320s total) loss: 157.570\n",
      "Epoch: [14] [   14/10059] total steps:[130781] lr:[0.00005000] time: 14.64s (46335s total) loss: 115.198\n",
      "Epoch: [14] [   24/10059] total steps:[130791] lr:[0.00005000] time: 14.85s (46349s total) loss: 107.400\n",
      "Epoch: [14] [   34/10059] total steps:[130801] lr:[0.00005000] time: 14.93s (46364s total) loss: 99.876\n",
      "Epoch: [14] [   44/10059] total steps:[130811] lr:[0.00005000] time: 14.70s (46379s total) loss: 120.992\n",
      "Epoch: [14] [   54/10059] total steps:[130821] lr:[0.00005000] time: 14.78s (46394s total) loss: 114.874\n",
      "Epoch: [14] [   64/10059] total steps:[130831] lr:[0.00005000] time: 14.82s (46409s total) loss: 146.153\n",
      "Epoch: [14] [   74/10059] total steps:[130841] lr:[0.00005000] time: 14.87s (46424s total) loss: 113.069\n",
      "Epoch: [14] [   84/10059] total steps:[130851] lr:[0.00005000] time: 14.90s (46438s total) loss: 102.334\n",
      "Epoch: [14] [   94/10059] total steps:[130861] lr:[0.00005000] time: 14.72s (46453s total) loss: 147.417\n",
      "Epoch: [14] [  104/10059] total steps:[130871] lr:[0.00005000] time: 14.72s (46468s total) loss: 136.875\n",
      "Epoch: [14] [  114/10059] total steps:[130881] lr:[0.00005000] time: 14.66s (46483s total) loss: 143.192\n",
      "Epoch: [14] [  124/10059] total steps:[130891] lr:[0.00005000] time: 14.71s (46497s total) loss: 162.234\n",
      "Epoch: [14] [  134/10059] total steps:[130901] lr:[0.00005000] time: 14.82s (46512s total) loss: 170.190\n",
      "Epoch: [14] [  144/10059] total steps:[130911] lr:[0.00005000] time: 14.85s (46527s total) loss: 133.055\n",
      "Epoch: [14] [  154/10059] total steps:[130921] lr:[0.00005000] time: 14.68s (46542s total) loss: 118.845\n",
      "Epoch: [14] [  164/10059] total steps:[130931] lr:[0.00005000] time: 14.70s (46556s total) loss: 120.677\n",
      "Epoch: [14] [  174/10059] total steps:[130941] lr:[0.00005000] time: 14.84s (46571s total) loss: 140.603\n",
      "Epoch: [14] [  184/10059] total steps:[130951] lr:[0.00005000] time: 14.91s (46586s total) loss: 160.851\n",
      "Epoch: [14] [  194/10059] total steps:[130961] lr:[0.00005000] time: 14.81s (46601s total) loss: 179.995\n",
      "Epoch: [14] [  204/10059] total steps:[130971] lr:[0.00005000] time: 14.77s (46616s total) loss: 172.891\n",
      "Epoch: [14] [  214/10059] total steps:[130981] lr:[0.00005000] time: 14.80s (46630s total) loss: 122.984\n",
      "Epoch: [14] [  224/10059] total steps:[130991] lr:[0.00005000] time: 14.77s (46645s total) loss: 185.872\n",
      "Epoch: [14] [  234/10059] total steps:[131001] lr:[0.00005000] time: 14.80s (46660s total) loss: 128.993\n",
      "Epoch: [14] [  244/10059] total steps:[131011] lr:[0.00005000] time: 14.90s (46675s total) loss: 121.720\n",
      "Epoch: [14] [  254/10059] total steps:[131021] lr:[0.00005000] time: 14.71s (46690s total) loss: 149.340\n",
      "Epoch: [14] [  264/10059] total steps:[131031] lr:[0.00005000] time: 14.80s (46704s total) loss: 142.373\n",
      "Epoch: [14] [  274/10059] total steps:[131041] lr:[0.00005000] time: 14.65s (46719s total) loss: 116.388\n",
      "Epoch: [14] [  284/10059] total steps:[131051] lr:[0.00005000] time: 14.72s (46734s total) loss: 134.879\n",
      "Epoch: [14] [  294/10059] total steps:[131061] lr:[0.00005000] time: 14.78s (46749s total) loss: 97.937\n",
      "Epoch: [14] [  304/10059] total steps:[131071] lr:[0.00005000] time: 14.85s (46763s total) loss: 158.937\n",
      "Epoch: [14] [  314/10059] total steps:[131081] lr:[0.00005000] time: 14.86s (46778s total) loss: 167.820\n",
      "Epoch: [14] [  324/10059] total steps:[131091] lr:[0.00005000] time: 14.70s (46793s total) loss: 134.990\n",
      "Epoch: [14] [  334/10059] total steps:[131101] lr:[0.00005000] time: 14.97s (46808s total) loss: 104.660\n",
      "Epoch: [14] [  344/10059] total steps:[131111] lr:[0.00005000] time: 14.79s (46823s total) loss: 117.052\n",
      "Epoch: [14] [  354/10059] total steps:[131121] lr:[0.00005000] time: 14.63s (46837s total) loss: 133.901\n",
      "Epoch: [14] [  364/10059] total steps:[131131] lr:[0.00005000] time: 14.83s (46852s total) loss: 154.768\n",
      "Epoch: [14] [  374/10059] total steps:[131141] lr:[0.00005000] time: 14.76s (46867s total) loss: 98.827\n",
      "Epoch: [14] [  384/10059] total steps:[131151] lr:[0.00005000] time: 14.77s (46882s total) loss: 138.578\n",
      "Epoch: [14] [  394/10059] total steps:[131161] lr:[0.00005000] time: 14.73s (46896s total) loss: 144.264\n",
      "Epoch: [14] [  404/10059] total steps:[131171] lr:[0.00005000] time: 14.76s (46911s total) loss: 83.391\n",
      "Epoch: [14] [  414/10059] total steps:[131181] lr:[0.00005000] time: 14.89s (46926s total) loss: 106.967\n",
      "Epoch: [14] [  424/10059] total steps:[131191] lr:[0.00005000] time: 14.86s (46941s total) loss: 141.631\n",
      "Epoch: [14] [  434/10059] total steps:[131201] lr:[0.00005000] time: 14.82s (46956s total) loss: 140.236\n",
      "Epoch: [14] [  444/10059] total steps:[131211] lr:[0.00005000] time: 14.82s (46971s total) loss: 130.368\n",
      "Epoch: [14] [  454/10059] total steps:[131221] lr:[0.00005000] time: 14.80s (46985s total) loss: 201.875\n",
      "Epoch: [14] [  464/10059] total steps:[131231] lr:[0.00005000] time: 14.70s (47000s total) loss: 96.291\n",
      "Epoch: [14] [  474/10059] total steps:[131241] lr:[0.00005000] time: 14.82s (47015s total) loss: 121.448\n",
      "Epoch: [14] [  484/10059] total steps:[131251] lr:[0.00005000] time: 14.71s (47030s total) loss: 122.058\n",
      "Epoch: [14] [  494/10059] total steps:[131261] lr:[0.00005000] time: 14.87s (47044s total) loss: 120.109\n",
      "Epoch: [14] [  504/10059] total steps:[131271] lr:[0.00005000] time: 14.82s (47059s total) loss: 134.762\n",
      "Epoch: [14] [  514/10059] total steps:[131281] lr:[0.00005000] time: 14.69s (47074s total) loss: 116.913\n",
      "Epoch: [14] [  524/10059] total steps:[131291] lr:[0.00005000] time: 14.72s (47089s total) loss: 121.419\n",
      "Epoch: [14] [  534/10059] total steps:[131301] lr:[0.00005000] time: 14.81s (47104s total) loss: 127.618\n",
      "Epoch: [14] [  544/10059] total steps:[131311] lr:[0.00005000] time: 14.85s (47118s total) loss: 115.655\n",
      "Epoch: [14] [  554/10059] total steps:[131321] lr:[0.00005000] time: 14.74s (47133s total) loss: 134.851\n",
      "Epoch: [14] [  564/10059] total steps:[131331] lr:[0.00005000] time: 14.77s (47148s total) loss: 108.852\n",
      "Epoch: [14] [  574/10059] total steps:[131341] lr:[0.00005000] time: 14.88s (47163s total) loss: 103.932\n",
      "Epoch: [14] [  584/10059] total steps:[131351] lr:[0.00005000] time: 14.85s (47178s total) loss: 126.422\n",
      "Epoch: [14] [  594/10059] total steps:[131361] lr:[0.00005000] time: 14.82s (47192s total) loss: 90.689\n",
      "Epoch: [14] [  604/10059] total steps:[131371] lr:[0.00005000] time: 14.83s (47207s total) loss: 124.982\n",
      "Epoch: [14] [  614/10059] total steps:[131381] lr:[0.00005000] time: 14.72s (47222s total) loss: 130.811\n",
      "Epoch: [14] [  624/10059] total steps:[131391] lr:[0.00005000] time: 14.93s (47237s total) loss: 87.864\n",
      "Epoch: [14] [  634/10059] total steps:[131401] lr:[0.00005000] time: 14.95s (47252s total) loss: 144.499\n",
      "Epoch: [14] [  644/10059] total steps:[131411] lr:[0.00005000] time: 14.89s (47267s total) loss: 126.291\n",
      "Epoch: [14] [  654/10059] total steps:[131421] lr:[0.00005000] time: 14.81s (47282s total) loss: 203.662\n",
      "Epoch: [14] [  664/10059] total steps:[131431] lr:[0.00005000] time: 14.77s (47296s total) loss: 87.633\n",
      "Epoch: [14] [  674/10059] total steps:[131441] lr:[0.00005000] time: 14.89s (47311s total) loss: 137.229\n",
      "Epoch: [14] [  684/10059] total steps:[131451] lr:[0.00005000] time: 14.74s (47326s total) loss: 132.800\n",
      "Epoch: [14] [  694/10059] total steps:[131461] lr:[0.00005000] time: 14.76s (47341s total) loss: 144.684\n",
      "Epoch: [14] [  704/10059] total steps:[131471] lr:[0.00005000] time: 14.68s (47355s total) loss: 126.941\n",
      "Epoch: [14] [  714/10059] total steps:[131481] lr:[0.00005000] time: 14.69s (47370s total) loss: 121.085\n",
      "Epoch: [14] [  724/10059] total steps:[131491] lr:[0.00005000] time: 14.75s (47385s total) loss: 145.552\n",
      "Epoch: [14] [  734/10059] total steps:[131501] lr:[0.00005000] time: 14.79s (47400s total) loss: 162.343\n",
      "Epoch: [14] [  744/10059] total steps:[131511] lr:[0.00005000] time: 14.72s (47414s total) loss: 156.182\n",
      "Epoch: [14] [  754/10059] total steps:[131521] lr:[0.00005000] time: 14.71s (47429s total) loss: 151.253\n",
      "Epoch: [14] [  764/10059] total steps:[131531] lr:[0.00005000] time: 14.79s (47444s total) loss: 126.406\n",
      "Epoch: [14] [  774/10059] total steps:[131541] lr:[0.00005000] time: 14.73s (47459s total) loss: 142.913\n",
      "Epoch: [14] [  784/10059] total steps:[131551] lr:[0.00005000] time: 14.73s (47473s total) loss: 152.533\n",
      "Epoch: [14] [  794/10059] total steps:[131561] lr:[0.00005000] time: 14.74s (47488s total) loss: 145.165\n",
      "Epoch: [14] [  804/10059] total steps:[131571] lr:[0.00005000] time: 14.80s (47503s total) loss: 177.325\n",
      "Epoch: [14] [  814/10059] total steps:[131581] lr:[0.00005000] time: 14.80s (47518s total) loss: 116.516\n",
      "Epoch: [14] [  824/10059] total steps:[131591] lr:[0.00005000] time: 14.71s (47532s total) loss: 131.551\n",
      "Epoch: [14] [  834/10059] total steps:[131601] lr:[0.00005000] time: 14.69s (47547s total) loss: 129.094\n",
      "Epoch: [14] [  844/10059] total steps:[131611] lr:[0.00005000] time: 14.86s (47562s total) loss: 175.504\n",
      "Epoch: [14] [  854/10059] total steps:[131621] lr:[0.00005000] time: 14.88s (47577s total) loss: 141.982\n",
      "Epoch: [14] [  864/10059] total steps:[131631] lr:[0.00005000] time: 14.80s (47592s total) loss: 157.693\n",
      "Epoch: [14] [  874/10059] total steps:[131641] lr:[0.00005000] time: 14.79s (47606s total) loss: 132.419\n",
      "Epoch: [14] [  884/10059] total steps:[131651] lr:[0.00005000] time: 14.74s (47621s total) loss: 132.684\n",
      "Epoch: [14] [  894/10059] total steps:[131661] lr:[0.00005000] time: 14.83s (47636s total) loss: 148.130\n",
      "Epoch: [14] [  904/10059] total steps:[131671] lr:[0.00005000] time: 14.79s (47651s total) loss: 159.544\n",
      "Epoch: [14] [  914/10059] total steps:[131681] lr:[0.00005000] time: 16.18s (47667s total) loss: 135.801\n",
      "Epoch: [14] [  924/10059] total steps:[131691] lr:[0.00005000] time: 14.81s (47682s total) loss: 126.775\n",
      "Epoch: [14] [  934/10059] total steps:[131701] lr:[0.00005000] time: 14.78s (47696s total) loss: 103.303\n",
      "Epoch: [14] [  944/10059] total steps:[131711] lr:[0.00005000] time: 14.77s (47711s total) loss: 154.513\n",
      "Epoch: [14] [  954/10059] total steps:[131721] lr:[0.00005000] time: 14.86s (47726s total) loss: 142.770\n",
      "Epoch: [14] [  964/10059] total steps:[131731] lr:[0.00005000] time: 14.74s (47741s total) loss: 162.933\n",
      "Epoch: [14] [  974/10059] total steps:[131741] lr:[0.00005000] time: 14.73s (47756s total) loss: 103.483\n",
      "Epoch: [14] [  984/10059] total steps:[131751] lr:[0.00005000] time: 14.71s (47770s total) loss: 122.368\n",
      "Epoch: [14] [  994/10059] total steps:[131761] lr:[0.00005000] time: 14.77s (47785s total) loss: 143.056\n",
      "Epoch: [14] [ 1004/10059] total steps:[131771] lr:[0.00005000] time: 14.68s (47800s total) loss: 116.094\n",
      "Epoch: [14] [ 1014/10059] total steps:[131781] lr:[0.00005000] time: 14.83s (47815s total) loss: 144.789\n",
      "Epoch: [14] [ 1024/10059] total steps:[131791] lr:[0.00005000] time: 14.83s (47829s total) loss: 139.577\n",
      "Epoch: [14] [ 1034/10059] total steps:[131801] lr:[0.00005000] time: 14.80s (47844s total) loss: 166.355\n",
      "Epoch: [14] [ 1044/10059] total steps:[131811] lr:[0.00005000] time: 14.70s (47859s total) loss: 140.824\n",
      "Epoch: [14] [ 1054/10059] total steps:[131821] lr:[0.00005000] time: 14.67s (47874s total) loss: 138.596\n",
      "Epoch: [14] [ 1064/10059] total steps:[131831] lr:[0.00005000] time: 14.82s (47888s total) loss: 174.043\n",
      "Epoch: [14] [ 1074/10059] total steps:[131841] lr:[0.00005000] time: 14.83s (47903s total) loss: 161.419\n",
      "Epoch: [14] [ 1084/10059] total steps:[131851] lr:[0.00005000] time: 14.82s (47918s total) loss: 102.455\n",
      "Epoch: [14] [ 1094/10059] total steps:[131861] lr:[0.00005000] time: 14.81s (47933s total) loss: 141.601\n",
      "Epoch: [14] [ 1104/10059] total steps:[131871] lr:[0.00005000] time: 14.69s (47948s total) loss: 102.931\n",
      "Epoch: [14] [ 1114/10059] total steps:[131881] lr:[0.00005000] time: 14.88s (47962s total) loss: 129.540\n",
      "Epoch: [14] [ 1124/10059] total steps:[131891] lr:[0.00005000] time: 14.82s (47977s total) loss: 151.862\n",
      "Epoch: [14] [ 1134/10059] total steps:[131901] lr:[0.00005000] time: 14.72s (47992s total) loss: 173.913\n",
      "Epoch: [14] [ 1144/10059] total steps:[131911] lr:[0.00005000] time: 14.78s (48007s total) loss: 175.765\n",
      "Epoch: [14] [ 1154/10059] total steps:[131921] lr:[0.00005000] time: 14.81s (48022s total) loss: 124.352\n",
      "Epoch: [14] [ 1164/10059] total steps:[131931] lr:[0.00005000] time: 14.75s (48036s total) loss: 193.471\n",
      "Epoch: [14] [ 1174/10059] total steps:[131941] lr:[0.00005000] time: 14.78s (48051s total) loss: 152.161\n",
      "Epoch: [14] [ 1184/10059] total steps:[131951] lr:[0.00005000] time: 14.75s (48066s total) loss: 94.541\n",
      "Epoch: [14] [ 1194/10059] total steps:[131961] lr:[0.00005000] time: 14.82s (48081s total) loss: 175.350\n",
      "Epoch: [14] [ 1204/10059] total steps:[131971] lr:[0.00005000] time: 14.82s (48095s total) loss: 153.304\n",
      "Epoch: [14] [ 1214/10059] total steps:[131981] lr:[0.00005000] time: 14.77s (48110s total) loss: 119.902\n",
      "Epoch: [14] [ 1224/10059] total steps:[131991] lr:[0.00005000] time: 14.74s (48125s total) loss: 168.065\n",
      "Epoch: [14] [ 1234/10059] total steps:[132001] lr:[0.00005000] time: 14.85s (48140s total) loss: 133.937\n",
      "Epoch: [14] [ 1244/10059] total steps:[132011] lr:[0.00005000] time: 14.86s (48155s total) loss: 134.432\n",
      "Epoch: [14] [ 1254/10059] total steps:[132021] lr:[0.00005000] time: 14.86s (48170s total) loss: 164.017\n",
      "Epoch: [14] [ 1264/10059] total steps:[132031] lr:[0.00005000] time: 14.77s (48184s total) loss: 96.837\n",
      "Epoch: [14] [ 1274/10059] total steps:[132041] lr:[0.00005000] time: 14.82s (48199s total) loss: 136.167\n",
      "Epoch: [14] [ 1284/10059] total steps:[132051] lr:[0.00005000] time: 14.84s (48214s total) loss: 167.721\n",
      "Epoch: [14] [ 1294/10059] total steps:[132061] lr:[0.00005000] time: 14.79s (48229s total) loss: 121.603\n",
      "Epoch: [14] [ 1304/10059] total steps:[132071] lr:[0.00005000] time: 14.73s (48244s total) loss: 109.159\n",
      "Epoch: [14] [ 1314/10059] total steps:[132081] lr:[0.00005000] time: 14.80s (48258s total) loss: 103.651\n",
      "Epoch: [14] [ 1324/10059] total steps:[132091] lr:[0.00005000] time: 14.81s (48273s total) loss: 92.905\n",
      "Epoch: [14] [ 1334/10059] total steps:[132101] lr:[0.00005000] time: 14.86s (48288s total) loss: 146.815\n",
      "Epoch: [14] [ 1344/10059] total steps:[132111] lr:[0.00005000] time: 14.79s (48303s total) loss: 142.390\n",
      "Epoch: [14] [ 1354/10059] total steps:[132121] lr:[0.00005000] time: 14.86s (48318s total) loss: 169.436\n",
      "Epoch: [14] [ 1364/10059] total steps:[132131] lr:[0.00005000] time: 14.76s (48332s total) loss: 126.976\n",
      "Epoch: [14] [ 1374/10059] total steps:[132141] lr:[0.00005000] time: 14.77s (48347s total) loss: 129.155\n",
      "Epoch: [14] [ 1384/10059] total steps:[132151] lr:[0.00005000] time: 14.71s (48362s total) loss: 94.735\n",
      "Epoch: [14] [ 1394/10059] total steps:[132161] lr:[0.00005000] time: 14.93s (48377s total) loss: 132.555\n",
      "Epoch: [14] [ 1404/10059] total steps:[132171] lr:[0.00005000] time: 14.70s (48392s total) loss: 128.058\n",
      "Epoch: [14] [ 1414/10059] total steps:[132181] lr:[0.00005000] time: 14.94s (48406s total) loss: 124.231\n",
      "Epoch: [14] [ 1424/10059] total steps:[132191] lr:[0.00005000] time: 14.80s (48421s total) loss: 161.481\n",
      "Epoch: [14] [ 1434/10059] total steps:[132201] lr:[0.00005000] time: 14.86s (48436s total) loss: 151.361\n",
      "Epoch: [14] [ 1444/10059] total steps:[132211] lr:[0.00005000] time: 14.76s (48451s total) loss: 127.978\n",
      "Epoch: [14] [ 1454/10059] total steps:[132221] lr:[0.00005000] time: 14.84s (48466s total) loss: 153.989\n",
      "Epoch: [14] [ 1464/10059] total steps:[132231] lr:[0.00005000] time: 14.82s (48481s total) loss: 120.305\n",
      "Epoch: [14] [ 1474/10059] total steps:[132241] lr:[0.00005000] time: 14.86s (48495s total) loss: 133.525\n",
      "Epoch: [14] [ 1484/10059] total steps:[132251] lr:[0.00005000] time: 14.90s (48510s total) loss: 121.652\n",
      "Epoch: [14] [ 1494/10059] total steps:[132261] lr:[0.00005000] time: 14.90s (48525s total) loss: 144.638\n",
      "Epoch: [14] [ 1504/10059] total steps:[132271] lr:[0.00005000] time: 14.92s (48540s total) loss: 154.768\n",
      "Epoch: [14] [ 1514/10059] total steps:[132281] lr:[0.00005000] time: 14.80s (48555s total) loss: 138.443\n",
      "Epoch: [14] [ 1524/10059] total steps:[132291] lr:[0.00005000] time: 14.80s (48570s total) loss: 120.814\n",
      "Epoch: [14] [ 1534/10059] total steps:[132301] lr:[0.00005000] time: 14.74s (48584s total) loss: 169.171\n",
      "Epoch: [14] [ 1544/10059] total steps:[132311] lr:[0.00005000] time: 14.81s (48599s total) loss: 103.194\n",
      "Epoch: [14] [ 1554/10059] total steps:[132321] lr:[0.00005000] time: 14.68s (48614s total) loss: 143.737\n",
      "Epoch: [14] [ 1564/10059] total steps:[132331] lr:[0.00005000] time: 14.79s (48629s total) loss: 198.329\n",
      "Epoch: [14] [ 1574/10059] total steps:[132341] lr:[0.00005000] time: 14.81s (48644s total) loss: 128.510\n",
      "Epoch: [14] [ 1584/10059] total steps:[132351] lr:[0.00005000] time: 14.82s (48658s total) loss: 128.894\n",
      "Epoch: [14] [ 1594/10059] total steps:[132361] lr:[0.00005000] time: 14.67s (48673s total) loss: 131.902\n",
      "Epoch: [14] [ 1604/10059] total steps:[132371] lr:[0.00005000] time: 14.78s (48688s total) loss: 167.782\n",
      "Epoch: [14] [ 1614/10059] total steps:[132381] lr:[0.00005000] time: 14.90s (48703s total) loss: 141.529\n",
      "Epoch: [14] [ 1624/10059] total steps:[132391] lr:[0.00005000] time: 14.75s (48717s total) loss: 129.362\n",
      "Epoch: [14] [ 1634/10059] total steps:[132401] lr:[0.00005000] time: 15.01s (48732s total) loss: 106.343\n",
      "Epoch: [14] [ 1644/10059] total steps:[132411] lr:[0.00005000] time: 14.86s (48747s total) loss: 147.241\n",
      "Epoch: [14] [ 1654/10059] total steps:[132421] lr:[0.00005000] time: 14.78s (48762s total) loss: 110.935\n",
      "Epoch: [14] [ 1664/10059] total steps:[132431] lr:[0.00005000] time: 14.71s (48777s total) loss: 120.732\n",
      "Epoch: [14] [ 1674/10059] total steps:[132441] lr:[0.00005000] time: 14.71s (48792s total) loss: 161.322\n",
      "Epoch: [14] [ 1684/10059] total steps:[132451] lr:[0.00005000] time: 14.74s (48806s total) loss: 105.236\n",
      "Epoch: [14] [ 1694/10059] total steps:[132461] lr:[0.00005000] time: 14.81s (48821s total) loss: 112.081\n",
      "Epoch: [14] [ 1704/10059] total steps:[132471] lr:[0.00005000] time: 14.77s (48836s total) loss: 138.512\n",
      "Epoch: [14] [ 1714/10059] total steps:[132481] lr:[0.00005000] time: 14.81s (48851s total) loss: 152.785\n",
      "Epoch: [14] [ 1724/10059] total steps:[132491] lr:[0.00005000] time: 14.84s (48865s total) loss: 118.289\n",
      "Epoch: [14] [ 1734/10059] total steps:[132501] lr:[0.00005000] time: 14.91s (48880s total) loss: 89.968\n",
      "Epoch: [14] [ 1744/10059] total steps:[132511] lr:[0.00005000] time: 14.73s (48895s total) loss: 173.672\n",
      "Epoch: [14] [ 1754/10059] total steps:[132521] lr:[0.00005000] time: 14.82s (48910s total) loss: 146.297\n",
      "Epoch: [14] [ 1764/10059] total steps:[132531] lr:[0.00005000] time: 14.83s (48925s total) loss: 124.941\n",
      "Epoch: [14] [ 1774/10059] total steps:[132541] lr:[0.00005000] time: 14.76s (48940s total) loss: 146.479\n",
      "Epoch: [14] [ 1784/10059] total steps:[132551] lr:[0.00005000] time: 14.88s (48954s total) loss: 97.614\n",
      "Epoch: [14] [ 1794/10059] total steps:[132561] lr:[0.00005000] time: 14.80s (48969s total) loss: 156.590\n",
      "Epoch: [14] [ 1804/10059] total steps:[132571] lr:[0.00005000] time: 14.71s (48984s total) loss: 189.699\n",
      "Epoch: [14] [ 1814/10059] total steps:[132581] lr:[0.00005000] time: 14.67s (48999s total) loss: 170.190\n",
      "Epoch: [14] [ 1824/10059] total steps:[132591] lr:[0.00005000] time: 14.65s (49013s total) loss: 123.945\n",
      "Epoch: [14] [ 1834/10059] total steps:[132601] lr:[0.00005000] time: 14.87s (49028s total) loss: 124.636\n",
      "Epoch: [14] [ 1844/10059] total steps:[132611] lr:[0.00005000] time: 14.75s (49043s total) loss: 134.156\n",
      "Epoch: [14] [ 1854/10059] total steps:[132621] lr:[0.00005000] time: 14.81s (49058s total) loss: 140.419\n",
      "Epoch: [14] [ 1864/10059] total steps:[132631] lr:[0.00005000] time: 14.76s (49072s total) loss: 135.870\n",
      "Epoch: [14] [ 1874/10059] total steps:[132641] lr:[0.00005000] time: 14.82s (49087s total) loss: 129.584\n",
      "Epoch: [14] [ 1884/10059] total steps:[132651] lr:[0.00005000] time: 14.73s (49102s total) loss: 168.591\n",
      "Epoch: [14] [ 1894/10059] total steps:[132661] lr:[0.00005000] time: 14.86s (49117s total) loss: 137.719\n",
      "Epoch: [14] [ 1904/10059] total steps:[132671] lr:[0.00005000] time: 14.78s (49132s total) loss: 109.332\n",
      "Epoch: [14] [ 1914/10059] total steps:[132681] lr:[0.00005000] time: 14.80s (49146s total) loss: 124.143\n",
      "Epoch: [14] [ 1924/10059] total steps:[132691] lr:[0.00005000] time: 14.78s (49161s total) loss: 97.192\n",
      "Epoch: [14] [ 1934/10059] total steps:[132701] lr:[0.00005000] time: 14.80s (49176s total) loss: 127.556\n",
      "Epoch: [14] [ 1944/10059] total steps:[132711] lr:[0.00005000] time: 14.77s (49191s total) loss: 174.841\n",
      "Epoch: [14] [ 1954/10059] total steps:[132721] lr:[0.00005000] time: 14.79s (49206s total) loss: 82.789\n",
      "Epoch: [14] [ 1964/10059] total steps:[132731] lr:[0.00005000] time: 14.74s (49220s total) loss: 162.345\n",
      "Epoch: [14] [ 1974/10059] total steps:[132741] lr:[0.00005000] time: 14.92s (49235s total) loss: 129.483\n",
      "Epoch: [14] [ 1984/10059] total steps:[132751] lr:[0.00005000] time: 14.77s (49250s total) loss: 109.717\n",
      "Epoch: [14] [ 1994/10059] total steps:[132761] lr:[0.00005000] time: 14.83s (49265s total) loss: 160.784\n",
      "Epoch: [14] [ 2004/10059] total steps:[132771] lr:[0.00005000] time: 14.72s (49280s total) loss: 125.295\n",
      "Epoch: [14] [ 2014/10059] total steps:[132781] lr:[0.00005000] time: 14.95s (49295s total) loss: 100.051\n",
      "Epoch: [14] [ 2024/10059] total steps:[132791] lr:[0.00005000] time: 14.84s (49309s total) loss: 106.763\n",
      "Epoch: [14] [ 2034/10059] total steps:[132801] lr:[0.00005000] time: 14.77s (49324s total) loss: 137.410\n",
      "Epoch: [14] [ 2044/10059] total steps:[132811] lr:[0.00005000] time: 14.78s (49339s total) loss: 108.325\n",
      "Epoch: [14] [ 2054/10059] total steps:[132821] lr:[0.00005000] time: 14.67s (49354s total) loss: 194.380\n",
      "Epoch: [14] [ 2064/10059] total steps:[132831] lr:[0.00005000] time: 14.78s (49368s total) loss: 133.753\n",
      "Epoch: [14] [ 2074/10059] total steps:[132841] lr:[0.00005000] time: 14.71s (49383s total) loss: 131.844\n",
      "Epoch: [14] [ 2084/10059] total steps:[132851] lr:[0.00005000] time: 14.79s (49398s total) loss: 162.919\n",
      "Epoch: [14] [ 2094/10059] total steps:[132861] lr:[0.00005000] time: 14.73s (49413s total) loss: 81.770\n",
      "Epoch: [14] [ 2104/10059] total steps:[132871] lr:[0.00005000] time: 14.85s (49427s total) loss: 155.374\n",
      "Epoch: [14] [ 2114/10059] total steps:[132881] lr:[0.00005000] time: 14.72s (49442s total) loss: 157.643\n",
      "Epoch: [14] [ 2124/10059] total steps:[132891] lr:[0.00005000] time: 14.88s (49457s total) loss: 116.550\n",
      "Epoch: [14] [ 2134/10059] total steps:[132901] lr:[0.00005000] time: 14.83s (49472s total) loss: 103.828\n",
      "Epoch: [14] [ 2144/10059] total steps:[132911] lr:[0.00005000] time: 14.76s (49487s total) loss: 123.108\n",
      "Epoch: [14] [ 2154/10059] total steps:[132921] lr:[0.00005000] time: 14.75s (49501s total) loss: 180.114\n",
      "Epoch: [14] [ 2164/10059] total steps:[132931] lr:[0.00005000] time: 14.66s (49516s total) loss: 130.318\n",
      "Epoch: [14] [ 2174/10059] total steps:[132941] lr:[0.00005000] time: 14.94s (49531s total) loss: 144.008\n",
      "Epoch: [14] [ 2184/10059] total steps:[132951] lr:[0.00005000] time: 14.76s (49546s total) loss: 168.422\n",
      "Epoch: [14] [ 2194/10059] total steps:[132961] lr:[0.00005000] time: 14.70s (49560s total) loss: 175.055\n"
     ]
    }
   ],
   "source": [
    "%run ./main.py -c ../config/dp3.ini -t train_dp \\\n",
    "--cont_model=../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-100591 \\\n",
    "--restore_flow_model=../results/KITTI_RAW_256_832_UnDepthflow_flow_pwc_b8_3frames/checkpoints/kitti_3frames/model-392302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Evaluate kitti depth...\n",
      "[Info] Reading datalist from: /home/garin/Documents/depth/src/kitti_eval/kitti/test_files_eigen.txt\n",
      "[Info] Loading images from: /home/waterman/dataset/KITTI\n",
      "[Info] Reshaing image to size: (256, 832)\n",
      "[Info] Restoring model: ../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-100591\n",
      "[Info] Data number: 697\n",
      "[Info] FPS: 25.820\n",
      "[Info] Saving to ../results/kitti/test_kitti.npy\n"
     ]
    }
   ],
   "source": [
    "%run ./main.py -c ../config/test_dp_kitti.ini -t kitti_eval \\\n",
    "--restore_dp_model=../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_all_3frames/checkpoints/kitti_3frames/model-100591\n",
    "# --restore_dp_model=../results/KITTI_RAW_128_416_UnDepthflow_dp_b4_resnet50_3frames/checkpoints/kitti_3frames/model-342007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ../results/kitti/test_kitti.npy...\n",
      "[Info] Saving depth resutls to: ../results/kitti_depths\n",
      "[NUM TEST]: 697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garin/Documents/depth/src/kitti_eval/eval_depth.py:127: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  misc.imsave(\"%s/%s_pred_depth.png\" % (depth_path, filename), colored_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   abs_rel,     sq_rel,        rms,    log_rms,         a1,         a2,         a3\n",
      "    0.1591,     1.3648,     5.8362,     0.2329,     0.7923,     0.9313,     0.9729\n"
     ]
    }
   ],
   "source": [
    "%run kitti_eval/eval_depth.py --split=eigen --kitti_dir=/home/waterman/dataset/KITTI/ \\\n",
    "--pred_file=../results/kitti/test_kitti.npy \\\n",
    "--depth_results=../results/kitti_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 將結果傳回本地端 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scp -r -P 2222 garin@140.113.214.40:/home/garin/Documents/depth/results/kitti_depths/ C:/Users/Garin/Desktop/學長畢業資料/實驗程式yu/result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tensorboard --logdir=../results/KITTI_RAW_256_832_UnDepthflow_dp_b4_ShuffleNetV2_3frames/ \\\n",
    "--samples_per_plugin images=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5_tf1.9",
   "language": "python",
   "name": "python3.5_tf1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
