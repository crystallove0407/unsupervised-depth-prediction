{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 選擇使用的GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select one or several free gpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "# use CPU only\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 到當前資料夾\n",
    "- cd C:/Users/Garin/Desktop/學長畢業資料/實驗程式yu/\n",
    "\n",
    "## 3. 同步程式\n",
    "### - local -> server\n",
    "- scp -r -P 2222 ./config garin@140.113.214.40:/home/garin/Documents/depth/\n",
    "- scp -r -P 2222 ./src garin@140.113.214.40:/home/garin/Documents/depth/\n",
    "\n",
    "### - server -> local \n",
    "- scp -r -P 2222 garin@140.113.214.40:/home/garin/Documents/depth/config .\n",
    "- scp -r -P 2222 garin@140.113.214.40:/home/garin/Documents/depth/src ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_preparation/kitti_data_prepare.py \\\n",
    "--dataset_dir=/work/garin0115/datasets/KITTI/ \\\n",
    "--dataset_name=kitti_raw_eigen \\\n",
    "--dump_root=/home/garin0115/datasets/kitti_3frames_256_832/ \\\n",
    "--seq_length=3 \\\n",
    "--img_height=256 \\\n",
    "--img_width=832 \\\n",
    "--num_threads=32 \\\n",
    "--remove_static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./main.py -c ../config/flow3.ini -t train_flow --cont_model=../results/KITTI_RAW_128_416_UnDepthflow_flow_pwc_b8_3frames/checkpoints/kitti_3frames/model-170987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train depth & pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.104826 139668652537600 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/garin0115/depth/unsupervised-depth-prediction/src/data_loader/data_loader.py:51: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.282510 139668652537600 deprecation.py:323] From /home/garin0115/depth/unsupervised-depth-prediction/src/data_loader/data_loader.py:51: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.411926 139668652537600 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.414656 139668652537600 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.417333 139668652537600 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.419424 139668652537600 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.420748 139668652537600 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/garin0115/depth/unsupervised-depth-prediction/src/data_loader/data_loader.py:58: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.550945 139668652537600 deprecation.py:323] From /home/garin0115/depth/unsupervised-depth-prediction/src/data_loader/data_loader.py:58: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/garin0115/depth/unsupervised-depth-prediction/src/data_loader/data_loader.py:85: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.554577 139668652537600 deprecation.py:323] From /home/garin0115/depth/unsupervised-depth-prediction/src/data_loader/data_loader.py:85: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/garin0115/depth/unsupervised-depth-prediction/src/data_loader/data_loader.py:139: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:22:50.809213 139668652537600 deprecation.py:323] From /home/garin0115/depth/unsupervised-depth-prediction/src/data_loader/data_loader.py:139: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Loading the model for 3 frames...\n",
      "[Info] Building depth and pose network ...\n",
      "[Info] img_height: 256 img_width 832\n",
      "[Downsample] out, out_channel: 24 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Downsample] out, out_channel: 116 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Downsample] out, out_channel: 232 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "skip[0]: (4, 128, 416, 24)\n",
      "skip[1]: (4, 64, 208, 24)\n",
      "skip[2]: (4, 32, 104, 116)\n",
      "skip[3]: (4, 16, 52, 232)\n",
      "skip[4]: (4, 8, 26, 464)\n",
      "[Downsample] out, out_channel: 24 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Downsample] out, out_channel: 116 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Downsample] out, out_channel: 232 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "skip[0]: (4, 128, 416, 24)\n",
      "skip[1]: (4, 64, 208, 24)\n",
      "skip[2]: (4, 32, 104, 116)\n",
      "skip[3]: (4, 16, 52, 232)\n",
      "skip[4]: (4, 8, 26, 464)\n",
      "[Downsample] out, out_channel: 24 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Downsample] out, out_channel: 116 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Downsample] out, out_channel: 232 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "skip[0]: (4, 128, 416, 24)\n",
      "skip[1]: (4, 64, 208, 24)\n",
      "skip[2]: (4, 32, 104, 116)\n",
      "skip[3]: (4, 16, 52, 232)\n",
      "skip[4]: (4, 8, 26, 464)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:23:38.079360 139668652537600 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Building depth and pose network ...\n",
      "[Info] img_height: 256 img_width 832\n",
      "[Downsample] out, out_channel: 24 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Downsample] out, out_channel: 116 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Downsample] out, out_channel: 232 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "skip[0]: (4, 128, 416, 24)\n",
      "skip[1]: (4, 64, 208, 24)\n",
      "skip[2]: (4, 32, 104, 116)\n",
      "skip[3]: (4, 16, 52, 232)\n",
      "skip[4]: (4, 8, 26, 464)\n",
      "[Downsample] out, out_channel: 24 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Downsample] out, out_channel: 116 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Downsample] out, out_channel: 232 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "skip[0]: (4, 128, 416, 24)\n",
      "skip[1]: (4, 64, 208, 24)\n",
      "skip[2]: (4, 32, 104, 116)\n",
      "skip[3]: (4, 16, 52, 232)\n",
      "skip[4]: (4, 8, 26, 464)\n",
      "[Downsample] out, out_channel: 24 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Rest] out, out_channel: 116 116\n",
      "[Downsample] out, out_channel: 116 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Rest] out, out_channel: 232 232\n",
      "[Downsample] out, out_channel: 232 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "[Rest] out, out_channel: 464 464\n",
      "skip[0]: (4, 128, 416, 24)\n",
      "skip[1]: (4, 64, 208, 24)\n",
      "skip[2]: (4, 32, 104, 116)\n",
      "skip[3]: (4, 16, 52, 232)\n",
      "skip[4]: (4, 8, 26, 464)\n",
      "[Info] Model size: 16.36794M\n",
      "[Info] Restoreing pretrained flow weights from: ../results/KITTI_256_832_flow_b8_3frames/model-392302\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:25:58.090988 139668652537600 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../results/KITTI_256_832_flow_b8_3frames/model-392302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1109 02:25:58.096693 139668652537600 saver.py:1270] Restoring parameters from ../results/KITTI_256_832_flow_b8_3frames/model-392302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/garin0115/depth/unsupervised-depth-prediction/src/model/undpflow_model.py:318: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1109 02:26:12.189686 139668652537600 deprecation.py:323] From /home/garin0115/depth/unsupervised-depth-prediction/src/model/undpflow_model.py:318: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1] [    1/ 5025] total steps:[     1] lr:[0.00010000] time: 224.06s (224s total) loss: 293.851\n",
      "[Info] Saving checkpoint to ../results/KITTI_256_832_dp_b8_ShuffleNetV2_mobile_sep/checkpoints ...\n",
      "Epoch: [ 1] [   11/ 5025] total steps:[    11] lr:[0.00010000] time: 342.15s (566s total) loss: 266.143\n",
      "Epoch: [ 1] [   21/ 5025] total steps:[    21] lr:[0.00010000] time: 29.06s (595s total) loss: 292.506\n",
      "Epoch: [ 1] [   31/ 5025] total steps:[    31] lr:[0.00010000] time: 29.07s (624s total) loss: 244.992\n",
      "Epoch: [ 1] [   41/ 5025] total steps:[    41] lr:[0.00010000] time: 29.10s (653s total) loss: 321.937\n",
      "Epoch: [ 1] [   51/ 5025] total steps:[    51] lr:[0.00010000] time: 29.01s (682s total) loss: 221.334\n",
      "Epoch: [ 1] [   61/ 5025] total steps:[    61] lr:[0.00010000] time: 29.15s (711s total) loss: 274.838\n",
      "Epoch: [ 1] [   71/ 5025] total steps:[    71] lr:[0.00010000] time: 29.04s (740s total) loss: 291.966\n",
      "Epoch: [ 1] [   81/ 5025] total steps:[    81] lr:[0.00010000] time: 29.03s (769s total) loss: 281.159\n",
      "Epoch: [ 1] [   91/ 5025] total steps:[    91] lr:[0.00010000] time: 29.26s (798s total) loss: 222.984\n",
      "Epoch: [ 1] [  101/ 5025] total steps:[   101] lr:[0.00010000] time: 29.17s (828s total) loss: 244.051\n",
      "Epoch: [ 1] [  111/ 5025] total steps:[   111] lr:[0.00010000] time: 29.30s (857s total) loss: 275.959\n",
      "Epoch: [ 1] [  121/ 5025] total steps:[   121] lr:[0.00010000] time: 28.93s (886s total) loss: 270.379\n",
      "Epoch: [ 1] [  131/ 5025] total steps:[   131] lr:[0.00010000] time: 29.17s (915s total) loss: 255.816\n",
      "Epoch: [ 1] [  141/ 5025] total steps:[   141] lr:[0.00010000] time: 29.08s (944s total) loss: 266.511\n",
      "Epoch: [ 1] [  151/ 5025] total steps:[   151] lr:[0.00010000] time: 29.03s (973s total) loss: 286.260\n",
      "Epoch: [ 1] [  161/ 5025] total steps:[   161] lr:[0.00010000] time: 29.00s (1002s total) loss: 273.652\n",
      "Epoch: [ 1] [  171/ 5025] total steps:[   171] lr:[0.00010000] time: 29.04s (1031s total) loss: 224.692\n",
      "Epoch: [ 1] [  181/ 5025] total steps:[   181] lr:[0.00010000] time: 28.97s (1060s total) loss: 272.924\n",
      "Epoch: [ 1] [  191/ 5025] total steps:[   191] lr:[0.00010000] time: 29.00s (1089s total) loss: 223.254\n",
      "Epoch: [ 1] [  201/ 5025] total steps:[   201] lr:[0.00010000] time: 29.37s (1118s total) loss: 238.188\n",
      "Epoch: [ 1] [  211/ 5025] total steps:[   211] lr:[0.00010000] time: 29.31s (1148s total) loss: 224.573\n",
      "Epoch: [ 1] [  221/ 5025] total steps:[   221] lr:[0.00010000] time: 29.17s (1177s total) loss: 208.653\n",
      "Epoch: [ 1] [  231/ 5025] total steps:[   231] lr:[0.00010000] time: 29.31s (1206s total) loss: 264.985\n",
      "Epoch: [ 1] [  241/ 5025] total steps:[   241] lr:[0.00010000] time: 29.18s (1235s total) loss: 255.531\n",
      "Epoch: [ 1] [  251/ 5025] total steps:[   251] lr:[0.00010000] time: 29.14s (1265s total) loss: 269.645\n",
      "Epoch: [ 1] [  261/ 5025] total steps:[   261] lr:[0.00010000] time: 29.03s (1294s total) loss: 198.337\n",
      "Epoch: [ 1] [  271/ 5025] total steps:[   271] lr:[0.00010000] time: 29.36s (1323s total) loss: 184.713\n",
      "Epoch: [ 1] [  281/ 5025] total steps:[   281] lr:[0.00010000] time: 29.14s (1352s total) loss: 251.916\n",
      "Epoch: [ 1] [  291/ 5025] total steps:[   291] lr:[0.00010000] time: 29.01s (1381s total) loss: 221.054\n",
      "Epoch: [ 1] [  301/ 5025] total steps:[   301] lr:[0.00010000] time: 29.20s (1410s total) loss: 179.123\n",
      "Epoch: [ 1] [  311/ 5025] total steps:[   311] lr:[0.00010000] time: 29.09s (1439s total) loss: 200.370\n",
      "Epoch: [ 1] [  321/ 5025] total steps:[   321] lr:[0.00010000] time: 29.15s (1469s total) loss: 246.065\n",
      "Epoch: [ 1] [  331/ 5025] total steps:[   331] lr:[0.00010000] time: 29.23s (1498s total) loss: 233.052\n",
      "Epoch: [ 1] [  341/ 5025] total steps:[   341] lr:[0.00010000] time: 29.09s (1527s total) loss: 251.509\n",
      "Epoch: [ 1] [  351/ 5025] total steps:[   351] lr:[0.00010000] time: 29.39s (1556s total) loss: 241.782\n",
      "Epoch: [ 1] [  361/ 5025] total steps:[   361] lr:[0.00010000] time: 29.26s (1586s total) loss: 232.827\n",
      "Epoch: [ 1] [  371/ 5025] total steps:[   371] lr:[0.00010000] time: 29.10s (1615s total) loss: 259.808\n",
      "Epoch: [ 1] [  381/ 5025] total steps:[   381] lr:[0.00010000] time: 29.07s (1644s total) loss: 250.216\n",
      "Epoch: [ 1] [  391/ 5025] total steps:[   391] lr:[0.00010000] time: 29.16s (1673s total) loss: 263.724\n",
      "Epoch: [ 1] [  401/ 5025] total steps:[   401] lr:[0.00010000] time: 29.45s (1702s total) loss: 230.680\n",
      "Epoch: [ 1] [  411/ 5025] total steps:[   411] lr:[0.00010000] time: 29.02s (1731s total) loss: 263.827\n",
      "Epoch: [ 1] [  421/ 5025] total steps:[   421] lr:[0.00010000] time: 29.18s (1761s total) loss: 227.608\n",
      "Epoch: [ 1] [  431/ 5025] total steps:[   431] lr:[0.00010000] time: 29.34s (1790s total) loss: 191.282\n",
      "Epoch: [ 1] [  441/ 5025] total steps:[   441] lr:[0.00010000] time: 29.14s (1819s total) loss: 220.407\n",
      "Epoch: [ 1] [  451/ 5025] total steps:[   451] lr:[0.00010000] time: 28.90s (1848s total) loss: 289.705\n",
      "Epoch: [ 1] [  461/ 5025] total steps:[   461] lr:[0.00010000] time: 29.03s (1877s total) loss: 323.743\n"
     ]
    }
   ],
   "source": [
    "%run ./main.py -c ../config/dp3.ini -t train_dp \\\n",
    "--restore_flow_model=../results/KITTI_256_832_flow_b8_3frames/model-392302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### continue training depth and pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./main.py -c ../config/dp3.ini -t train_dp \\\n",
    "--cont_model=../results/KITTI_256_832_UnDepthflow_dp_b32_ShuffleNetV2_3frames/checkpoints/kitti_3frames/model-251251 \\\n",
    "--restore_flow_model=../results/KITTI_256_832_flow_b8_3frames/model-392302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./main.py -c ../config/test_dp_kitti.ini -t kitti_eval \\\n",
    "--restore_dp_model=../results/KITTI_256_832_UnDepthflow_dp_b32_ShuffleNetV2_3frames/checkpoints/kitti_3frames/model-251251 \n",
    "# --restore_dp_model=../results/KITTI_RAW_128_416_UnDepthflow_dp_b4_resnet50_3frames/checkpoints/kitti_3frames/model-342007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kitti_eval/eval_depth.py --split=eigen --kitti_dir=/work/garin0115/datasets/KITTI/ \\\n",
    "--pred_file=../results/kitti/test_kitti.npy \\\n",
    "--depth_results=../results/kitti_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 將結果傳回本地端 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scp -r -P 2222 garin@140.113.214.40:/home/garin/Documents/depth/results/kitti_depths/ C:/Users/Garin/Desktop/學長畢業資料/實驗程式yu/result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=../results/KITTI_256_832_UnDepthflow_dp_b32_ShuffleNetV2_3frames/ \\\n",
    "--samples_per_plugin images=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "\n",
    "# Define a scenario\n",
    "IMAGE_SIZE = 320\n",
    "CHANNELS_BATCH_SIZE = 2048  # channels * batch_size\n",
    "KERNEL_SIZE = 3\n",
    "REPEATS = 50\n",
    "\n",
    "\n",
    "def build_ops(image: tf.Tensor, channels: int, depth_multiplier: int) -> Tuple[tf.Operation, tf.Operation]:\n",
    "    in_channels = channels\n",
    "    out_channels = channels\n",
    "    data_format = \"NCHW\"\n",
    "\n",
    "    # Filter definitions\n",
    "    basis_filters = tf.random_normal(\n",
    "        shape=[3, 3, in_channels, depth_multiplier], dtype=tf.float32)\n",
    "    coeffs = tf.random_normal(\n",
    "        shape=[in_channels, depth_multiplier, out_channels], dtype=tf.float32)\n",
    "\n",
    "    sep_coffs = tf.reshape(coeffs, [1, 1, channels * depth_multiplier, out_channels])\n",
    "\n",
    "    # Normal method\n",
    "    effective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\n",
    "\n",
    "    # Separable_native method\n",
    "    depthwiseN = tf.nn.depthwise_conv2d_native(\n",
    "        image,\n",
    "        basis_filters,\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding=\"SAME\",\n",
    "        data_format=data_format)\n",
    "\n",
    "    pointwiseN = tf.nn.conv2d(\n",
    "        depthwiseN,\n",
    "        sep_coffs,\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "        use_cudnn_on_gpu=True,\n",
    "        data_format=data_format)\n",
    "\n",
    "    # Separable method\n",
    "    depthwise = tf.nn.depthwise_conv2d(\n",
    "        image,\n",
    "        basis_filters,\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding=\"SAME\",\n",
    "        data_format=data_format)\n",
    "\n",
    "    pointwise = tf.nn.conv2d(\n",
    "        depthwise,\n",
    "        sep_coffs,\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "        use_cudnn_on_gpu=True,\n",
    "        data_format=data_format)\n",
    "\n",
    "    # separable\n",
    "    separable =  slim.separable_conv2d(image, out_channels, 3, depth_multiplier=depth_multiplier, \n",
    "                 stride=1,rate=1, activation_fn=None, biases_initializer=None)\n",
    "\n",
    "    # Normal method\n",
    "    normal = tf.nn.conv2d(\n",
    "        image,\n",
    "        effective_filters,\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding=\"SAME\",\n",
    "        use_cudnn_on_gpu=True,\n",
    "        data_format=data_format)\n",
    "\n",
    "    net = slim.conv2d(image, out_channels, 1, 1, rate=1,\n",
    "                    biases_initializer=None, activation_fn=None)\n",
    "    net = slim.separable_conv2d(\n",
    "                            net,\n",
    "                            None,\n",
    "                            3,\n",
    "                            depth_multiplier=depth_multiplier,\n",
    "                            stride=1,\n",
    "                            rate=1,\n",
    "                            activation_fn=None, \n",
    "                            biases_initializer=None)\n",
    "    net = slim.conv2d(net, out_channels, 1, 1, rate=1,\n",
    "                    biases_initializer=None, activation_fn=None)\n",
    "\n",
    "    return normal, pointwise, pointwiseN, net\n",
    "\n",
    "\n",
    "def run(sess: tf.Session, normal: tf.Operation, pointwise: tf.Operation, pointwiseN: tf.Operation, net: tf.Operation):\n",
    "    # Assert equality of the different methods\n",
    "#     norm, pw, pwN, sep, nt= sess.run([normal, pointwise, pointwiseN, separable, net])\n",
    "#     np.testing.assert_almost_equal(norm, sep, decimal=2)\n",
    "\n",
    "    # Benchmark normal method\n",
    "    start = time.time()\n",
    "    for _ in range(REPEATS):\n",
    "        _ = sess.run(normal)\n",
    "    end = time.time()\n",
    "    d1 = int((end - start) / REPEATS * 1000)\n",
    "    \n",
    "    # Benchmark normal method\n",
    "    start = time.time()\n",
    "    for _ in range(REPEATS):\n",
    "        _ = sess.run(pointwise)\n",
    "    end = time.time()\n",
    "    d2 = int((end - start) / REPEATS * 1000)\n",
    "    \n",
    "    # Benchmark normal method\n",
    "    start = time.time()\n",
    "    for _ in range(REPEATS):\n",
    "        _ = sess.run(pointwiseN)\n",
    "    end = time.time()\n",
    "    d3 = int((end - start) / REPEATS * 1000)\n",
    "\n",
    "    \n",
    "    # Benchmark seperable method\n",
    "    start = time.time()\n",
    "    for _ in range(REPEATS):\n",
    "        _ = sess.run(net)\n",
    "    end = time.time()\n",
    "    d4 = int((end - start) / REPEATS * 1000)\n",
    "\n",
    "\n",
    "    # Print results\n",
    "    print(\"Normal method: {}ms \\t depthwise_native method: {}ms\\t depthwise method: {}ms\\t net method: {}ms\".format(d1, d2, d3, d4))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for channels in [32, 64, 128, 256, 512, 1024]:\n",
    "            # adjust batch_size so gpu doesn't run out of memory\n",
    "            for imRate in [1, 2, 4, 8, 16, 32]:\n",
    "                imH, imW = 256//imRate, 832//imRate\n",
    "                batch_size = CHANNELS_BATCH_SIZE // channels\n",
    "                image = tf.random_normal(shape=[batch_size, channels, imH, imW], dtype=tf.float32)\n",
    "                \n",
    "                depth_multiplier=1\n",
    "\n",
    "                normal, pointwise, pointwiseN, net = build_ops(image, channels, depth_multiplier)\n",
    "\n",
    "                print('Channels:', channels, 'size:', imH, imW)\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                run(sess, normal, pointwise, pointwiseN, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Define a scenario\n",
    "IMAGE_SIZE = 320\n",
    "CHANNELS_BATCH_SIZE = 2048  # channels * batch_size\n",
    "KERNEL_SIZE = 3\n",
    "REPEATS = 100\n",
    "\n",
    "\n",
    "def build_ops(image: tf.Tensor, channels: int, depth_multiplier: int) -> Tuple[tf.Operation, tf.Operation]:\n",
    "    with tf.variable_scope(\"{}_{}\".format(channels, depth_multiplier)):\n",
    "        in_channels = out_channels = channels\n",
    "        data_format = \"NCHW\"\n",
    "\n",
    "        # Filter definitions\n",
    "        basis_filters = tf.random_normal(\n",
    "            shape=[KERNEL_SIZE, KERNEL_SIZE, in_channels, depth_multiplier], dtype=tf.float32)\n",
    "        coeffs = tf.random_normal(\n",
    "            shape=[in_channels, depth_multiplier, out_channels], dtype=tf.float32)\n",
    "\n",
    "        sep_coffs = tf.reshape(coeffs, [1, 1, channels * depth_multiplier, out_channels])\n",
    "\n",
    "        # Normal method\n",
    "        effective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\n",
    "\n",
    "        # Separable method\n",
    "        depthwise = tf.nn.depthwise_conv2d_native(\n",
    "            image,\n",
    "            basis_filters,\n",
    "            strides=[1, 1, 1, 1],\n",
    "            padding=\"SAME\",\n",
    "            data_format=data_format)\n",
    "\n",
    "        separable = tf.nn.conv2d(\n",
    "            depthwise,\n",
    "            sep_coffs,\n",
    "            strides=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "            use_cudnn_on_gpu=True,\n",
    "            data_format=data_format)\n",
    "\n",
    "        # Normal method\n",
    "        normal = tf.nn.conv2d(\n",
    "            image,\n",
    "            effective_filters,\n",
    "            strides=[1, 1, 1, 1],\n",
    "            padding=\"SAME\",\n",
    "            use_cudnn_on_gpu=True,\n",
    "            data_format=data_format)\n",
    "\n",
    "        return normal, separable\n",
    "\n",
    "\n",
    "def run(sess: tf.Session, normal: tf.Operation, separable: tf.Operation):\n",
    "    # Assert equality of the different methods\n",
    "    norm, sep = sess.run([normal, separable])\n",
    "    np.testing.assert_almost_equal(norm, sep, decimal=2)\n",
    "\n",
    "    # Benchmark normal method\n",
    "    start = time.time()\n",
    "    for _ in range(REPEATS):\n",
    "        _ = sess.run(normal)\n",
    "    end = time.time()\n",
    "    d1 = int((end - start) / REPEATS * 1000)\n",
    "\n",
    "    # Benchmark seperable method\n",
    "    start = time.time()\n",
    "    for _ in range(REPEATS):\n",
    "        _ = sess.run(separable)\n",
    "    end = time.time()\n",
    "    d2 = int((end - start) / REPEATS * 1000)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with tf.Session() as sess:\n",
    "        for channels in [32, 128, 1024]:\n",
    "            # adjust batch_size so gpu doesn't run out of memory\n",
    "            batch_size = CHANNELS_BATCH_SIZE // channels\n",
    "            image = tf.random_normal(shape=[batch_size, channels, IMAGE_SIZE, IMAGE_SIZE], dtype=tf.float32)\n",
    "\n",
    "            for depth_multiplier in [1, 4, 8]:\n",
    "                normal, separable = build_ops(image, channels, depth_multiplier)\n",
    "\n",
    "                print('Channels:', channels, 'depth_multiplier:', depth_multiplier)\n",
    "                run(sess, normal, separable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
